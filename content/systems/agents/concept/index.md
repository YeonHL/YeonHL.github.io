---
title: 에이전트의 개념
description: 에이전트는 기존의 봇이나 어시스턴트와 어떤 차이점이 있을까요? 에이전트의 정의를 알아보겠습니다.
date: 2025-08-07T19:03:00
lastmod: 2025-09-05
slug: concept
comments: true
math: false
categories:
  - Systems
tags:
  - Agents
  - AI
  - LLM
keywords:
  - Agents
  - AI
---
## 개요

에이전트를 단순한 프로그램이나 챗봇과 구분할 수 있는 기준은 무엇일까요? 에이전트를 개발하면서 이를 고민하고, 본질을 잃지 않고 올바른 시스템을 만들기 위해 고민했습니다. **에이전트 (Agents)** 페이지에서는 에이전트의 개념과 특징, 발전 과정을 다룹니다.

이 포스트에서는 에이전트가 다른 시스템과 구분되는 특징과 속성을 알아보겠습니다.

## 에이전트의 속성

에이전트는 **자율성 (Autonomy)**, **반응성 (Reactivity)**, **주도성 (Pro-activeness)**, **사회성, (Sociality)**, **학습 능력 (Learning)** 의 속성을 갖습니다.

### 자율성 (Autonomy)

**자율성**은 사전에 프로그래밍된 작업을 수행하는 것을 넘어, 지속적인 인간의 감독이나 직접적인 개입 없이 <span style="background:#fff88f">독립적으로 상황을 판단</span>하고, <span style="background:#fff88f">의사결정</span>을 내리며, 행동을 취할 수 있는 능력을 의미합니다. 에이전트의 가장 근본적이고 결정적인 특징으로 에이전트를 수동적인 도구에서 능동적인 행위자로 만듭니다.

예를 들어, 자율 주행 자동차는 복잡한 도심 환경에서 수많은 센서로부터 쏟아지는 데이터를 실시간으로 처리하여 차선 변경, 속도 조절, 돌발 상황 회피 등 수많은 결정을 독립적으로 수행합니다. 마찬가지로, 현대적인 물류 창고의 로봇은 재고의 위치를 파악하고, 최적의 이동 경로를 스스로 계산하며, 다른 로봇과의 충돌을 피해 작업을 수행합니다. 이들은 단순히 명령을 따르는 기계가 아니라, 주어진 목표(예: 안전한 주행, 효율적인 물류 처리)를 달성하기 위해 스스로 판단하고 행동합니다.

### 반응성 (Reactivity)

**반응성**은 에이전트가 센서를 통해 주변 <span style="background:#fff88f">환경의 변화를 인식</span>하고, 그 변화에 실시간으로 적절하게 대응하는 능력입니다. 

예를 들어, 자율 주행 자동차는 갑자기 끼어드는 차량이나 도로에 나타난 장애물을 감지하고 즉시 감속하거나 회피합니다. 또한, 스마트 온도 조절기는 실내 온도의 변화나 사람의 유무를 감지하여 난방이나 냉방을 조절하며, 고객 서비스 챗봇은 사용자의 새로운 질문에 즉각적으로 응답하여 문제를 해결합니다. 이러한 실시간 적응 능력으로 에이전트는 정적인 프로그램을 넘어 동적인 환경의 일부로 동작합니다.

### 주도성 (Pro-activeness)

**주도성**은 현재 상황을 분석하고 미래를 예측하여, 문제가 발생하거나 필요가 명시적으로 요구되기 전에 <span style="background:#fff88f">선제적으로 행동을 개시</span>하는 능력입니다. 에이전트는 단순히 외부 자극에 반응하는 것을 넘어, <span style="background:#fff88f">목표 지향적인 행동을 주도적으로 수행</span>합니다. 앞의 자율성과 주도성을 통해 에이전트가 능동적 주체로 행동할 수 있습니다. 

예를 들어, AI 개인 비서는 사용자가 묻기 전에 다가올 회의 일정을 미리 알려주거나, 평소 출퇴근 패턴과 실시간 교통 정보를 분석하여 최적의 경로를 먼저 제안할 수 있습니다. AI 기반 금융 자문가는 현재 포트폴리오를 관리하는 데 그치지 않고, 시장 동향을 예측하여 위험을 줄이고 수익을 극대화하기 위한 포트폴리오 조정을 선제적으로 제안합니다. 이처럼 주도성은 에이전트가 사용자의 목표를 이해하고 목표 달성을 위해 적극적으로 행동하게 만드는 능력입니다.

### 사회성 및 학습 (Sociality & Learning)

에이전트는 다른 에이전트나 사람과 <span style="background:#fff88f">소통하고 협력</span>하는 사회적 능력을 가질 수 있습니다. 또한 경험을 통해 스스로의 성능을 개선하는 학습 능력도 가질 수 있습니다.

사회성은 다중 에이전트 시스템(Multi-Agent Systems)에서 특히 중요합니다. 예를 들어, 물류 창고의 여러 로봇들은 서로 정보를 교환하며 작업 순서를 최적화하고, 교통 관제 시스템의 에이전트들은 서로 통신하며 전체적인 교통 흐름을 개선합니다. 이러한 협업 능력은 개별 에이전트의 능력을 합한 것 이상의 시너지를 창출합니다. 이 사회성의 기반에는 자연어 처리(NLP) 기술이 있으며, 특히 대규모 언어 모델(LLM)의 등장으로 에이전트가 인간과 훨씬 더 자연스럽고 정교하게 상호작용하고 있습니다.

학습 능력은 에이전트가 시간이 지날수록 더 많은 역할을 수행할 수 있게 합니다. 자율 주행 자동차는 수백만 마일의 주행 데이터를 학습하며 운전 실력을 향상시키고, 콘텐츠 추천 시스템은 사용자의 <span style="background:#fff88f">피드백을 학습하여 더 정확한 추천을 제공</span>합니다. 이처럼 학습 능력은 에이전트를 정적인 시스템에서 나아가, 환경과 상호작용하며 진화하는 동적인 존재로 만듭니다.

## AI 시스템의 발전

AI 에이전트는 어떤 발전 과정을 거쳤을까요? Google 등 업계에서는 다음과 같은 기준으로 분류합니다.

### 봇 (Bots)

봇은 주로 자동화된 대화나 단순 반복 작업을 위해 설계됩니다. 봇의 핵심 특징은 **반응성**과 **규칙 기반** 작동입니다. 이들은 <u>사전에 정의된 규칙이나 특정 트리거에 따라 반응</u>하며, 학습 능력은 거의 없거나 매우 제한적입니다. 초기의 챗봇인 엘리자(ELIZA)나 간단한 키워드 기반의 스팸 필터, 웹사이트의 자동 응답 시스템 등이 대표적인 예시입니다. 봇은 독립적인 의사결정 능력을 갖추지 못하고 사용자의 명시적인 명령이나 특정 조건이 충족될 때만 작동하는 수동적인 도구에 가깝습니다.

### AI 어시스턴트 (AI Assistants)

AI 어시스턴트는 봇보다 한 단계 진화한 형태로, 사용자의 작업을 보조하는 역할을 수행합니다. 애플의 시리(Siri)나 구글 어시스턴트, 아마존 알렉사(Alexa) 등이 여기에 해당합니다. 봇보다 향상된 자연어 처리 능력과 약간의 학습 능력을 갖추고 있어, 사용자의 요청이나 질문에 더 유연하게 반응하고 정보를 제공하거나 간단한 작업을 수행할 수 있습니다.

AI 어시스턴트의 핵심적인 특징은 사용자와의 **상호작용을 통한 보조**입니다. 이들은 작업의 여러 단계에 걸쳐 사용자와 소통하며, 특정 행동을 추천할 수는 있지만 <u>최종적인 의사결정 권한은 항상 사용자</u>에게 있습니다. 즉, AI 어시스턴트는 여전히 사용자의 지시를 기다리는 반응적인 존재이며, 자율성의 정도가 제한적입니다.

### AI 에이전트 (AI Agents)

AI 에이전트는 어시스턴트에서 더 나아가, 단순히 사용자를 보조하는 것을 넘어, 사용자를 대신하여 자율적이고 주도적으로 목표를 추구하고 과업을 완수합니다. 복잡하고 여러 단계로 이루어진 작업을 <span style="background:#fff88f">독립적으로 계획하고 실행</span>할 수 있으며, 지속적으로 <span style="background:#fff88f">자신의 성능을 개선</span>합니다. 자율 주행 자동차, 정교한 금융 거래 에이전트, 공급망을 최적화하는 시스템, 그리고 최근 등장한 OpenAI의 연구 에이전트나 구글의 프로젝트 아스트라와 같은 다중 모드 에이전트가 예시입니다. 단순한 도구나 보조자가 아닌, 특정 <span style="background:#fff88f">목표를 부여</span>받고 그 목표를 달성하기 위해 스스로 세계와 상호작용합니다. 이러한 자율성과 주도성의 차이는 AI 에이전트를 이전 세대의 AI와 구별 짓는 가장 중요한 차이점입니다.

| 특성          | 봇 (Bot)                | AI 어시스턴트 (AI Assistant)              | AI 에이전트 (AI Agent)                 |
| ----------- | ---------------------- | ------------------------------------ | ---------------------------------- |
| **목적**      | 단순 작업 또는 대화 자동화        | 사용자의 과업 보조                           | 자율적, 주도적 과업 수행                     |
| **핵심 능력**   | 사전 정의된 규칙 준수, 기본적 상호작용 | 요청/프롬프트에 응답, 정보 제공, 간단한 과업 완료, 행동 추천 | 복잡한 다단계 행동 수행, 독립적 의사결정, 학습 및 적응   |
| **상호작용 방식** | 반응적 (트리거 또는 명령어에 응답)   | 반응적 (사용자 요청에 응답)                     | 주도적 (목표 지향적)                       |
| **자율성 수준**  | 가장 낮음 (프로그래밍된 규칙 엄수)   | 중간 (사용자 지시 및 확인 필요)                  | 가장 높음 (목표 달성을 위한 독립적 운영 및 의사결정)    |
| **학습 능력**   | 제한적이거나 없음              | 일부 학습 능력 보유                          | 지속적인 학습 및 성능 개선                    |

#### AI 에이전트 vs. 챗봇 & AI 어시스턴트

챗봇과 AI 어시스턴트는 AI 에이전트와 흔하게 혼동되는 개념이지만, 자율성과 복잡성 측면에서 차이가 있습니다.

- **자율성:** 챗봇과 AI 어시스턴트는 '수동적(reactive)'이며, 사용자의 질문이나 명령(prompt)에 응답하는 방식으로 동작합니다. 행동을 위해 지속적인 사용자 입력이 필요합니다. 반면, AI 에이전트는 '능동적(proactive)'이고 목표 지향적입니다. 목표가 주어지면 사람의 개입 없이도 스스로 계획을 세우고 작업을 수행합니다.
- **복잡성:** 챗봇과 AI 어시스턴트는 FAQ 답변, 정보 제공, 단일 작업 수행 등 비교적 단순하고 정형화된 상호작용을 처리하는 데 적합합니다. 반면, AI 에이전트는 여러 시스템과 연동하고, 여러 단계를 거쳐야 하는 복잡한 워크플로우도 처리할 수 있습니다.

#### AI 에이전트 vs. 로보틱 프로세스 자동화(RPA)

RPA와 AI 에이전트는 모두 비즈니스 프로세스를 자동화하지만, 그 방식과 지능 수준에 차이가 있습니다.

- **핵심 기능:** RPA는 인간의 행동을 모방하여 정해진 '절차(procedure)'를 자동화합니다. 예를 들어, 특정 폴더에서 엑셀 파일을 열어 데이터를 복사한 후, 다른 시스템의 특정 필드에 붙여넣는 것과 같은 반복적이고 규칙 기반의 작업을 수행합니다. 반면, AI 에이전트는 특정 '결과(outcome)'를 달성하기 위해 자율적으로 행동합니다. "이 고객의 환불 요청을 처리하라"는 목표가 주어지면, 에이전트는 스스로 필요한 시스템에 접근하고, 정책을 확인하며, 고객과 소통하여 문제를 해결합니다.
- **데이터 처리:** RPA는 스프레드시트나 양식과 같은 '정형 데이터(structured data)'를 처리하는 데 최적화되어 있으며, 애플리케이션의 사용자 인터페이스(UI)가 변경되면 쉽게 오류가 발생합니다. 반면, AI 에이전트는 자연어 처리(NLP) 기술을 통해 이메일, 채팅 기록, 문서 등 '비정형 데이터(unstructured data)'를 이해하고 처리할 수 있으며, 환경 변화에 더 잘 적응합니다.
- **지능과 학습:** 전통적인 RPA 봇은 학습 능력이 없으며, 프로그래밍된 규칙을 기계적으로 수행합니다. 반면, AI 에이전트는 경험으로부터 학습하고, 추론하며, 복잡한 의사결정을 내릴 수 있습니다.

### 발전 방향

기술이 발전할수록 시스템은 점차 <span style="background:#fff88f">인간의 개입을 덜 필요</span>로 하고, <span style="background:#fff88f">수동적인 반응에서 능동적인 형태로</span> 나아갑니다. 이는 어시스턴트에서 에이전트로 넘어가는 지점에서 큰 차이가 나타납니다.

최근 이러한 발전이 가능한 것은 대규모 언어 모델(LLM)의 등장 덕분입니다. LLM은 추론, 계획, 자연어 상호작용 능력에서 탁월한 성능을 보이며, 현대 AI 에이전트의 '두뇌' 또는 '제어기' 역할을 수행하기에 이상적인 기반을 제공합니다. LLM의 생성 능력은 자율성을, 다중 모드 통합은 반응성을, 예측 및 계획 능력은 주도성을, 그리고 자연어 처리 능력은 사회성을 구현하는 데 결정적인 역할을 합니다. 오늘날 AI 에이전트는 LLM이 주도하는 행위성(agency)으로 표현됩니다.

LLM 이전 시대에 에이전트를 만드는 가장 큰 어려움은 핵심적인 추론 능력과 세계 모델링 기능을 처음부터 구축하는 것이었습니다. 그러나 LLM의 등장으로 강력한 범용 추론 엔진은 누구나 쉽게 활용할 수 있는 일종의 '상품(commodity)'이 되었고, 이제 현대 에이전트 개발의 다음 핵심 과제는 '**오케스트레이션(Orchestration)**'입니다. 이 강력한 인지 엔진을 어떻게 <span style="background:#fff88f">기억(memory), 도구(tools), 그리고 안전하고 신뢰할 수 있는 거버넌스 프레임워크와 효과적으로 결합하여 특정 목표를 안정적으로 달성</span>하게 할지 고민해야 합니다. 경쟁의 핵심은 누가 더 뛰어난 범용 지능을 만드느냐가 아니라, 주어진 지능을 누가 더 정교하게 조율하여 실질적인 가치를 창출하느냐로 옮겨가고 있습니다.

## 에이전트의 기원

그렇다면 AI 에이전트가 처음부터 지금과 같은 역할을 수행했을까요? 사실, 에이전트의 개념은 오래 전부터 존재했고, 수십 년간의 연구가 축적된 결과물입니다. 그 변천사를 살펴보겠습니다. 초기 연구자들은 기계가 인간처럼 합리적으로 사고하고 문제를 해결할 수 있는 방법을 모색했습니다.

### 기호주의 시대 (1950년대-1980년대): 합리성을 향한 탐구

AI 연구의 초기 단계는 기호주의(Symbolic AI)로 표현할 수 있습니다. 이 시기의 에이전트는 <span style="background:#fff88f">논리적 규칙과 탐색 알고리즘을 기반으로 작동하는 시스템</span>입니다.

이 시대의 대표적인 예로는 우선 '일반 문제 해결사(General Problem Solver, GPS)' 프로그램이 있습니다. GPS는 주어진 목표를 달성하기 위해 일련의 연산을 순차적으로 적용하는 방법으로 해답을 찾았습니다. 

또한, 마빈 민스키와 시모어 페퍼트가 제안한 '마이크로월드(micro-worlds)' 접근법은 복잡한 현실 세계 대신 '블록 월드'와 같이 단순화된 환경에서 에이전트의 지능을 구현하려는 시도였습니다. 이 환경에서 작동하는 SHRDLU 시스템은 자연어 명령을 이해하고 가상 블록을 조작하며 계획을 수립하는 등 인상적인 능력을 보였습니다.

이러한 초기 에이전트들은 정해진 절차와 규칙에 따라 자율적으로 작업을 수행하는 '**절차적 자율성(procedural autonomy)**'을 가집니다. 목표 달성을 위한 논리적 스크립트를 처음부터 끝까지 수행할 수는 있었지만, 그 스크립트를 벗어나는 창의적인 행동은 불가능했습니다.

현실 세계의 문제는 탐색해야 할 <u>경로의 수가 기하급수적으로 증가</u>하는 '조합적 폭발(combinatorial explosion)' 문제를 야기했으며, 미리 정의된 규칙은 <u>현실 세계의 모호함과 예측 불가능성에 대처하기에는 너무 경직</u>되어 있어 AI에 대한 과도한 기대를 충족시키지 못했습니다.

### 머신러닝과 다중 에이전트 시스템(MAS) 시대 (1980년대-2000년대): 특화된 학습의 부상

1980년대에 들어서면서 AI 연구는 새로운 국면을 맞이했습니다. 규칙 기반 전문가 시스템(Expert Systems)이 상업적으로 성공을 거두고, 프로그래밍된 논리에서 데이터 기반 학습으로 패러다임이 전환되기 시작했습니다. 이 시기 에이전트의 핵심은 '**학습**'입니다.

DENDRAL이나 MYCIN과 같은 전문가 시스템은 특정 분야(화학 분석, 의료 진단 등)의 지식을 활용하여 전문가 수준의 결정을 내렸습니다. 이는 에이전트가 <span style="background:#fff88f">특정 도메인에서 높은 성능</span>을 발휘할 수 있음을 보였습니다. 동시에, 머신러닝 기술의 발전은 에이전트가 데이터로부터 스스로 패턴을 학습하고 성능을 개선할 수 있는 계기가 됐습니다. 특히 강화학습(Reinforcement Learning)은 에이전트가 환경과의 상호작용을 통해 보상을 최대화하는 행동을 학습하여, 특정 작업에 대한 '**통계적 자율성(statistical autonomy)**'을 부여했습니다.

또한, 여러 에이전트 간의 상호작용을 연구하는 **다중 에이전트 시스템(Multi-Agent Systems, MAS)** 분야가 발전했습니다. MAS 연구는 분산 AI, 게임 이론, 자율 로봇 등 다양한 분야에 적용되었으며, 여러 전문화된 에이전트들이 어떻게 협력하거나 경쟁하며 공동의 목표를 달성하는지를 탐구했습니다. 이는 오늘날 복잡한 문제를 해결하기 위해 여러 에이전트를 조율하는 <span style="background:#fff88f">현대적 에이전트 워크플로우의 이론적 기반</span>이 되었습니다.

하지만 이 시대의 에이전트들은 고도로 '특화'되어 있다는 점이 문제였습니다. 특정 게임에서 인간 챔피언을 이기거나(예: TD-Gammon) 1, 특정 공정을 제어하는 데에는 뛰어났지만, <u>한 분야에서 학습한 지식을 다른 분야로 일반화하거나 전이하는 능력은 부족</u>했습니다. 각 에이전트는 자신이 훈련된 특정 작업을 위한 '장인'이 될 수 있지만, 관련된 다양한 문제를 해결하기엔 여전히 부족했습니다.

### 트랜스포머 혁명 (2017년-현재)

2017년 구글이 발표한 트랜스포머 아키텍처는 자연어 처리(NLP) 분야에 혁명을 일으켰습니다. 어텐션 메커니즘(Attention Mechanism)을 통해 문장 내 단어 간의 장거리 의존성을 효과적으로 포착함으로써, 기존 모델들의 한계를 뛰어넘는 성능을 보였습니다. 이를 기반으로 OpenAI의 GPT-1(2018)과 구글의 BERT(2018) 같은 모델들이 등장했으며, 이들은 방대한 양의 레이블 없는 텍스트 데이터로 사전 훈련(pre-training)함으로써 전례 없는 일반화 능력을 갖췄습니다.

이는 큰 변화를 불러왔습니다. 더 이상 특정 작업을 위해 모델을 처음부터 훈련시킬 필요 없이, 하나의 거대한 '기반 모델(Foundation Model)'을 만들어두고, 소량의 데이터로 <u>미세 조정(fine-tuning)하거나 아예 조정 없이도 다양한 작업을 수행</u>할 수 있게 됐습니다. 또한 이를 에이전트의 '두뇌' 또는 '인지 엔진(cognitive engine)' 역할을 하면서 자율적인 에이전트를 구현하려는 시도로 이어졌습니다.

2023년 등장한 Auto-GPT나 BabyAGI와 같은 프레임워크는 LLM을 핵심 엔진으로 사용하여, 사용자가 제시한 복잡한 목표를 스스로 작은 <span style="background:#fff88f">하위 작업으로 분해</span>하고(task decomposition), <span style="background:#fff88f">계획을 수립</span>하며(planning), 웹 검색이나 API 호출과 같은 외부 <span style="background:#fff88f">도구(tools)를 사용하여 정보를 수집</span>하고, 최종적으로 <span style="background:#fff88f">목표를 달성</span>하는 과정을 수행했습니다. 이는 이전의 자율성과 다른 '**인지적 자율성(cognitive autonomy)**'을 특징으로 합니다. 정해진 규칙이나 학습된 전략을 따르는 것을 넘어, 새로운 목표에 대해 <span style="background:#fff88f">스스로 '추론'하고 '계획'하며 '적응'</span>하는 능력입니다. 이 인지적 자율성이 현대 AI 에이전트와 이전의 에이전트의 핵심적인 차이점이다.

### 분석 및 시사점

AI 에이전트의 발전사의 핵심적인 변화는 '자율성'의 개념의 진화와 그에 따른 엔지니어링의 중심 과제 변화입니다.

초기 기호주의 시대의 에이전트는 **절차적 자율성**을 가졌습니다. 실행은 자율적으로 했지만, 생각 과정은 정해진 스크립트를 벗어나지 못했습니다. 이후 머신러닝 시대의 에이전트는 특정 도메인 안에서 '전략을 학습하는' **통계적 자율성**을 획득했습니다. 강화학습으로 훈련된 알파고(AlphaGo)는 바둑이라는 고정된 영역 안에서 최적의 전략을 자율적으로 학습했지만, 바둑 이외의 다른 문제에 능력을 적용할 수 없었습니다.

그러나 LLM 기반의 현대 에이전트는 새로운 종류의 자율성, 즉 '전략 자체를 스스로 고안하는' 인지적 자율성을 가집니다. Auto-GPT와 같은 에이전트는 "지속 가능한 에너지 스타트업을 위한 사업 계획서 작성"과 같은 한 번도 접해보지 못한 새로운 목표가 주어졌을 때, 이를 달성하기 위한 계획을 스스로 수립하고 필요한 도구를 찾아 사용합니다.

이전에 에이전트를 만드는 가장 큰 어려움은 핵심적인 추론 능력과 세계 모델링 기능을 처음부터 구축하는 것이었습니다. 그러나 LLM의 등장으로 강력한 범용 추론 엔진은 누구나 쉽게 활용할 수 있는 일종의 '상품(commodity)'이 되었습니다. 현대 에이전트 개발의 새로운 핵심 과제는 '**오케스트레이션(Orchestration)**'으로, LLM을 어떻게 <span style="background:#fff88f">기억(memory), 도구(tools), 거버넌스 프레임워크와 결합하여 특정 목표를 안정적으로 달성</span>하게 할 것인가의 문제입니다. 최근 LangChain, LlamaIndex와 같은 에이전트 프레임워크가 그 예시입니다. 경쟁의 핵심은 누가 더 뛰어난 범용 지능을 만드느냐가 아니라, 누가 <span style="background:#fff88f">주어진 지능을 더 정교하게 조율하여 실질적인 가치를 창출</span>할지 입니다.

## 에이전트의 분류

AI 에이전트는 그 지능 수준과 의사결정 방식에 따라 여러 유형으로 분류됩니다. 이 분류는 기능이 점차 정교해지는 능력 계층 구조로 이해할 수 있습니다. 각 유형은 이전 유형의 한계를 극복하기 위해 새로운 구성 요소를 추가하는 방식으로 발전했습니다.

### 단순 반사 에이전트

가장 기본적인 형태의 에이전트는 **단순 반사 에이전트(Simple Reflex Agent)** 입니다. 이 에이전트는 오직 '현재의 인식(current percept)'에만 기반하여 행동합니다. "만약 A 조건이라면, B 행동을 하라"는 식의 사전 정의된 <span style="background:#fff88f">'조건-행동 규칙(condition-action rule)'에 따라 반응</span>할 뿐, <u>과거의 경험이나 행동의 결과를 고려하지 않습니다.</u> 예를 들어, 실내 온도가 설정값 이하로 떨어지면 히터를 켜는 온도 조절기나, 연기를 감지하면 경보를 울리는 화재 경보기가 있습니다. 

이러한 에이전트는 규칙이 명확하고 환경의 모든 정보를 즉시 파악할 수 있는 '완전 관찰 가능(fully observable)' 환경에서는 효과적이지만, 환경이 복잡하고 동적으로 변하며, 현재의 인식만으로는 모든 상황을 파악할 수 없는 '부분 관찰 가능(partially observable)' 환경에서는 제대로 작동하기 어렵습니다.

### 모델 기반 반사 에이전트

이러한 한계를 극복하기 위해 등장한 것이 **모델 기반 반사 에이전트(Model-based Reflex Agent)** 입니다. 핵심적인 차별점은 환경에 대한 <span style="background:#fff88f">'내부 모델(internal model)' 또는 '내부 상태(internal state)'를 유지</span>하는 것입니다. 내부 모델은 과거의 인식 기록을 바탕으로 현재 보이지 않는 환경의 측면을 추론하고, 행동이 어떤 영향을 미칠지 예측합니다. 즉, 이 에이전트는 '기억'을 가집니다.

예를 들어, 로봇 청소기는 단순 반사 에이전트처럼 눈앞의 장애물에만 반응하는 것이 아니라, 이미 청소한 구역을 지도로 기억(내부 모델)하여 같은 곳을 반복해서 청소하는 것을 방지합니다. 또한 자율주행차가 차선을 변경할 때, 현재 카메라에 보이는 옆 차선의 차뿐만 아니라, 잠시 보이지 않았던 사각지대의 차가 있을 가능성을 내부 모델을 통해 추론합니다.

### 목표 기반 에이전트

모델 기반 에이전트가 '현재'와 '과거'를 이해한다면, 다음 단계는 '미래'를 계획하는 능력입니다. **목표 기반 에이전트(Goal-based Agent)** 는 여기에 '목표(goal)'라는 정보를 추가하여 의사결정 능력을 한 차원 더 확장합니다. 이 에이전트는 상황에 반응하는 것을 넘어, <span style="background:#fff88f">미래 상태(목표)를 달성하기 위해 어떤 행동 순서가 필요한지를 탐색하고 계획</span>합니다.

내비게이션 시스템이 그 예시입니다. 사용자가 목적지(목표)를 입력하면, 에이전트는 현재 위치에서 목적지까지 도달할 수 있는 여러 경로(행동 순서)를 탐색하고, 그중 하나를 선택하여 안내합니다. 이 과정에서 에이전트는 "이 길로 가면 목표에 더 가까워지는가?"를 끊임없이 평가하며, 더 나은 경로가 발견되면 계획을 수정합니다. 이처럼 목표 기반 에이전트는 <u>검색(search)과 계획(planning)</u> 능력을 통해 반사적 에이전트보다 유연하고 지능적으로 행동합니다.

하지만 목표 기반 에이전트에도 한계는 있습니다. 목표 달성 여부가 이진법적(binary)이라는 점입니다. 목표에 도달하는 여러 경로가 있다면, 그 경로들 사이의 <u>'질적인 차이'를 구분하지 못합니다.</u> 예를 들어, 목적지에 도착하는 경로가 여러 개 있을 때, 어떤 길이 더 빠르고, 더 안전하며, 통행료가 더 저렴한지를 종합적으로 고려하여 '최적의' 경로를 선택하기는 어렵습니다.

### 효용 기반 에이전트

**효용 기반 에이전트(Utility-based Agent)** 는 이 문제를 해결할 수 있습니다. 이 에이전트는 각 상태가 얼마나 '바람직한지'를 나타내는 수치적 척도인 <span style="background:#fff88f">'효용 함수(utility function)'를 사용</span>합니다. 효용은 <u>행복, 이익, 효율성 등 다양한 가치를 정량화</u>한 것으로, 에이전트는 자신의 행동 결과로 도달하게 될 상태의 '기대 효용(expected utility)'을 최대화하는 방향으로 결정합니다.

다시 내비게이션의 예를 들면, 효용 기반 에이전트는 단순히 목적지에 도착하는 것(목표)뿐만 아니라, 이동 시간, 연료 소모량, 통행료, 도로 안전성 등 여러 상충하는 요인들을 종합적으로 고려하여 가장 높은 효용을 주는 경로를 추천합니다. 이처럼 효용 기반 에이전트는 여러 목표가 충돌하거나, 목표 달성 방식에 여러 등급이 있을 때 훨씬 더 정교하고 합리적인 결정을 내릴 수 있습니다.

### 학습 에이전트

앞의 모든 에이전트 유형은 설계자가 부여한 모델, 목표, 효용 함수에 따라 작동합니다. 그러나 <u>환경이 예측 불가능하게 변하거나, 초기 지식이 불완전할 경우 이들의 성능은 저하</u>됩니다. **학습 에이전트(Learning Agent)** 는 이러한 한계를 '<span style="background:#fff88f">학습' 능력</span>을 통해 극복합니다.

학습 에이전트는 다른 에이전트들의 구성 요소를 모두 포함하면서, 스스로 성능을 개선할 수 있는 독특한 아키텍처를 가집니다. 이 아키텍처는 주로 4가지 요소로 구성됩니다.

1. **성능 요소(Performance Element):** 현재 지식을 바탕으로 외부 환경에 대한 행동을 선택하고 실행하는 부분으로, 사실상 앞서 설명한 에이전트 전체에 해당합니다.
2. **비평가(Critic):** 성능 요소의 <u>행동이 얼마나 좋았는지를 외부의 성능 표준(performance standard)과 비교하여 평가하고 피드백을 생성</u>한다. 이 피드백은 <u>보상이나 벌점의 형태</u>일 수 있습니다.
3. **학습 요소(Learning Element):** 비평가로부터 받은 피드백을 바탕으로 <u>성능 요소의 내부 모델이나 규칙을 수정</u>하여 미래에 더 나은 결정을 내릴 수 있습니다.
4. **문제 생성기(Problem Generator):** 현재까지의 경험을 바탕으로, <u>새로운 지식을 얻기 위해 시도해볼 만한 새로운 행동(탐험적 행동)을 제안</u>합니다.

이러한 피드백 루프를 통해 학습 에이전트는 경험으로부터 배우고, 낯선 환경에 적응하며, 시간이 지남에 따라 점점 더 나은 성능을 보입니다. 전자상거래 사이트의 추천 시스템이 사용자의 클릭과 구매 이력을 학습하여 점점 더 개인화된 상품을 추천하는 것이나, 자율주행차가 다양한 주행 경험을 통해 안전하고 효율적인 운전 방식을 스스로 터득하는 것이 학습 에이전트의 대표적인 예입니다. 이처럼 지속적인 자기 개선 능력 덕분에 학습 에이전트는 현재 가장 강력하고 적응성이 뛰어난 에이전트 유형으로 주목 받고 있습니다.

| 에이전트 유형      | 핵심 추가 요소 | 의사결정 기반         | 환경 적합성         | 핵심 한계                 | 대표 사례            |
| ------------ | -------- | --------------- | -------------- | --------------------- | ---------------- |
| **단순 반사**    | 없음       | 현재 인식, 조건-행동 규칙 | 완전 관찰 가능, 정적   | 기억 부재, 부분 관찰 환경 처리 불가 | 온도 조절기, 기본 스팸 필터 |
| **모델 기반 반사** | 내부 상태/모델 | 현재 인식 + 내부 상태   | 부분 관찰 가능, 동적   | 목표 부재, 장기 계획 불가       | 로봇 청소기, 자율주행차    |
| **목표 기반**    | 목표 정보    | 미래 상태 예측, 계획    | 목표가 명확한 복잡한 환경 | 경로/방법의 질적 차이 구분 불가    | 내비게이션, 게임 AI     |
| **효용 기반**    | 효용 함수    | 기대 효용 최대화       | 상충하는 목표가 있는 환경 | 효용 함수 설계의 복잡성         | 개인화 추천, 자원 배분    |
| **학습**       | 학습/비평 요소 | 피드백 기반 자기 개선    | 미지의 동적 환경      | 초기 성능 낮음, 많은 데이터 필요   | 추천 시스템, 자율 로봇    |


## 주요 산업별 에이전트 적용

AI 에이전트는 단순한 업무 자동화를 넘어, 각 산업의 고유한 문제를 해결하고 새로운 전략적 가치를 창출하는 핵심 동력으로 나아가고 있습니다.

| 산업 분야        | 주요 사용 사례                                                       | 핵심 전략적 이점            | 주요 변혁 방향                        | 핵심 도입 과제                        |
| ------------ | -------------------------------------------------------------- | -------------------- | ------------------------------- | ------------------------------- |
| **금융 서비스**   | 실시간 사기 탐지, 알고리즘 트레이딩, 개인화된 로보어드바이저, 자동화된 규제 준수                 | 리스크 완화 및 운영 효율성 극대화  | 수동적 사후 분석에서 능동적 실시간 대응으로 전환     | 데이터 보안, 규제 준수, 모델의 설명가능성 확보     |
| **헬스케어**     | 개인 맞춤형 치료 계획 수립, 의료 영상 분석을 통한 진단 보조, 신약 개발 가속화, 행정 업무 자동화      | 진단 정확도 향상 및 운영 비용 절감 | 단발적 진료에서 지속적인 환자 관리로 전환         | 의료 데이터 프라이버시(HIPAA), 임상적 유효성 검증 |
| **제조 및 공급망** | 예측 유지보수, 실시간 품질 관리, 수요 예측 및 재고 최적화, 적응형 공급망 조정                 | 생산성 향상 및 공급망 탄력성 강화  | 사후 대응적 생산에서 예측 기반의 자율 운영으로 전환   | 기존 시스템과의 통합(OT/IT), 센서 데이터의 품질  |
| **고객 서비스**   | 복잡한 다단계 문의 해결, 선제적 고객 지원, 옴니채널 경험 개인화, 인간 상담원 증강(Agent-assist) | 고객 만족도 증대 및 운영 비용 절감 | 비용 센터에서 가치 창출 및 고객 관계 관리 허브로 전환 | 감성적 상호작용의 한계, 대화 맥락 유지의 어려움     |

### 금융 서비스

금융 산업은 데이터 집약적이고, 속도와 정확성이 경쟁력을 좌우하는 분야인 만큼 AI 에이전트의 도입이 가장 활발하게 이루어지고 있습니다.

#### 리스크 관리 및 트레이딩

- **사용 사례:** 
	- 알고리즘 트레이딩 에이전트는 시장 데이터를 24시간 분석하여 인간의 개입 없이 최적의 타이밍에 거래 실행
	- 사기 탐지 에이전트는 수백만 건의 <u>거래 패턴을 실시간으로 모니터링하여 이상 징후나 사기 가능성이 있는 거래를 즉시 식별하고 차단</u>
	- 리스크 관리 에이전트는 자금세탁방지(AML), 사베인즈-옥슬리법(SOX), 일반정보보호규정(GDPR)과 같은 복잡한 규제 요건을 지속적으로 모니터링하고 보고서를 자동 생성하여 규제 준수 지원
- **전략적 영향:** 
	- 경쟁의 축을 인간 트레이더의 직관과 속도에서 알고리즘의 정교함과 데이터 처리 규모로 이동
	- 사기 및 규제 위반으로 인한 운영 리스크와 막대한 비용을 획기적으로 절감

#### 금융 자문

- **사용 사례:** 
	- 로보어드바이저(Robo-advisor)는 <u>고객의 투자 성향, 재무 목표, 리스크 수용도를 분석하여 개인화된 투자 포트폴리오를 자동으로 생성하고 시장 상황에 따라 리밸런싱</u>까지 수행
	- 대출 심사 에이전트는 신청자의 신용 정보와 다양한 데이터를 종합하여 대출 가능 여부와 한도를 신속하게 결정하며, 지능형 챗봇은 복잡한 금융 상품에 대한 문의나 계좌 관련 문제 해결 지원
- **전략적 영향:** 
	- 금융 기관은 더 넓은 고객층에게 저렴한 비용으로 자산 관리 서비스를 제공할 수 있게 되어 새로운 시장 창출

### 헬스케어

#### 임상 의사결정 증강

- **사용 사례:** 
	- 환자의 유전체 정보, 과거 진료 기록, 최신 연구 논문, 생활 습관 데이터 등을 종합적으로 분석하여 개인에게 <u>최적화된 맞춤형 치료 계획</u>을 생성하고 의사에게 제안
	- IBM Watson Health와 같은 시스템은 암 진단 및 치료법 추천에 활용
	- 엑스레이, CT, MRI와 같은 의료 영상을 분석하여 인간 의사가 놓칠 수 있는 <u>미세한 병변을 찾아내 진단을 보조</u>
	- 방대한 <u>임상시험 데이터를 분석</u>하여 신약 개발 후보 물질을 발굴하고 개발 기간 단축에 기여
- **전략적 영향:** 
	- 표준화된 치료 방식에서 벗어나 정밀 의료(Precision Medicine)와 예측 의료(Predictive Medicine)로의 전환 가속화

#### 헬스케어 운영

- **사용 사례:** 
	- 의사의 진료 기록을 바탕으로 전자의무기록(EHR)을 자동으로 업데이트하고, 진료 내용에 맞는 의료 코드를 생성하여 <u>보험 청구 및 정산 프로세스를 자동화</u>
	- 병원 내 자율주행 로봇이 약품이나 검체를 운송하고, 방역 작업을 수행하며 물류를 최적화
	- 스마트워치나 혈당 측정기와 같은 웨어러블 기기와 연동하여 환자의 상태를 24시간 실시간으로 모니터링하고, 이상 징후 발생 시 의료진에게 즉시 경고
- **전략적 영향:** 
	- 병원의 행정 업무 부담과 운영 비용을 획기적으로 절감
	- 일회성 병원 방문에 의존하던 환자 관리 패러다임을 '지속적이고 예방적인 관리'로 전환

### 제조 및 공급망

#### 스마트 팩토리

- **사용 사례:** 
	- 생산 설비에 부착된 수많은 센서 데이터를 <u>실시간으로 분석하여 장비의 미세한 이상 징후를 감지하고, 고장이 발생하기 전에 유지보수 일정을 알리는 예측 유지보수(Predictive Maintenance)를 수행</u>
	- 생산 라인의 비전 센서 데이터를 분석하여 제품의 결함을 실시간으로 검출하고 불량률 감소 
	- 공장 전체의 에너지 소비 패턴을 분석하여 비효율적인 부분을 찾아내고 에너지 사용을 최적화
- **전략적 영향:** 
	- 설비의 가동 중단 시간(downtime)을 최소화하고 생산성을 극대화
	- 불량품 발생으로 인한 폐기물과 재작업 비용을 줄이고, 에너지 비용을 절감하여 제조 원가 감소

#### 적응형 공급망

- **사용 사례:** 
	- 과거 판매 데이터, 시장 트렌드, 거시 경제 지표 등을 종합 분석하여 미래 수요 예측, 이를 바탕으로 최적의 재고 수준을 유지하도록 자동 발주를 실행
	- 특정 지역의 자연재해나 지정학적 리스크로 인해 부품 공급에 차질이 생길 경우, 대체 공급업체를 탐색하거나, 다른 경로로 운송 계획을 재수립하는 등 <u>실시간으로 공급망 조정</u>
- **전략적 영향:** 
	- '사후 대응적' 공급망 관리를 '예측 기반의 능동적' 관리로 전환
	- 과잉 재고로 인한 비용과 재고 부족으로 인한 판매 기회 손실 감소
	- 예측 불가능한 외부 충격에 대한 회복탄력성을 높여 비즈니스의 연속성 보장

### 고객 서비스

#### FAQ 봇

- **사용 사례:** 
	- 고객이 복잡한 요금 청구 이의를 제기했을 때, 에이전트는 <u>고객의 과거 이용 내역, 결제 시스템, 프로모션 데이터베이스 등 여러 백엔드 시스템에 자율적으로 접근</u>하여 문제의 원인을 파악하고 해결책 제시
	- 고객의 웹사이트 행동 패턴이나 과거 문의 이력을 분석하여 문제가 발생하기 전에 먼저 연락을 취하는 선제적 지원(Proactive Support) 제공
	- 고객이 채팅으로 문의를 시작했다가 이메일이나 전화로 채널을 변경하더라도 이전 대화의 맥락을 그대로 유지하는 옴니채널(Omnichannel) 경험 제공
- **전략적 영향:** 
	- 고객 만족도와 충성도를 높여 매출 기여 기대
	- 24시간 365일 고품질의 지원을 제공함으로써 고객 경험을 획기적으로 개선

#### 인간-에이전트 파트너십

- **사용 사례:** 
	- 상담원의 통화 중, 에이전트 어시스트(Agent-assist) 도구는 실시간으로 대화를 분석하여 <u>관련된 지식 베이스 문서를 화면에</u> 표시
	- 고객 문의에 대한 최적의 <u>답변 초안을 작성하여 제안</u>
	- 통화 종료 후에는 <u>전체 대화 내용을 자동으로 요약하여 CRM 시스템에 기록</u>
- **전략적 영향:** 
	- 인간 상담원의 역량 향상
	- 신입 상담원의 교육 시간을 단축하고, 모든 상담원이 일관된 수준의 서비스를 제공하도록 보장

### 분석 및 시사점

위 사례에서 두 가지 핵심적인 변화의 흐름을 발견할 수 있습니다.

첫 번째는 '**능동적 패러다임으로의 전환(Proactive Paradigm Shift)**'입니다. 모든 산업 분야에서 AI 에이전트가 창출하는 핵심 가치는 기존의 '수동적, 사후 대응적' 운영 모델을 '능동적, 예측적' 모델로 전환합니다. 단순히 주어진 질문에 답하거나 명령을 실행하는 것을 넘어, 제조업에서는 설비가 고장 나기 '전에' 유지보수를 예측하고, 금융에서는 사기가 발생한 '후'가 아니라 의심 현상을 먼저 탐지하며, 고객 서비스에서는 고객이 불만을 제기하기 '전에' 문제를 해결합니다. 이처럼 <span style="background:#fff88f">지속적으로 데이터를 모니터링하고 분석하여 미래를 예측하고 선제적으로 행동</span>하는 능력이야말로 AI 에이전트가 제공하는 가장 큰 전략적 가치입니다.

두 번째는 새로운 **'데이터 플라이휠(Data Flywheel)'의 생성**입니다. AI 에이전트의 성공적인 도입은 스스로를 강화하는 강력한 선순환 구조를 만듭니다. 에이전트가 더 <u>많은 작업을 수행할수록</u>, 더 많은 <span style="background:#fff88f">상호작용 및 결과 데이터가 생성</span>됩니다. 이 데이터는 다시 에이전트의 기반 모델과 의사결정 로직을 개선합니다. 이 '데이터 플라이휠' 효과는 한번 앞서나가기 시작한 기업이 경쟁사와의 격차를 기하급수적으로 벌릴 수 있게 만드는 강력한 경쟁 해자(competitive moat)로 작용할 수 있습니다.


## 에이전트의 과제

### 기술적 난제와 신뢰성

- **추론과 맥락 이해의 결함:** 현재 에이전트들은 깊이 있는 다단계 추론이나 복잡한 지시의 맥락을 완전히 이해하는 능력이 부족합니다. 때로는 논리적 오류에 빠져 무한 루프를 돌거나, 중요한 맥락을 놓쳐 엉뚱한 행동을 수행합니다. 예를 들어, "부서 보고서를 작성해줘"라는 간단한 요청에도, 해당 <u>사용자의 부서, 역할, 보고서의 성격, 이전 대화와의 연관성 등 수많은 맥락을 정확히 파악</u>해야 하는데, 현재 모델들은 실수할 가능성이 높습니다.
- **'취약성(Brittleness)' 문제:** 통제된 환경에서 훈련된 에이전트는 <u>한 번도 경험해보지 못한 새로운(out-of-distribution) 시나리오에 직면했을 때 예측 불가능하게 실패</u>하는 경향이 있습니다. 이들의 성능은 아직 견고하지(robust) 않으며, 특정 상황에서는 정확도가 14.9%까지 떨어지는 등 심각한 오류를 보입니다. 이러한 '취약성'은 금융 거래나 의료 진단과 같이 실패의 대가가 큰 고위험 환경에 에이전트 단독 투입이 어려운 요인입니다.
- **장기 기억과 지속적 학습의 한계:** 현재 에이전트들의 기억 시스템은 완전하지 않습니다. 모델 전체를 재훈련하지 않고 실시간으로 새로운 지식을 반영하여 파라미터를 업데이트하는 '지속적 학습(continuous learning)'은 아직 주요 연구 과제입니다.
- **확장성과 비용:** AI 에이전트를 훈련하고 운영하는 데 필요한 컴퓨팅 자원은 막대합니다. 이는 많은 기업에게 상당한 비용 장벽으로 작용하며, 특히 온프레미스 환경에서 인프라를 구축하고 유지하는 것은 확장성 측면에서도 큰 부담입니다. 또한, 여러 종류의 AI를 통합하여 운영하고, 빠르게 변화하는 기술과 API 정책에 대응하는 것 역시 복잡하고 어려운 유지보수 과제입니다.

### 윤리 및 거버넌스

- **책임과 배상: 책임의 공백:** 자율적인 에이전트가 잘못된 금융 자문을 제공하거나, 의료 과실을 일으키거나, 개인정보를 유출하는 등 피해를 발생시켰을 때, 그 책임은 누구에게 있는지는 아직 명확한 법적, 윤리적 기준이 정립되지 않았습니다. 2024년, 에어캐나다의 챗봇이 고객에게 잘못된 유족 할인 정책 정보를 제공했고, 법원이 이에 대해 회사에 배상 책임을 인정한 사건은 중요한 선례를 남았습니다. 이는 기업이 AI를 단순한 <u>'도구'로 취급하며 책임을 회피할 수 없음</u>을 의미합니다.
- **편향, 공정성, 그리고 조작:** <u>편향된 데이터</u>로 학습된 AI 에이전트는 채용, 대출 심사, 범죄 예측 등 민감한 영역에서 기존의 사회적 차별을 그대로 답습하거나 증폭시킬 위험이 있습니다. 예를 들어, 과거 남성 위주의 채용 데이터로 학습한 에이전트는 여성 지원자를 부당하게 차별할 수 있습니다. 더 나아가, 에이전트의 설득력 있는 상호작용 능력은 사용자의 인지적, 감정적 취약점을 이용하여 사용자의 최선의 이익에 부합하지 않는 방향으로 행동을 미묘하게 유도하는 '조작(manipulation)'의 위험이 있습니다.
- **투명성과 설명가능성(XAI): '블랙박스' 문제:** 복잡한 딥러닝 모델에 기반한 <u>에이전트의 의사결정 과정은 종종 개발자조차 완벽히 이해하기 어려운 '블랙박스'</u>와 같습니다. 이러한 투명성의 부재는 에이전트의 행동을 감사하고, 그 결과를 신뢰하며, 오류의 원인을 진단하는 것을 어렵게 만듭니다.
- **데이터 프라이버시와 보안:** AI 에이전트는 효과적으로 작동하기 위해 방대한 양의 개인 및 기업 데이터에 접근해야 합니다. 이는 심각한 프라이버시 침해 위험을 야기하며, 에이전트가 <u>고부가가치 공격 대상</u>이 됩니다. 특히, 공격자가 악성 이메일이나 교묘한 명령을 통해 에이전트를 속여 민감한 데이터를 외부로 유출하도록 만드는 '하이재킹(hijacking)' 공격은 새로운 보안 위협으로 떠오르고 있습니다. 특정 업무 시나리오 실험 결과에서 하이재킹 공격 성공률은 평균 92%에 달할 정도로 심각한 수준입니다.

### 분석 및 시사점

현재의 AI 에이전트는 현실 세계의 <span style="background:#fff88f">복잡성을 신뢰성 있게 처리할 만큼 충분히 '유능'하거나 '견고'하지 않습니다.</span> 이는 에이전트의 기술적 한계이며, 이로 인해 발생하는 윤리적 문제를 경계해야 합니다. 예를 들어, 에이전트가 사용자의 지시를 잘못 해석하여 엉뚱한 도구를 사용하는 기술적 문제인 '기능 호출 환각(function-calling hallucination)'은, 에어캐나다 사례처럼 고객에게 잘못된 정책 정보를 제공하는 윤리적, 법적 실패로 직접 이어집니다. 기술적 문제인 '신뢰성 부족'이 '자율성'이라는 매개를 통해 '책임 소재의 문제'라는 윤리적 문제를 야기합니다.

하지만 단순히 더 나은 기술을 개발하는 것만으로는 해결되지 않습니다. 기술 개발과 동시에, 에이전트가 <span style="background:#fff88f">안전하게 작동할 수 있는 강력한 '거버넌스 및 감독 프레임워크'를 구축</span>하는 것이 새로운 핵심 역량으로 부상하고 있습니다. 이 프레임워크는 다음과 같은 다층적 접근을 요구합니다.

1. **기술적 안전장치(Technological Guardrails):** 환각 탐지기, 편향 감사 도구, 보안 코드 실행 환경 등 <u>에이전트의 오류와 악용을 기술적으로 방지하는 시스템</u> 내장
2. **조직적 책임(Organizational Accountability):** 에이전트의 행동에 대한 명확한 인간 책임자를 지정하고, 윤리 위원회를 설치하며, 중요한 결정에는 반드시 <span style="background:#fff88f">인간이 개입(human-in-the-loop)하거나 감독(human-on-the-loop)하는 프로세스</span> 수립
3. **규제 준수(Regulatory Alignment):** EU의 AI 법(AI Act)과 같이 새롭게 등장하는 규제에 선제적으로 대응하고, 투명성과 문서화를 시스템 설계 초기부터 고려

## 마치며

이번 포스트를 작성하면서 강화 학습이나 멀티 에이전트가 이전부터 있었던 개념임을 알았습니다. 새로운 개념 뿐만 아니라, 기존의 개념을 기술의 발전에 맞게 구현하는 것도 큰 가치를 가져올 수 있다고 느꼈습니다.

그리고 위의 내용 중, 뛰어난 범용 지능보다 "주어진 지능을 더 정교하게 조율하여 실질적인 가치를 창출"하는 것이 경쟁의 핵심이라는 내용이 특히 인상 깊었습니다. 저 역시 에이전트를 개발하는 프로젝트에서, 상태 머신을 구현하여 추론을 보조하거나 계획 단계를 추가했을 때 더 높은 성능을 관찰할 수 있었기에 더욱 공감했습니다.

언급된 에이전트의 사례들을 보면, 공통적으로 데이터를 기반으로 판단, 분석 등을 수행하여 사용자에게 알리거나 초안을 작성하고 있습니다. 각 산업의 데이터와 결합할 때 가치가 더 극대화되는 것으로 보이며, 그럼에도 에어캐나다의 사례와 같이 100% 신뢰할 수는 없기에 보조의 역할까지만 수행하고 사람이 개입하는 것이 적절할 것으로 보입니다. 

지금까지 에이전트를 구현할 때는 속성 중 학습 능력에 대한 고민이 부족했습니다. 앞으로의 목표로 사용 데이터를 수집하고, 이를 에이전트에 반영하여 서비스 품질을 개선할 방법을 고민하려 합니다.

> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.