---
title: MCP의 개념
description: MCP는 어떤 문제를 해결하기 위해 등장했을까요? MCP에 대해 알아봅시다.
date: 2025-08-11T19:03:00
lastmod: 2025-09-09
slug: concept
comments: true
math: false
categories:
  - Systems
tags:
  - MCP
  - LLM
keywords:
  - MCP
  - Agents
  - LLM
---
## 개요

MCP 이전에도 LLM은 도구를 사용하고 있었고, 외부 데이터에 접근하고 있었습니다. 그렇다면 MCP는 어떤 문제를 해결하기 위해 등장했을까요?

MCP가 등장하기 전에는, M개의 AI 모델을 N개의 외부 도구 또는 데이터 소스에 연결하기 위해 각각의 통합, 즉 M×N개의 커넥터를 개발해야 했습니다. 그리고 각각의 맞춤형 커넥터는 개발, 테스트, 유지보수, 보안 검토를 위해 재사용이 불가능한 상당한 엔지니어링 자원을 요구했습니다. 이는 재사용이 불가능하고 감사가 어려웠으며, 기반이 되는 API나 모델이 업데이트될 때마다 쉽게 손상되어 단편적이고 예측 불가능한 시스템을 만들었고, "높은 통합 비용과 개발자 오버헤드", "중복된 개발 노력", 그리고 "과도한 유지보수 부담"으로 이어졌습니다. (이 문제를 'M×N 문제'라고 합니다.) 이 문제는 소프트웨어 개발의 비효율성을 넘어 AI 시스템의 확장을 근본적으로 저해하는 장벽이었습니다.

이 포스트에서는 MCP가 어떤 특징을 갖고, 어떤 변화를 가져왔는지 살펴보겠습니다.

## MCP의 특징


### 원칙

MCP는 핵심 원칙들에 기반합니다.

- **상호 운용성 (Interoperability):** 벤더 종속성(vendor lock-in)을 깨고 <span style="background:#fff88f">MCP를 준수하는 모든 모델이 MCP를 준수하는 모든 도구와 작동</span>할 수 있도록 합니다.
- **구성 가능성 (Composability):** 개발자들이 모듈식 "플러그 앤 플레이" 방식으로 도구와 데이터 소스를 결합하여 복잡하고 다단계적인 에이전트 워크플로우를 쉽게 구축할 수 있도록 합니다.
- **발견 가능성 (Discoverability):** AI 에이전트가 사전에 프로그래밍된 지식 없이도 런타임에 <span style="background:#fff88f">서버에 동적으로 질의</span>하여("어떤 도구를 제공하나요?") 그 능력을 파악하고, 더 큰 적응성을 가능하게 합니다. 이는 특히 정적인 API와의 핵심적인 차이점입니다.

### 아키텍처

MCP는 네 가지 핵심 구성 요소로 이루어집니다: 

- **호스트(Host):** Claude Desktop이나 IDE와 같이 여러 클라이언트를 관리하고 사용자 권한을 집행하는 조정자 역할의 <span style="background:#fff88f">LLM 애플리케이션</span>입니다.
- **클라이언트(Client):** 단일 서버와 1:1 <span style="background:#fff88f">상태 저장(stateful) 연결을 유지</span>하는 전용 커넥터입니다. 메시지 라우팅, 프로토콜 버전 협상, 서버의 기능 관리 등을 책임집니다.
- **서버(Server):** 외부 세계의 기능(`tools`, `resources`, `prompts`)을 <span style="background:#fff88f">AI 모델에게 노출</span>하는 구성 요소입니다.
- **기본 프로토콜(Base Protocol):** 이들 구성 요소 간의 통신 규칙을 정의합니다.

이 아키텍처의 핵심은 **결합성(Composability)** 입니다. 하나의 애플리케이션이 <u>클라이언트와 서버 역할을 동시에 수행할 수 있어</u>, 계층적인 에이전트 시스템 구축이 가능합니다. 예를 들어, 주 에이전트(클라이언트)가 특정 작업을 전문 하위 에이전트(서버)에게 위임하고, 이 하위 에이전트는 다시 다른 MCP 서버(파일 시스템 서버 등)의 클라이언트가 되어 필요한 도구를 호출하는 복잡한 워크플로우를 구성할 수 있습니다.

### 통신

MCP는 구조화된 통신을 위해 명확한 역할을 가진 클라이언트-서버 모델을 채택합니다.

클라이언트는 서버와 일대일 연결을 유지하며, 안전하고 격리된 통신 채널 역할을 합니다. 호스트가 요청을 조율하지만, 모든 통신은 클라이언트를 통해 중개됩니다. 이는 서버와 호스트가 직접 통신하지 않도록 보장하는 핵심적인 보안 설계 원칙입니다.

MCP는 클라이언트와 서버 간의 연결에 대해 예측 가능한 동작을 보장하기 위해 엄격한 3단계 생명주기를 강제합니다.

1. **초기화(Initialization):** 클라이언트와 서버가 서로 지원하는 프로토콜 버전과 기능을 교환하고 협상합니다. 이는 런타임에 사용 가능한 기능을 동적으로 발견하고 호환성을 보장하는 매우 중요한 단계입니다.
2. **작동(Operation):** 협상된 기능의 범위 내에서 정상적인 통신이 이루어집니다.
3. **종료(Shutdown):** 연결을 정상적으로 종료하는 절차를 따릅니다.

RESTful API과 같은 기존 API는 <u>상태 비저장(stateless) 방식으로 작동</u>합니다. 각 요청은 이전 요청과 독립적으로 처리되며, 클라이언트가 여러 단계에 걸친 <u>작업의 상태와 컨텍스트를 스스로 관리해야 합니다.</u> 이는 간단한 데이터 조회 수준이 아닌 여러 단계의 <u>상호작용이 필요한 복잡한 작업을 수행하는 AI 에이전트에게 상당한 부담</u>으로 작용합니다. 에이전트 또는 클라이언트 측 오케스트레이터가 <u>모든 상태를 기억하고 매 요청마다 전체 컨텍스트를 다시 전송</u>해야 하므로, 이는 비효율적이고 시스템을 취약하게 만드는 원인이 됩니다.

반면, MCP는 **상태를 유지하는(stateful) 영속적인 연결(persistent connections)** 을 기반으로 설계되었습니다. 이는 일련의 개별적인 요청-응답이 아닌, 마치 <span style="background:#fff88f">웹소켓(WebSocket) 세션과 유사한 지속적인 양방향 통신 채널을 구축</span>하는 것을 의미합니다. 이러한 상태 유지 연결은 다단계 작업 수행에 있어 결정적인 장점을 가집니다. 서버는 <span style="background:#fff88f">진행 중인 워크플로우의 컨텍스트를 세션 내에서 유지</span>할 수 있으므로, 클라이언트는 매번 전체 컨텍스트를 다시 보낼 필요가 없습니다. MCP 로드맵에서도 <u>연결 끊김 및 재연결에 대한 탄력적인 처리와 장기 실행 작업을 지원하는 것이 핵심 우선순위</u>로 명시되어 있으며, 이는 상태 유지의 중요성을 다시 한번 강조합니다.

이러한 아키텍처적 선택은 단순한 기술적 편의를 넘어, 에이전트와 도구 간의 상호작용 모델을 단순한 '요청-응답'에서 **'대화형 상호작용' 모델**로 전환시킵니다. 이는 고급 에이전트 행동을 위한 필수 전제 조건입니다. 상태 비저장 API가 LLM이나 복잡한 클라이언트 측 오케스트레이터를 유일한 상태 관리자로 만드는 반면, 상태 유지 연결은 이러한 인지적 부담의 일부를 도구 서버로 오프로드합니다. 이를 통해 <span style="background:#fff88f">도구 자체가 메모리를 가지고 에이전트를 특정 프로세스로 안내하는 등 훨씬 더 정교한 상호작용이 가능</span>해집니다. 이러한 설계는 도구에서 <u>더 이상 수동적으로 호출되는 함수가 아니라, 문제 해결 과정에 능동적으로 참여하며 에이전트과 협업하는 주체</u>가 됩니다. 

상태 비저장 API는 거래적(transactional)입니다. 에이전트가 도구에게 개별적인 행동을 명령하면, 과거 상호작용에 대한 기억이 없는 도구는 그저 명령을 수행합니다. 그러나 MCP의 상태 유지 연결은 서버가 세션의 컨텍스트를 "기억"할 수 있음을 의미합니다. 예를 들어, "순차적 사고(Sequential Thinking)" 서버는 동적인 문제 해결 과정을 추적할 수 있습니다. 여기에 더해 `Elicitation` 및 `Sampling`과 같은 서버 주도 상호작용 기능은 <u>서버가 통신을 시작하여 에이전트에게 추가 정보를 요청하거나 추론 작업을 수행하도록 요청</u>할 수 있게 합니다. 이는 강력한 피드백 루프를 형성합니다. 에이전트가 도구에 도움을 요청하면, 도구는 자체 상태와 전문화된 로직을 사용하여 추가 정보가 필요하다고 판단하고 에이전트에게 다시 질문(`Elicitation`)하거나, 창의적인 단계가 필요하다고 판단하여 에이전트에게 텍스트 생성을 요청(`Sampling`)할 수 있습니다. 결과적으로 복잡한 문제를 해결하는 데 필요한 인지적 부하가 분산됩니다. LLM은 일반적인 추론과 언어를 처리하고, 전문화된 MCP 서버는 <span style="background:#fff88f">도메인 특화 로직, 상태 및 상호작용 흐름을 처리</span>합니다. 이 협력 모델은 LLM이 모든 것을 관리해야 하는 모델보다 훨씬 더 강력하고 효율적입니다.

### 전송 계층

프로토콜 자체는 가볍고 널리 이해되는 원격 프로시저 호출 프로토콜인 **JSON-RPC 2.0**을 기반으로 구축되었습니다. MCP는 다양한 배포 시나리오를 지원하기 위해 전송 계층을 유연하게 설계했으며, 그 발전 과정은 프로토콜의 적용 범위 확대를 명확히 보여줍니다.

- **STDIO (Standard Input/Output):** 가장 초기의 단순한 전송 방식으로, 클라이언트와 서버가 동일한 환경에서 실행되는 <span style="background:#fff88f">로컬 프로세스 통합에 이상적</span>입니다.6 예를 들어, IDE(호스트)가 로컬 파일 시스템에 접근하는 서버와 통신하는 경우에 사용됩니다. STDIO의 가장 큰 강점은 기존의 원격 전용 API(예: REST)가 쉽게 복제할 수 없는 로컬 우선(local-first) 에이전트 워크플로우를 가능하게 한다는 점입니다.
- **HTTP와 서버-전송 이벤트 (SSE):** 원격 연결을 위해 처음 도입된 메커니즘으로, 서버가 클라이언트에게 비동기적으로 알림을 푸시할 수 있게 했습니다.6 하지만 SSE는 장시간 연결을 유지해야 하는 특성 때문에 기업 방화벽에 의해 차단되거나, AWS Lambda와 같은 상태 비저장(stateless) 클라우드 함수 환경에서는 사용하기 어렵고, 역압력(back-pressure) 처리가 <u>까다로운 문제점</u>을 드러냈습니다.
- **스트리밍 가능한 HTTP (Streamable HTTP):** 2025년 3월 업데이트에서 도입된 현재의 표준 원격 통신 방식입니다.3 이 방식은 청크 분할 전송 인코딩(chunked transfer encoding)을 지원하는 단<u>일 HTTP 요청을 통해 양방향 바이트 스트림을 터널링</u>합니다. 이는 MCP의 실용성을 극적으로 향상시킨 핵심적인 발전이었습니다. 이 방식을 통해 MCP 서버를 <span style="background:#fff88f">상태 비저장 클라우드 함수로 배포</span>할 수 있게 되었고, 일반적인 <span style="background:#fff88f">기업 네트워크 프록시 문제를 우회</span>할 수 있어, MCP가 프로덕션 등급의 클라우드 네이티브 애플리케이션에 적용될 수 있는 길을 열었습니다.
- **WebSocket:** 최대의 상호작용성이 요구되는 시나리오를 위한 전송 방식으로 언급되며, 완전한 양방향(full-duplex) 통신을 제공합니다. 이는 스트리밍 데이터, 진행 상황 업데이트, 협업 상호작용 등이 포함된 복잡한 AI 워크플로우에 특히 유용할 수 있습니다.


| **전송 방식**       | **주요 사용 사례**             | **통신 모델**            | **지연 시간** | **확장성**     | **네트워크 호환성**     | **현재 상태**            |
| --------------- | ------------------------ | -------------------- | --------- | ----------- | ---------------- | -------------------- |
| STDIO           | 로컬 프로세스 간 통신 (예: 데스크톱 앱) | 양방향                  | 매우 낮음     | 제한적 (단일 머신) | 해당 없음 (로컬)       | 활성                   |
| HTTP + SSE      | 초기 원격 연결                 | 단방향 (서버→클라이언트)       | 낮음-중간     | 중간          | 표준 HTTP/S 포트     | 사용되지 않음 (Deprecated) |
| Streamable HTTP | 원격/클라우드 배포               | 양방향 (단일 연결)          | 낮음-중간     | 높음          | 표준 HTTP/S 포트     | **현재 표준**            |
| WebSocket       | 고도의 실시간 상호작용             | 완전 양방향 (Full-duplex) | 매우 낮음     | 높음          | 별도 프로토콜/포트 필요 가능 | 고려 대상                |


### 데이터 교환

단순한 함수 호출 API는 모든 외부 상호작용을 "이것을 하라"는 명령으로 취급합니다. 이는 맥락에 대한 일차원적인 시각입니다.

MCP는 맥락을 전달하기 위해 기능보다 더 세분화된 표현 단위인 프리미티브를 사용합니다. 이는 <u>기능 목록이 아니라</u>, <span style="background:#fff88f">AI와 시스템 간의 통신을 위한 구조화된 문법</span>입니다. 이는 맥락 뿐만 아니라 <u>맥락의 의도를 전달하는 것이 중요</u>하다는 철학을 아키텍처적으로 구현한 것입니다.

#### 서버의 프리미티브

핵심은 세 가지 프리미티브를 통한 표준화된 상호작용입니다: **Tools(실행 가능한 함수)**, **Resources(구조화된 읽기 전용 데이터)**, 그리고 **Prompt Templates(사전 정의된 지침)**. 일반적으로 도구는 모델이 제어하고, 리소스와 프롬프트는 사용자가 제어합니다.

- **도구 (Tools):** <u>API를 호출하거나, 데이터베이스에 쿼리를 보내거나, 계산을 수행</u>하는 등 <span style="background:#fff88f">행동을 수행</span>하고 <u>부수 효과(side effect)</u>를 가질 수 있는 실행 가능한 함수입니다. 이는 **행동하려는 의도(intent to act)** 를 나타냅니다.
- **리소스 (Resources):** <u>파일의 내용, API 응답 결과, 데이터베이스 레코드</u> 등 같이 모델의 컨텍스트를 풍부하게 하기 위해 제공되는 구조화된 <span style="background:#fff88f">읽기 전용 데이터</span>입니다. 이는 **정보를 제공하려는 의도(intent to inform)** 를 나타냅니다.
- **프롬프트 (Prompts):** 특정 작업을 위해 <span style="background:#fff88f">모델의 추론을 안내</span>할 수 있는 재사용 가능한 사전 정의된 지침 템플릿입니다. 이는 **안내하려는 의도(intent to guide)** 를 나타냅니다.

이러한 의도 분리로 더 정교한 시스템 설계가 가능합니다. 예를 들어, 보안에 민감한 애플리케이션은 에이전트에게 민감한 데이터베이스의 `Resources`(읽기 전용 데이터)에 대한 접근은 허용하되, 데이터를 수정할 수 있는 `Tools`(행동)에 대한 접근은 거부할 수 있습니다. 단순한 함수 호출 인터페이스는 이를 명확하게 표현하기 어렵습니다. 이 문법은 시스템이 AI에게 "여기 읽을 데이터가 있다", "여기 네가 취할 수 있는 행동이 있다", "이 문제는 이렇게 접근해야 한다"와 같이 미묘한 지시를 전달하여, LLM과 보다 정교하게 통신합니다.

| **프리미티브**          | **철학적 의도**          | **기술적 기능**          | **사용 사례 예시**                                     |
| ------------------ | ------------------- | ------------------- | ------------------------------------------------ |
| **도구 (Tool)**      | 행동하기 (To Act)       | 부수 효과가 있는 실행 가능한 함수 | `post_message_to_slack`, `create_calendar_event` |
| **리소스 (Resource)** | 정보 제공하기 (To Inform) | 구조화된 읽기 전용 데이터      | 재무 보고서 PDF, 데이터베이스 스키마, 사용자 프로필                  |
| **프롬프트 (Prompt)**  | 안내하기 (To Guide)     | 재사용 가능한 지침 템플릿      | 법률 문서 요약 템플릿, 코드 리팩토링 지침                         |

#### 클라이언트의 프리미티브

서버보단 사용 빈도가 낮지만, 클라이언트도 프리미티브를 가집니다.

- **루트 (Roots):** 서버가 허가를 받아 접근할 수 있는 호스트의 로컬 환경(예: 파일 시스템 디렉토리)에 대한 진입점입니다.
- **샘플링 (Sampling):** 서버가 <span style="background:#fff88f">클라이언트의 LLM에게 추론 작업(예: 텍스트 생성, 콘텐츠 요약)을 수행하고 그 결과를 반환하도록 요청</span>할 수 있습니다. 서버는 모델, 시스템 프롬프트, temperature와 같은 매개변수를 지정할 수 있습니다. Python SDK는 이를 위해 `ctx.session.create_message` 메서드를 제공합니다. 이 기능은 전문화된 도구가 범용 추론이나 창의적 능력을 가진 호스트 LLM을 활용할 수 있게 하여, 도구가 다른 도구를 사용하는 것과 같은 구성 가능한 시스템을 만듭니다. 여기서 LLM은 일종의 "추론 도구" 역할을 하게 됩니다.
- **채록 (Elicitation):** 서버가 워크플로우를 일시 중지하고, 클라이언트를 통해 최종 <span style="background:#fff88f">사용자에게 추가적인 구조화된 정보를 요청</span>할 수 있습니다. 서버는 필요한 입력에 대한 스키마를 정의합니다. Python SDK 예제에서는 `book_table` 도구가 특정 날짜에 예약이 불가능할 경우 `ctx.elicit`을 사용하여 사용자에게 대체 날짜를 묻는 것을 보여줍니다. 이 기능은 에이전트가 중요한 결정 지점에서 사용자에게 명확한 설명이나 승인을 요청할 수 있는 <u>"인간 참여형(human-in-the-loop)" 워크플로우를 구현</u>하는 공식적인 메커니즘입니다.

#### 활용

MCP의 핵심 원칙 중 하나는 **구조화된 컨텍스트**의 사용입니다. <u>기존 REST API의 응답을 그대로 LLM의 컨텍스트 창에 주입하면, 불필요한 정보로 인해 토큰이 낭비되고 모델의 추론 능력이 저하</u>될 수 있습니다. MCP는 **구조화된 도구 출력(Tool Output Schema)** 과 같은 기능을 통해 이 문제를 해결합니다. 서버는 반환할 데이터의 형태를 미리 선언하고, LLM에게는 작업과 관련된 간결하고 구조화된 객체만 전달하여 토큰 효율성을 높이고 모델이 정보를 더 효과적으로 파싱하도록 돕습니다.

또한 정적인 데이터 교환을 넘어 **동적 컨텍스트** 처리를 지원합니다. **구독 가능한 리소스(Subscribable Resources)** 는 기반 <u>데이터가 변경될 때마다 클라이언트에게 알림을 보내 재처리를 유발</u>할 수 있으며, **샘플링된 리소스(Sampled Resources)** 는 <u>대규모 데이터 소스에서 요약 정보를 추출하는 데 사용</u>될 수 있습니다. 특히 **샘플링(Sampling)** 기능은 서버가 클라이언트 측의 LLM에게 특정 프롬프트에 대한 응답 생성을 요청할 수 있게 하여, 단순한 요청-응답 패턴을 넘어서는 진정한 의미의 양방향 대화를 가능하게 합니다. 이는 MCP를 다른 프로토콜과 차별화하는 핵심적인 특징입니다.

## 다른 기술과의 통합

MCP는 기존 기술 스택을 완전히 대체하기보다는 <span style="background:#fff88f">보완하고 확장하는 역할</span>에 가깝습니다. 다른 기술과 비교하여, 그 독자적인 가치와 기술 생태계 내에서의 전략적 위치를 명확히 규명합니다.

### MCP vs. REST/GraphQL: 상태, 발견, 컨텍스트의 패러다임 전환

MCP와 REST/GraphQL 같은 전통적 API는 근본적으로 다른 목적을 위해 설계되었습니다. 이 둘의 차이는 상태 관리, 서비스 발견, 그리고 컨텍스트 처리 방식에서 패러다임의 전환을 보여줍니다.

- **목적의 차이:** 전통적인 API는 주로 <u>애플리케이션 간의 통신</u>을 위해 설계되었으며, 애플리케이션이 처리할 구조화된 **데이터(data)** 를 반환합니다. 반면, MCP는 AI, 특히 LLM을 위해 제작되었습니다. MCP 서버는 LLM이 추론하는 데 필요한 **컨텍스트(context)** 를 제공하는 것을 목표로 합니다. 예를 들어, REST API가 10KB 크기의 방대한 JSON 객체를 반환한다면, 잘 설계된 MCP 서버는 LLM의 컨텍스트 창에 최적화된 간결하고 작업 관련성이 높은 <span style="background:#fff88f">요약 정보를 제공</span>할 것입니다.
- **발견(Discovery) 방식:** REST나 GraphQL API는 정적입니다. 개발자는 OpenAPI 명세서와 같은 문서를 사전에 읽고 학습해야만 해당 API를 사용할 수 있습니다. 이와 대조적으로, MCP는 동적인 런타임 발견을 지원합니다. MCP 클라이언트는 서버에 `tools/list`와 같은 요청을 보내 사전 지식 없이도 해당 <u>서버가 제공하는 기능 목록과 사용법을 실시간으로 파악</u>할 수 있습니다. 이는 AI 에이전트가 보다 자율적이고 적응적으로 동작할 수 있게 하는 핵심 기능입니다.
- **통신 패턴:** REST는 각 요청이 독립적으로 처리되는 상태 비저장(stateless) 방식입니다. MCP는 <u>세션 기반의 양방향(bidirectional) 통신 모델</u>을 채택하여 여러 상호작용에 걸쳐 <span style="background:#fff88f">컨텍스트를 유지</span>합니다. 이는 여러 단계로 구성된 복잡한 에이전트 워크플로우를 수행하는 데 필수적입니다.
- **상호 관계:** MCP는 REST를 대체하는 기술이 아니라는 것입니다. 오히려 MCP는 기존 API 위에 구축되는 **보완적인 추상화 계층**입니다. 실제로 많은 MCP 서버는 기존 <span style="background:#fff88f">REST API를 AI 친화적으로 감싸는 래퍼(wrapper) 역할</span>을 합니다. 예를 들어, GitHub MCP 서버는 내부적으로 <u>GitHub의 REST API를 호출하여 MCP의 표준화된 형식으로 변환한 후 클라이언트에게 제공</u>합니다.

| **특징/원칙**   | **모델 컨텍스트 프로토콜 (MCP)**  | **전통적인 REST API** |
| ----------- | ----------------------- | ----------------- |
| **표준화**     | 개방형, 범용 표준              | 표준 부재 (각 API가 고유) |
| **발견 메커니즘** | 동적, 런타임에 질의 가능          | 정적, 문서를 통해 파악     |
| **주요 목적**   | AI 모델과 외부 시스템 간의 맥락 교환  | 범용 소프트웨어 간 통신     |
| **생태계 모델**  | 개방형, 커뮤니티 주도, 상호 운용 가능  | 단편화된, 개별적 통합      |
| **맥락의 풍부함** | 도구, 리소스, 프롬프트를 통한 의도 전달 | 주로 데이터 검색/조작에 초점  |


### MCP vs. gRPC: 성능, 스키마, 그리고 LLM 친화성에 대한 고찰

gRPC는 고성능 마이크로서비스 통신을 위해 설계된 반면, MCP는 LLM과의 상호작용에 최적화되어 있습니다. 이 둘의 비교는 성능과 LLM 해석 가능성 사이의 중요한 트레이드오프를 보여줍니다.

- **성능 vs. 해석 가능성:** gRPC는 고효율의 바이너리 직렬화 포맷인 프로토콜 버퍼(Protocol Buffers)와 HTTP/2를 사용하여 <u>기계 간 통신 성능을 극대화</u>합니다. 반면 MCP는 <span style="background:#fff88f">LLM의 해석 가능성을 우선시</span>합니다. 이를 위해 사람이 쉽게 읽고 이해할 수 있는 JSON 형식을 사용하며, 스키마 내에 자연어 설명과 사용 지침을 포함시킵니다. 이 덕분에 LLM은 별도의 변환 계층 없이도 도구의 목적과 매개변수를 훨씬 쉽게 이해할 수 있습니다.
- **스키마 및 계약:** 두 기술 모두 강력한 타입의 스키마를 사용합니다. gRPC는 프로토콜 버퍼를 통해 엄격한 서비스 계약을 정의합니다. MCP 역시 JSON-RPC 2.0 기반의 정의된 스키마를 사용하지만, 여기에 <span style="background:#fff88f">자연어 프롬프트와 설명이라는 추가적인 의미 계층</span>을 더합니다.

### MCP vs. OpenAI 함수 호출: '인프라'와 '의도'의 상호보완적 관계

MCP와 OpenAI의 함수 호출(Function Calling)은 경쟁 관계가 아니라, 서로 다른 역할을 수행하는 상호보완적인 관계입니다.

- **핵심적인 차이:** 함수 호출은 **'의도(intent)'** 에 해당합니다. LLM이 <u>특정 작업을 수행해야 할 필요성을 인식</u>하고, 필요한 매개변수를 구조화된 형식으로 출력하는 메커니즘입니다. 반면, MCP는 **'인프라(infrastructure)'** 입니다. MCP는 LLM이 표현한 의도를 받아, 실제 작업을 <span style="background:#fff88f">발견하고, 실행하며, 관리하</span>는 표준화된 프로토콜입니다.
- **표준화 문제:** <u>함수 호출의 형식은 각 LLM 제공사(OpenAI, Anthropic, Google 등)마다 다릅니다.</u> MCP를 사용하면 각 도구는 단 하나의 MCP 서버만 구현하면 되고, MCP와 호환되는 모든 모델이 이를 사용할 수 있습니다.
- **아키텍처:** 함수 호출에 사용되는 도구는 일반적으로 단일 애플리케이션 내에 하드코딩되어 정의됩니다. MCP는 도구가 그것을 소비하는 애플리케이션과 분리된, <u>재사용 가능한 별도의 서버에 존재하는 분산 아키텍처</u>를 장려합니다.
- **시너지:** 이 둘은 함께 작동합니다. LLM은 자신의 고유한 함수 호출 기능을 사용하여 요청을 생성합니다. 그러면 MCP 클라이언트가 이 요청을 받아 표준화된 프로토콜을 통해 적절한 MCP 서버로 전송하여 실행합니다.

이러한 비교 분석을 통해 MCP의 핵심 가치 제안이 특정 기술적 축에서의 우월성이 아니라, **표준화를 통한 통합 마찰의 감소**에 있음을 알 수 있습니다. gRPC보다 빠르거나 단일 REST 호출보다 단순하지는 않지만, M×N 문제를 해결함으로써 전체 생태계의 <span style="background:#fff88f">개발 효율성을 향상</span>시킵니다. MCP는 기존 기술 스택을 대체하는 것이 아니라, 그 위에 새로운 가치를 창출하는 <span style="background:#fff88f">추상화 계층</span>으로 위치합니다. 이는 MCP와 기존 기술 사이에서 양자택일할 필요 없이, MCP를 새로운 계층으로 활용하여 시스템을 강화하는 전략을 고려해야 함을 의미합니다.

## MCP의 방향

### 변경 사항

- **초기 안정화 (2024-11-05):** 최초 공개된 버전은 MCP의 핵심 개념을 정립하는 데 중점을 두었습니다. JSON-RPC 2.0 기반의 메시지 형식과 함께, 프로토콜의 핵심 프리미티브(primitive)인 `tool`(도구), `resource`(리소스), `prompt`(프롬프트)가 정의되었습니다. 이 시점에서는 스트리밍 통신을 위한 전송 방식으로 HTTP와 서버-전송 이벤트(Server-Sent Events, SSE)를 채택했는데, 이는 실시간 대화형 사용 사례에 초기 초점을 맞추었음을 시사합니다.
- **엔터프라이즈 및 보안 강화 (2025-03-26):** 이 버전은 MCP가 본격적으로 엔터프라이즈 시장을 겨냥하기 시작했음을 알리는 중요한 전환점입니다. 가장 주목할 만한 변화는 <span style="background:#fff88f">OAuth 2.1 기반의 포괄적인 인증 프레임워크 도입</span>입니다.1 이는 기업 환경에서 필수적인 강력한 보안 및 신원 관리 요구사항을 충족시키기 위한 결정이었습니다. 또한, 기존 SSE 방식이 가진 기업 방화벽 및 프록시 환경에서의 호환성 문제를 해결하기 위해, 보다 유연하고 견고한 **스트리밍 가능한 HTTP(Streamable HTTP)** 전송 방식으로 대체되었습니다. 더불어, 도구의 속성을 명시하는 `tool annotations`(예: 읽기 전용, 파괴적 행위) 기능과 오디오 콘텐츠 지원이 추가되어, 더욱 풍부하고 제어된 상호작용이 가능해졌습니다. 성능 최적화를 위해 JSON-RPC 일괄 처리(batching) 기능이 잠시 도입되었다가 이후 버전에서 철회되었는데, 이는 프로토콜의 효율성과 단순성 사이에서 균형점을 찾으려는 시도가 있었음을 보여줍니다.
- **정제 및 보안 강화 (2025-06-18):** 가장 최신 릴리스는 프로토콜의 완성도를 높이고 보안을 한층 더 강화하는 데 집중했습니다. 일괄 처리 기능을 제거하여 프로토콜의 복잡성을 낮추고 구현을 단순화했습니다. 핵심적인 추가 사항은 예측 가능한 통합을 위한 구조화된 도구 출력(structured tool output)과, MCP 서버를 OAuth 리소스 서버로 분류하고 토큰 오용을 방지하기 위해 리소스 표시자(Resource Indicators, RFC 8707) 사용을 의무화한 것입니다. 이는 '혼란된 대리인(confused deputy)' 문제와 같은 실제적인 보안 위협에 대한 깊은 이해를 바탕으로 한 조치입니다. 또한, 서버가 사용자에게 요청을 시작할 수 있는 유도(elicitation) 기능이 추가되어 프로토콜의 양방향 상호작용성이 더욱 강화되었습니다.

이러한 프로토콜의 발전 과정은 우연이 아닙니다. 초기에는 개발자 커뮤니티의 지지를 확보하는 데 주력하고, 이후에는 기업 고객의 엄격한 보안 및 운영 요구사항을 충족시키는 방향으로 명확하게 전환하는 전략적 움직임을 보여줍니다. 이는 MCP가 단기적인 유행이 아닌, 장기적으로 지속 가능한 표준으로 자리매김하려는 의도를 명백히 드러냅니다.

| 버전 (릴리스 날짜) | 주요 기능 및 향상점                                                                                                                                         | 주요 변경 사항 (Breaking Changes) | 전략적 중요성                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| **2024-11-05**     | • 핵심 아키텍처 및 메시지 형식 정의 (JSON-RPC 2.0) • `tool`, `resource`, `prompt` 프리미티브 도입 • HTTP + SSE 기반 스트리밍 전송                           | 해당 없음 (초기 버전)             | 개발자 중심의 초기 생태계 구축 및 핵심 개념 정립. 대화형 AI 에이전트의 기본 기능 지원에 초점.                 |
| **2025-03-26**     | • OAuth 2.1 기반 인증 프레임워크 추가 • `tool annotations` (읽기 전용, 파괴적 등) 도입 • 오디오 콘텐츠 지원 추가                                            | • SSE를 Streamable HTTP로 대체    | 엔터프라이즈 도입의 핵심 장벽인 보안 및 네트워크 호환성 문제 해결. 프로토콜의 적용 범위를 기업 환경으로 확장. |
| **2025-06-18**     | • `structured tool output` 지원 • MCP 서버를 OAuth 리소스 서버로 분류 • Resource Indicators (RFC 8707) 요구 • 서버 주도 요청을 위한 `elicitation` 기능 추가 | • JSON-RPC 일괄 처리 기능 제거    | '혼란된 대리인' 등 정교한 보안 위협에 대응하여 프로토콜을 강화. 프로토콜의 단순성과 보안성을 동시에 향상.     |

### 현재 보고된 문제점

하지만 앞의 발전 외에도, 사용자들은 MCP에 대해 다음의 문제들을 보고하고 있습니다.

- **멀티테넌시(Multi-Tenancy):** 많은 사용자가 공유 서버에 안전하게 접근해야 하는 멀티테넌트 SaaS 아키텍처를 위해 설계되지 않았습니다. 이는 많은 엔터프라이즈 사용 사례에 주요한 장애물입니다.
- **디버깅 및 관찰 가능성:** 개발자들은 MCP 통합을 디버깅하는 것이 매우 어렵다고 보고합니다. 클라이언트 측 추적이 종종 누락되거나 접근하기 어렵고, 각 클라이언트마다 고유한 특성이 있기 때문입니다.
- **발견 및 신뢰:** 서버를 발견할 수는 있지만, 신뢰성을 검증할 중앙화된 신뢰할 수 있는 레지스트리가 없습니다. 이는 에이전트가 신뢰할 수 없거나 악의적인 서버에 연결될 위험을 초래하며, 향후 개발의 핵심 영역입니다.
- **워크플로우 오케스트레이션:** MCP에는 복잡한 다단계 워크플로우를 관리하기 위한 기능이 부족하여, 클라이언트의 <u>재시도나 재개 가능성과 같은 로직을 직접 구현</u>해야 합니다.

| **영역**      | **구체적인 과제**          | **잠재적 미래 방향 / 연구 분야**                |
| ----------- | -------------------- | ------------------------------------ |
| **거버넌스**    | 내장된 세분화된 권한 모델 없음    | 사양에 권한 모델 도입, 제3자 PAM 솔루션과의 표준 통합    |
| **운영 확장성**  | 멀티테넌시 지원 부족          | 멀티테넌트 서버 아키텍처를 위한 패턴 정의              |
| **생태계 건전성** | 신뢰할 수 있는 서버 레지스트리 부재 | 커뮤니티가 관리하는 검증된 레지스트리 구축              |
| **개발자 경험**  | 디버깅 및 워크플로우 관리의 복잡성  | 표준화된 디버깅 도구 및 워크플로우 오케스트레이션 프리미티브 도입 |

MCP에서는 이러한 문제점을 어떻게 개선하고, 향후 어떻게 나아갈 것인지 살펴보겠습니다.

### 2025년 7월 공식 로드맵 분석: 에이전트, 보안, 멀티모달리티의 미래

- **에이전트 기능 강화:** 로드맵의 최우선 과제 중 하나는 <u>더 복잡한 에이전트 워크플로우를 지원</u>하는 것입니다. 특히 수 분에서 수 시간에 이르는 작업을 처리할 수 있는 **비동기 작업(asynchronous operations)** 지원이 핵심입니다. 이는 단순한 질의응답을 넘어 장기적인 목표를 수행하는 자율 에이전트 구현에 필수적인 기능입니다.
- **인증 및 보안 고도화:** 엔터프라이즈 도입을 위해 보안은 여전히 가장 중요한 영역입니다. 로드맵에는 **세분화된 권한 부여(fine-grained authorization)**, 사용자 경험을 해치지 않으면서 보안을 강화하기 위한 동적 클라이언트 등록(DCR)의 대안 탐색, 그리고 SSO(Single Sign-On)를 통한 **엔터프라이즈 관리형 인증(enterprise-managed authorization)** 기능 추가 계획이 포함되어 있습니다.
- **검증 및 레지스트리:** 생태계의 신뢰성과 확장성을 위해, 일관된 구현을 보장하는 **준수 테스트 스위트(compliance test suites)** 와 중앙에서 서버를 발견할 수 있는 **MCP 레지스트리(MCP Registry)** 개발이 계획되어 있습니다. 특히 레지스트리는 앤스로픽이 직접 운영하는 앱스토어 형태가 아니라, 서드파티 마켓플레이스가 그 위에 구축될 수 있는 API 계층으로 구상되고 있어 개방형 생태계를 지향함을 보여줍니다.
- **멀티모달리티 확장:** 현재의 텍스트와 이미지를 넘어, **비디오**와 같은 추가적인 데이터 양식(modality)을 지원하고, 대화형 경험을 위한 **스트리밍** 기능을 개선하여 AI의 전체 스펙트럼을 지원하는 것을 목표로 하고 있습니다.



### 커뮤니티 논의와 기술적 과제: A2A, gRPC 통합, 게이트웨이의 필요성

공식 로드맵 외에도, 커뮤니티에서는 MCP의 미래를 형성할 중요한 기술적 논의가 활발하게 이루어지고 있습니다.

- **MCP와 A2A (Agent-to-Agent Protocol):** 커뮤니티의 핵심 논의 중 하나는 MCP와 구글의 A2A 프로토콜 간의 관계입니다. 현재 지배적인 견해는 이 <span style="background:#fff88f">둘이 경쟁 관계가 아닌 상호 보완적</span>이라는 것입니다. MCP가 **에이전트와 도구(agent-to-tool)** 간의 통신을 표준화하는 반면, A2A는 **에이전트와 에이전트(agent-to-agent)** 간의 협업을 표준화하는 것을 목표로 합니다. 미래에는 A2A 프로토콜 기반의 에이전트가 자신의 도구를 사용하기 위해 내부적으로 MCP를 활용하는 구조가 될 수 있습니다.
- **gRPC 통합 가능성:** 커뮤니티에서는 기존의 JSON/HTTP 전송 방식 대신, gRPC의 높은 성능과 성숙한 생태계를 활용하자는 주장이 꾸준히 제기되고 있습니다. 이는 MCP가 향후 다양한 전송 계층을 지원하는 방향으로 발전할 수 있음을 시사합니다.
- **게이트웨이의 필연성:** 프로덕션 환경, 특히 <u>다중 테넌트나 기업 환경에서 보안, 관찰 가능성, 트래픽 관리를 위한 게이트웨이 계층의 필요성</u>은 전문가들 사이에서 거의 공통된 의견입니다. 게이트웨이는 MCP 핵심 명세에 포함되어 있지는 않지만, 사실상 안전한 배포를 위한 <span style="background:#fff88f">필수 구성 요소</span>로 인식되고 있습니다.

### MCP 생태계의 확장: 주요 플레이어, 시장, 그리고 인프라

- **주요 플레이어의 참여:** MCP의 가장 큰 성공 요인 중 하나는 주요 기업들의 지지입니다. Anthropic이 시작했지만, 경쟁사인 OpenAI, Google DeepMind, Microsoft가 신속하게 이를 채택했습니다. Microsoft는 Copilot Studio에 MCP를 통합하고 C# SDK를 공동으로 유지 관리하고 있으며 34, GitHub는 VS Code 내 MCP 지원을 정식 버전으로 출시했습니다. 이러한 '경쟁적 협력(coopetition)' 구도는 MCP가 단일 벤더에 종속되지 않는 사실상의 업계 표준으로 자리 잡을 가능성을 높여줍니다. 이는 특정 기업의 향방과 관계 없이 프로토콜의 장기적 안정성을 보장하므로, 다른 기업들의 채택 리스크를 크게 낮추는 효과가 있습니다.
- **SDK 및 서버 생태계:** 생태계는 폭발적으로 성장하고 있습니다. TypeScript, Python, Java, C#, Go, Rust, Ruby 등 주요 언어에 대한 공식 SDK가 제공되고 있으며, 이는 종종 Microsoft(C#), Google(Go)과 같은 파트너사와의 협력을 통해 개발됩니다. GitHub, Slack, 데이터베이스, Puppeteer 등 널리 사용되는 도구들을 위한 오픈소스 서버 저장소도 방대하게 구축되어 있습니다.
- **신흥 마켓플레이스와 인프라:** MCP를 중심으로 한 상업 생태계도 형성되고 있습니다. mcpmarket.com과 같이 사전 구축된 서버를 발견하고 사용할 수 있는 마켓플레이스와, MCP 서버의 구축 및 호스팅을 단순화하는 인프라 도구들이 등장하고 있습니다.39

### 장기적 비전: 자율 에이전트와 AI 네이티브 웹의 기반으로서의 MCP

MCP에 대한 장기적인 비전은 단순한 도구 통합을 훨씬 뛰어넘습니다. 이는 차세대 컴퓨팅을 위한 기반 프로토콜로 자리매김하는 것입니다.

- **자율 시스템의 기반:** MCP는 인간의 직접적인 개입 없이 기업의 리소스나 웹 서비스를 동적으로 발견하고, 학습하며, 상호작용할 수 있는 자율 에이전트 시스템에 필요한 핵심 패턴을 제공합니다.
- **에이전트 상거래와 AI 네이티브 웹:** 전문가들은 MCP가 **'AI 네이티브 웹(AI-Native Web)'** 을 가능하게 할 것이라고 전망합니다.10 과거 HTTP와 웹 브라우저가 인간이 웹 페이지와 상호작용하는 방식을 정의했다면, 미래에는 MCP가 AI 에이전트가 우리를 대신하여 웹에서 행동하는 방식을 정의할 수 있습니다. 이는 AI가 여러 서비스를 오가며 복잡한 구매 절차를 완료하는 '에이전트 상거래(agentic commerce)'와 같은 새로운 개념으로 이어질 수 있습니다.

MCP의 궁극적인 영향은 단순히 기존 시스템을 AI에 연결하는 것을 넘어, 처음부터 **'AI가 이해할 수 있는(AI-comprehensible)'** 시스템의 설계를 촉진하는 것입니다. 현재 <u>대부분의 MCP 서버는 AI를 위해 설계되지 않은 기존 API의 래퍼</u>에 불과합니다. 하지만 미래에는 애플리케이션과 서비스가 설계 단계부터 MCP 인터페이스를 기본으로 고려하게 될 수 있으며, 이는 자율 AI 에이전트와의 상호작용을 전제로 하는 애플리케이션 설계 철학의 근본적인 변화입니다.

## 마치며

MCP는 AI 개발의 초점을 "모델 중심"(더 나은 모델 구축)에서 "맥락 중심"(모델 주변 데이터 및 도구 생태계 엔지니어링)으로 이동시켰습니다. 모델이 상호작용하는 환경을 설계하여 AI 시스템의 능력을 향상시킬 수 있다는 새로운 관점을 제시합니다.

목적을 달성하려면 모델 자체의 성능도 큰 영향을 주지만, 필요한 데이터를 적절하게 전달하거나 원하는 동작을 수행할 수 있는 도구 등 생태계가 갖춰져야 합니다. 이러한 환경을 구현할 표준이 있다면 생산성, 재사용성 등 개발 효율성에서 큰 이점을 얻을 수 있습니다. MCP를 Anthropic, OpenAI, Microsoft, Google DeepMind 등 주요 기업들이 수용했다는 점에서 신뢰하고 사용할 수 있다고 생각합니다.

이번 글을 위해 자료를 찾으면서, "대부분의 MCP 서버는 AI를 위해 설계되지 않은 기존 API의 래퍼"라 언급된 것처럼 저 또한 이전까지는 MCP를 단순 요청 응답 형태로 사용하고 있었습니다. 에이전트와 MCP 서버를 "대화형 상호작용 모델"로 사용하는 것이 MCP의 철학인 만큼, 저도 올바르게 사용할 수 있도록 더 자세히 알아보려 합니다. 앞으로의 포스트에서는 MCP의 보다 구체적인 내용과, 고려사항에 대해 다루겠습니다.

> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.