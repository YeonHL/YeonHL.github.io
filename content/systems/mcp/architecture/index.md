---
title: MCP 아키텍처
description: MCP의 구성 요소를 자세히 보면서 권장되는 아키텍처를 살펴보겠습니다.
date: 2025-08-14T19:03:00
lastmod: 2025-09-11
slug: consideration
comments: true
math: false
categories:
  - Systems
tags:
  - MCP
  - LLM
keywords:
  - MCP
  - Agents
  - LLM
---

## 개요

## 섹션 1: MCP의 삼위일체: 호스트, 클라이언트, 서버 아키텍처

Model Context Protocol (MCP)는 명확하게 정의된 역할과 책임을 가진 세 가지 주요 구성요소, 즉 호스트(Host), 클라이언트(Client), 서버(Server)의 상호작용이 있습니다. 이 클라이언트-서버 아키텍처는 언어 서버 프로토콜(LSP)에서 영감을 받았으며, 각 구성요소의 역할을 분리함으로써 모듈성, 보안성 및 확장성을 달성합니다. 이 섹션에서는 각 구성요소의 본질적인 기능과 이들의 상호작용이 MCP의 핵심 설계 원칙을 어떻게 구현하는지 심층적으로 분석합니다.

### 호스트

MCP 호스트는 전체 MCP 생태계의 조정자이자 최종 통제 지점입니다. 이는 사용자가 직접 상호작용하는 <span style="background:#fff88f">AI 애플리케이션</span>으로, VS Code와 같은 통합 개발 환경(IDE), Claude Desktop과 같은 데스크톱 어시스턴트, 또는 맞춤형 에이전트 애플리케이션의 형태를 띱니다. 호스트는 단순히 LLM을 포함하는 컨테이너를 넘어, 모든 MCP 상호작용을 시작하고, 관리하며, 보호하는 복잡한 책임을 수행합니다.

호스트의 핵심 책임은 다음과 같이 분류할 수 있습니다.

- **생명주기 관리 (Lifecycle Management):** 호스트는 연결된 <u>각 MCP 서버에 대해 하나씩, 여러 MCP 클라이언트 인스턴스를 생성, 관리 및 종료할 책임</u>이 있습니다. 이는 전체 MCP 세션의 시작과 끝을 통제하는 근본적인 역할입니다.
    
- **오케스트레이션 (Orchestration):** 호스트는 사용자 프롬프트나 에이전트 워크플로우에 대응하여 <u>어떤 서버의 기능이 필요한지를 결정</u>하는 주요 오케스트레이션 로직을 포함합니다. 예를 들어, 사용자가 "오늘 가입한 고객 수는?"이라고 질문하면, 호스트는 이 요청을 분석 MCP 서버로 라우팅하는 결정을 내립니다.
    
- **컨텍스트 집계 (Context Aggregation):** 호스트는 연결된 모든 클라이언트로부터 도구(Tools), 리소스(Resources), 프롬프트(Prompts)와 같은 <u>컨텍스트를 수집하고 병합하여 LLM에 제공</u>합니다. 여러 서버에서 제공하는 다양한 컨텍스트를 하나의 일관된 프롬프트로 구성하는 이 복잡한 작업은 주로 호스트가 수행하며, 프로토콜 자체는 이에 대한 구체적인 방법을 정의하지 않습니다.
    
- **보안 및 동의 집행 (Security and Consent Enforcement):** 호스트는 최종적인 보안 게이트키퍼 역할을 합니다. 사용자의 명시적인 동의 없이 도구를 실행하거나 데이터에 접근하는 것을 방지하고, 각 서버 간의 엄격한 보안 경계를 유지하며, 전반적인 보안 정책을 강제합니다. 이는 MCP 시스템의 신뢰성과 안전성을 보장하는 가장 중요한 기능입니다.
    

### 클라이언트

MCP 클라이언트는 독립적인 애플리케이션이 아닌, 호스트 프로세스 내에 존재하는 저수준 컴포넌트입니다. 클라이언트의 핵심 역할은 단일 MCP 서버와의 전담 연결을 관리하는 중개자 역할입니다. 호스트가 여러 서버와 통신해야 할 경우, 각 서버마다 별도의 클라이언트 인스턴스를 생성하여 1:1 관계를 유지합니다.

클라이언트의 주요 책임은 다음과 같습니다.

- **1:1 연결 관리 (1:1 Connection Management):** 각 클라이언트는 특정 MCP 서버와 단일의 <u>상태 저장(stateful) 세션을 설정하고 유지</u>합니다. 이 구조는 각 서버와의 통신을 격리하여 복잡성을 줄이고 보안을 강화합니다.
    
- **프로토콜 변환 (Protocol Translation):** 클라이언트는 <u>MCP 프로토콜의 기술적인 세부 사항을 처리</u>합니다. JSON-RPC 메시지를 양방향으로 라우팅하고, 초기 핸드셰이크 과정에서 기능 협상(capability negotiation)을 관리하며, 구독 및 알림과 같은 비동기 통신을 처리합니다.
    
- **격리 유지 (Maintaining Isolation):** 클라이언트는 호스트의 관점에서 보안 경계를 강제합니다. 한 클라이언트의 통신 채널이 다른 클라이언트의 채널을 "엿보거나" 간섭할 수 없도록 보장하여, 서버 간의 정보 유출을 원천적으로 차단합니다.
    

### 1.3. MCP 서버: 특화된 컨텍스트 제공자

MCP 서버는 MCP 사양에 따라 특정하고 집중된 기능 집합을 노출하는 독립적인 프로그램입니다. 서버는 로컬 머신에서 실행될 수도 있고(예: 파일 시스템 접근), 원격으로 호스팅될 수도 있습니다(예: Stripe API 연동). 서버의 핵심은 복잡한 비즈니스 로직을 추상화하고, 이를 LLM이 이해하고 사용할 수 있는 표준화된 형태로 제공하는 것입니다.

서버의 핵심 책임은 다음과 같습니다.

- **프리미티브 노출 (Exposing Primitives):** 서버는 표준화된 MCP 데이터 모델인 리소스, 도구, 프롬프트를 통해 클라이언트에 <span style="background:#fff88f">컨텍스트를 제공</span>합니다. 예를 들어, Git 서버는 `git_log`, `git_diff`와 같은 도구를 노출할 수 있습니다.
    
- **집중된 로직 (Focused Logic):** 서버는 단일 도메인이나 서비스에 집중하도록 설계되었습니다. 복잡한 오케스트레이션은 호스트의 역할이므로, 서버는 독립적으로 작동하며 <u>자신의 전문 분야에만 집중</u>합니다.
    
- **제약 조건 준수 (Respecting Constraints):** 서버는 호스트가 강제하는 보안 제약 및 권한 내에서 작동해야 합니다. 전체 대화 기록이나 다른 서버의 컨텍스트에 접근할 수 없으며, 오직 호스트로부터 전달받은 최소한의 정보만을 사용하여 작업을 수행합니다.
    

### 1.4. 아키텍처 설계 원칙: 구성 가능성, 격리, 확장성

MCP의 삼위일체 아키텍처는 몇 가지 핵심적인 설계 원칙에 기반합니다. 이 원칙들은 프로토콜의 유연성과 견고성을 보장하는 기반이 됩니다.

- **구성 가능성 (Composability):** 각 서버는 독립적이고 모듈화된 단위입니다. 호스트는 여러 개의 단순한 서버를 조합하여 복잡한 기능을 구성할 수 있습니다. 예를 들어, 코드 분석 에이전트는 파일 시스템 서버, Git 서버, 정적 분석 서버를 동시에 사용하여 사용자 요청을 처리할 수 있습니다.
    
- **격리 (Isolation):** 서버 간의 엄격한 분리는 MCP의 근본적인 보안 원칙입니다. 호스트가 유일한 컨텍스트 집계자 역할을 함으로써, 서버는 인가되지 않은 데이터에 접근할 수 없으며 서버 간 상호 간섭으로 인한 위험이 완화됩니다.
    
- **단순성 및 확장성 (Simplicity and Extensibility):** 이 설계는 복잡한 오케스트레이션 로직을 의도적으로 호스트에 배치하여 서버를 "극도로 쉽게 구축할 수 있도록" 만듭니다. 또한, 프로토콜은 기능 협상 메커니즘을 통해 점진적으로 확장 가능하도록 설계되었습니다.
    

이러한 아키텍처는 의도적인 트레이드오프를 내포합니다. MCP 사양은 서버 개발 경험을 단순화하는 대신, 복잡성과 책임을 호스트 구현에 집중시킵니다. 서버는 간단하고, 격리되어 있으며, 특정 기능에 집중합니다. 반면, 호스트는 모든 클라이언트를 관리하고, 모든 컨텍스트를 집계하며, 모든 보안 및 동의 정책을 시행해야 합니다. 결과적으로, MCP 기반 시스템의 보안과 견고성은 프로토콜 자체보다는 호스트 구현의 품질에 의해 결정됩니다. 호스트는 신뢰, 통제, 그리고 잠재적 실패의 단일 지점(single point of trust and failure)이 됩니다. 이는 AI 에이전트를 구축하는 개발자에게 중요한 시사점을 던져줍니다. 핵심 과제는 단순히 서버에 연결하는 것이 아니라, 정교하고 안전한 호스트를 구축하는 데 있습니다.

---

## 섹션 2: 데이터 레이어 프로토콜: 컨텍스트의 언어로서의 프리미티브

MCP의 핵심은 클라이언트와 서버 간의 스키마와 의미 체계를 정의하는 데이터 레이어 프로토콜에 있습니다. 이 프로토콜의 어휘는 "프리미티브(Primitives)"라고 불리는 핵심 개념들로 구성됩니다. 프리미티브는 AI 애플리케이션과 공유할 수 있는 컨텍스트 정보의 유형과 수행할 수 있는 작업의 범위를 명시적으로 정의합니다. 이 섹션에서는 각 프리미티브의 스키마, 목적, 그리고 가장 중요한 제어 모델을 세분화하여 분석하고, 이들이 어떻게 풍부하고 구조화된 컨텍스트 교환을 가능하게 하는지 설명합니다.

### 2.1. 서버 노출 프리미티브: 핵심 제공 기능

서버가 클라이언트에 컨텍스트를 제공하는 주요 방법은 세 가지 프리미티브를 통해 이루어집니다. 이들 간의 가장 중요한 차이점은 누가 그것의 사용을 통제하는가에 대한 '제어 모델'에 있습니다. 이 구분은 단순한 명칭이 아니라, 의도된 상호작용 패턴을 정의하는 핵심적인 아키텍처 개념입니다.

#### 2.1.1. 도구 (Tools): 행동과 상호작용 활성화 (모델 제어)

- **개념:** 도구는 LLM이 발견하고 호출을 결정할 수 있는 실행 가능한 함수입니다. 데이터베이스 쿼리, API 호출, 파일 쓰기와 같이 외부 시스템의 상태를 변경하거나 부작용(side effect)을 일으키는 작업을 수행하는 데 사용됩니다. 예를 들어, OpenAI의 ChatGPT와 통합하기 위해서는 `search`와 `fetch`라는 특정 도구를 구현해야 합니다.
    
- **제어 모델:** "모델 제어(Model-controlled)"는 LLM이 사용자의 프롬프트와 도구의 설명을 바탕으로 자율적으로 특정 도구의 호출 여부와 시점을 결정한다는 의미입니다. 이는 에이전트의 자율적인 행동을 가능하게 하는 핵심적인 특징입니다.
    
- **스키마:** 도구 정의는 고유한 `name`, LLM의 의사결정에 결정적인 역할을 하는 `description`, 그리고 인수를 정의하는 `inputSchema`를 포함합니다. 결과 검증을 위한 `outputSchema`를 선택적으로 포함할 수도 있습니다. `inputSchema`는 일반적으로 JSON Schema 객체 형식입니다.
    

#### 2.1.2. 리소스 (Resources): 수동적 지식 제공 (애플리케이션 제어)

- **개념:** 리소스는 LLM에 컨텍스트를 제공하는 읽기 전용의 파일과 유사한 데이터 객체입니다. 데이터베이스 스키마, 문서 내용, API 응답 등이 이에 해당하며, 부작용을 일으키지 않도록 설계되었습니다.
    
- **제어 모델:** "애플리케이션 제어(Application-controlled)" 또는 "사용자 제어(User-controlled)"는 <span style="background:#fff88f">호스트 애플리케이션이나 사용자가</span> UI 요소(예: '@' 기호 입력, '컨텍스트 추가' 버튼 클릭)를 통해 명시적으로 리소스를 컨텍스트에 포함시킬 시점을 결정한다는 것을 의미합니다. <u>LLM은 자율적으로 리소스를 가져오도록 결정하지 않습니다.</u>
    
- **스키마:** 리소스는 URI로 식별되며 `name`, `title`, `mimeType`과 같은 메타데이터를 포함합니다.
    

#### 2.1.3. 프롬프트 (Prompts): 사용자 주도 워크플로우 구조화 (사용자 제어)

- **개념:** 프롬프트는 사용자 상호작용을 안내하거나 복잡한 작업을 구조화하는, 미리 정의되고 매개변수화 가능한 메시지 템플릿입니다.
    
- **제어 모델:** "사용자 제어(User-controlled)"는 일반적으로 <span style="background:#fff88f">사용자가 UI 명령(예: 슬래시 명령어)을 통해 명시적으로 프롬프트를 선택</span>한다는 것을 의미합니다.
    
- **스키마:** 프롬프트 정의는 `name`, `description`, `arguments` 목록, 그리고 템플릿을 구성하는 `messages` 배열을 포함합니다.
    

### 2.2. 클라이언트 노출 프리미티브: 서버 주도 상호작용 강화

MCP는 서버가 클라이언트에게 특정 작업을 요청할 수 있는, 덜 일반적이지만 강력한 프리미티브도 정의합니다. 이는 더욱 복잡하고 양방향적인 워크플로우를 가능하게 합니다.

#### 2.2.1. 샘플링 (Sampling): 위임된 언어 모델 추론

- **개념:** 서버가 호스트의 LLM에게 모델 완성을 요청할 수 있도록 허용합니다. 이는 AI 기능이 필요하지만 <u>특정 모델에 종속되지 않고 LLM SDK를 내장하고 싶지 않은 서버</u>에게 매우 중요합니다.
    
- **사용 사례:** 서버는 자체 API 키나 모델 종속성 없이, 샘플링을 사용하여 <u>자체 데이터를 처리하거나 요약한 후 결과를 반환</u>할 수 있습니다.
    

#### 2.2.2. 정보 요청 (Elicitation): 대화형 및 보안 데이터 수집

- **개념:** 서버가 호스트의 UI를 통해 <u>사용자에게 추가 정보나 확인을 요청</u>할 수 있게 합니다. 호스트가 이 상호작용을 중재하여 사용자 제어와 개인 정보 보호를 보장합니다.
    
- **사용 사례:** 다단계 인증이 필요한 도구는 정보 요청을 사용하여 서버가 직접 원시 입력을 처리하지 않고도 사용자에게 안전하게 코드를 입력하도록 요청할 수 있습니다.
    

### 2.3. 데이터 스키마와 검증: TypeScript, Zod, JSON Schema의 역할

- **권위 있는 스키마:** MCP 사양은 TypeScript 스키마 파일(`schema.ts`)을 통해 권위 있게 정의됩니다. 이는 프로토콜의 모든 데이터 구조에 대한 단일 진실 공급원(single source of truth) 역할을 합니다.
    
- **구현:** 실제 개발에서는 TypeScript의 Zod나 Python의 Pydantic과 같은 라이브러리를 사용하여 도구 인수 및 기타 프리미티브의 스키마를 정의하고 검증합니다. 이는 타입 안정성을 보장하고 견고한 오류 처리를 가능하게 합니다. 도구의 `inputSchema`는 일반적으로 JSON Schema 객체로 정의되어 언어에 구애받지 않는 상호 운용성을 제공합니다.

프리미티브의 제어 모델 구분은 MCP에 내장된 근본적인 보안 및 사용자 경험(UX) 설계 패턴입니다. 이는 개발자가 AI 에이전트가 특정 기능에 대해 가져야 할 자율성의 수준을 추론할 수 있는 프레임워크를 제공하여, 시스템이 얼마나 안전하고 예측 가능하게 작동할지에 직접적인 영향을 미칩니다. 예를 들어, <u>민감한 작업은 LLM이 예기치 않게 호출할 수 있는 '도구'보다는 명시적인 사용자 조치가 필요한 '리소스'로 노출</u>해야 합니다. 이처럼 제어 모델을 올바르게 선택하는 것은 안전하고 신뢰할 수 있는 AI 에이전트를 설계하는 데 있어 가장 중요한 아키텍처 결정 중 하나입니다.

---

## 섹션 3: 통신 흐름: 상태 저장 대화

이 섹션에서는 데이터 모델("무엇을")에서 통신 메커니즘("어떻게")으로 초점을 전환합니다. MCP를 단순한 상태 비저장(stateless) API보다 강력하게 만드는 기본 프로토콜 및 전송 계층부터 상태 저장 세션 생명주기까지 전체 통신 시퀀스를 상세히 설명합니다.

### 3.1. 기반: 공용어로서의 JSON-RPC 2.0

MCP는 통신의 기반으로 JSON-RPC 2.0 사양을 채택했습니다. 이는 요청, 응답, 알림을 위한 가볍고 잘 정의된 구조를 제공하여, 서로 다른 시스템 간의 명확한 통신을 보장합니다.

- **메시지 유형:**
    
    - **요청 (Request):** `jsonrpc`, `id`, `method`(예: `tools/list`), `params`를 포함하며, 응답을 기대합니다.
        
    - **응답 (Response):** `jsonrpc`, 일치하는 `id`, 그리고 `result` 또는 `error` 객체 중 하나를 포함합니다.
        
    - **알림 (Notification):** `jsonrpc`와 `method`는 포함하지만 `id`가 없습니다. 응답이 필요 없는 단방향 메시지입니다 (예: `initialized`, `notifications/tools/list_changed`).
        

### 3.2. 전송 메커니즘: 비교 분석

MCP 프로토콜 자체는 특정 전송 방식에 종속되지 않지만, 두 가지 표준 메커니즘을 정의하여 대부분의 사용 사례를 지원합니다.

#### 3.2.1. `stdio` (표준 입출력)

- **메커니즘:** 호스트가 서버를 자식 프로세스로 실행하고 표준 입력(`stdin`)과 표준 출력(`stdout`)을 통해 통신하는 로컬 통합에 사용됩니다.
    
- **사용 사례:** 로컬 파일 시스템 접근, Git 저장소 조작, 로컬 스크립트 실행에 이상적입니다. <span style="background:#fff88f">단일 사용자, 로컬 전용 시나리오</span>에 대해 간단하고 안전한 통신을 제공합니다.
    

#### 3.2.2. `Streamable HTTP` (레거시 `HTTP+SSE` 대체)

- **메커니즘:** 원격 또는 네트워크 서버에 사용됩니다. 클라이언트-서버 메시지에는 HTTP POST를 사용하며, 서버-클라이언트 응답 및 알림 스트리밍에는 서버-전송 이벤트(Server-Sent Events, SSE)를 사용할 수 있습니다.
    
- **사용 사례:** 웹 서비스, 서드파티 API 또는 다중 사용자/원격 서비스 연결에 필수적입니다. `Mcp-Session-Id` 헤더를 통해 <span style="background:#fff88f">상태 저장 세션을 지원</span>하여, 여러 요청에 걸쳐 컨텍스트를 유지할 수 있습니다.
    

### 3.3. 세션 생명주기: 3막 구성

MCP는 상태 비저장 REST API와 구별되는 핵심적인 특징으로, 엄격하고 상태를 저장하는 세션 생명주기를 정의합니다. 이 생명주기는 세 단계로 구성됩니다.

#### 3.3.1. 초기화: 핸드셰이크 및 기능 협상

1. **`initialize` 요청:** 클라이언트는 지원하는 프로토콜 버전과 기능(예: `sampling` 지원)을 선언하는 `initialize` 요청을 보내 통신을 시작합니다.
2. **`initialize` 응답:** 서버는 자체적으로 지원하는 버전과 기능(예: `listChanged` 알림을 지원하는 `tools` 기능)으로 응답합니다. 이 협상 과정은 해당 세션 동안 사용할 수 있는 기능을 결정합니다.
3. **`initialized` 알림:** 클라이언트는 `initialized` 알림을 보내 핸드셰이크가 완료되었음을 확인하고, 이후 정상적인 통신이 시작됩니다.

#### 3.3.2. 운영: 동적 컨텍스트 교환

이 단계에서는 클라이언트와 서버가 초기화 단계에서 협상된 기능에 따라 요청, 응답, 알림을 자유롭게 교환합니다. 예를 들어, 클라이언트는 `tools/list`로 사용 가능한 도구를 확인하고 `tools/call`로 특정 도구를 실행할 수 있으며, 서버는 `notifications/prompts/list_changed` 알림을 보내 프롬프트 목록의 변경 사항을 알릴 수 있습니다.

#### 3.3.3. 종료: 정상적인 연결 해제

연결은 기본 전송 메커니즘을 사용하여 정상적으로 종료됩니다. `stdio`의 경우 `stdin` 스트림을 닫고, HTTP 세션의 경우 `DELETE` 요청을 보내는 방식입니다.

상태 저장 세션과 기능 협상을 채택한 것은 MCP를 단순한 "AI용 API"를 넘어 동적이고 함께 발전하는 시스템을 위한 프레임워크로 변모시키는 의도적인 아키텍처 결정입니다. 각 요청이 독립적인 일반적인 REST API와 달리, MCP는 지속적인 연결을 설정하고 그 안에서 컨텍스트를 유지합니다. 초기 핸드셰이크는 단순한 인증 절차가 아니라, 세션의 "계약 조건"을 설정하는 공식적인 협상 과정입니다. 이 상태 저장 및 협상된 컨텍스트는 `listChanged`와 같은 동적 업데이트 알림, `sampling`과 같은 서버 주도 요청, 세션 내 효율적인 컨텍스트 캐싱 등 상태 비저장 모델에서는 불가능한 고급 기능을 가능하게 합니다. 이는 클라이언트와 서버가 독립적으로 개발되고 시간이 지남에 따라 새로운 기능을 추가할 수 있게 하면서도, 핸드셰이크를 통해 하위 호환성을 보장하고 지원되지 않는 작업으로 인한 런타임 오류를 방지합니다. 이것이 바로 프로토콜의 확장성과 장기적인 생존 가능성의 핵심입니다.

### 1.1. 상태 유지 연결 vs. 상태 비저장 API: 에이전트 워크플로우를 위한 근본적 전환

전통적인 API 통합, 특히 RESTful API는 본질적으로 상태 비저장(stateless) 방식으로 작동합니다. 각 요청은 이전 요청과 독립적으로 처리되며, 클라이언트는 여러 단계에 걸친 <u>작업의 상태와 컨텍스트를 스스로 관리해야 할 책임</u>이 있습니다. 이는 간단한 데이터 조회에는 효율적일 수 있으나, 여러 단계의 <u>상호작용이 필요한 복잡한 작업을 수행하는 AI 에이전트에게는 상당한 부담</u>으로 작용합니다. 에이전트 또는 클라이언트 측 오케스트레이터가 모든 상태를 기억하고 매 요청마다 전체 컨텍스트를 다시 전송해야 하므로, 이는 비효율적이고 시스템을 취약하게 만드는 원인이 됩니다.

반면, MCP는 **상태를 유지하는(stateful) 영속적인 연결(persistent connections)** 을 기반으로 설계되었습니다. 이는 일련의 개별적인 요청-응답이 아닌, 마치 웹소켓(WebSocket) 세션과 유사한 지속적인 양방향 통신 채널을 구축하는 것을 의미합니다. 이러한 상태 유지 연결은 다단계 작업 수행에 있어 결정적인 장점을 가집니다. 서버는 진행 중인 워크플로우의 컨텍스트를 세션 내에서 유지할 수 있으므로, 클라이언트는 <span style="background:#fff88f">매번 전체 컨텍스트를 다시 보낼 필요가 없습니다.</span> MCP 로드맵에서도 <u>연결 끊김 및 재연결에 대한 탄력적인 처리와 장기 실행 작업을 지원하는 것이 핵심 우선순위</u>로 명시되어 있으며, 이는 상태 유지의 중요성을 다시 한번 강조합니다.

이러한 아키텍처적 선택은 단순한 기술적 편의를 넘어, 에이전트와 도구 간의 상호작용 모델을 단순한 '요청-응답'에서 **'대화형 상호작용' 모델**로 전환시킵니다. 이는 고급 에이전트 행동을 위한 필수 전제 조건입니다. 상태 비저장 API가 LLM이나 복잡한 클라이언트 측 오케스트레이터를 유일한 상태 관리자로 만드는 반면, 상태 유지 연결은 이러한 인지적 부담의 일부를 도구 서버로 오프로드합니다. 이를 통해 <span style="background:#fff88f">도구 자체가 메모리를 가지고 에이전트를 특정 프로세스로 안내하는 등 훨씬 더 정교한 상호작용이 가능</span>해집니다.

이러한 설계는 AI 에이전트와 도구 간의 관계를 단순한 '주인-하인(master-servant)' 관계에서 '파트너십'으로 발전시키는 "협력적 인지(collaborative cognition)"라는 새로운 패러다임을 가능하게 합니다. 도구는 <u>더 이상 수동적으로 호출되는 함수가 아니라, 문제 해결 과정에 능동적으로 참여하는 주체</u>가 됩니다. 상태 비저장 API는 거래적(transactional)입니다. 에이전트(주인)가 도구(하인)에게 개별적인 행동을 명령하면, 과거 상호작용에 대한 기억이 없는 도구는 그저 명령을 수행할 뿐입니다. 그러나 MCP의 상태 유지 연결은 서버가 세션의 컨텍스트를 "기억"할 수 있음을 의미합니다. 예를 들어, "순차적 사고(Sequential Thinking)" 서버는 동적인 문제 해결 과정을 추적할 수 있습니다. 여기에 더해 `Elicitation` 및 `Sampling`과 같은 서버 주도 상호작용 기능은 <u>서버가 통신을 시작하여 에이전트에게 추가 정보를 요청하거나 추론 작업을 수행하도록 요청</u>할 수 있게 합니다. 이는 강력한 피드백 루프를 형성합니다. 에이전트가 도구에 도움을 요청하면, 도구는 자체 상태와 전문화된 로직을 사용하여 추가 정보가 필요하다고 판단하고 에이전트에게 다시 질문(`Elicitation`)하거나, 창의적인 단계가 필요하다고 판단하여 에이전트에게 텍스트 생성을 요청(`Sampling`)할 수 있습니다. 결과적으로 복잡한 문제를 해결하는 데 필요한 인지적 부하가 분산됩니다. LLM은 일반적인 추론과 언어를 처리하고, 전문화된 MCP 서버는 <span style="background:#fff88f">도메인 특화 로직, 상태 및 상호작용 흐름을 처리</span>합니다. 이 협력 모델은 LLM이 모든 것을 관리해야 하는 모델보다 훨씬 더 강력하고 효율적입니다.

### 1.2. JSON-RPC 2.0 기반과 전송 계층 메커니즘

MCP는 메시징 형식을 위해 널리 확립된 **JSON-RPC 2.0** 프로토콜을 기반으로 구축되었습니다.3 이는 요청, 응답 및 오류 처리를 위한 표준화된 구조를 제공하여 프로토콜의 안정성과 예측 가능성을 높입니다. MCP는 다양한 배포 시나리오를 수용하기 위해 여러 전송 계층을 지원하며, 이는 프로토콜의 유연성을 보여줍니다.

- **STDIO (Standard Input/Output):** 주로 <span style="background:#fff88f">로컬 통합</span>에 사용되며, 서버가 클라이언트의 하위 프로세스로 실행될 때(예: Claude Desktop과 같은 데스크톱 애플리케이션) 활용됩니다. 이 방식은 간단하고 지연 시간이 짧으며, 프로세스 격리를 통해 본질적으로 안전한 통신을 제공합니다.
- **HTTP + SSE (Server-Sent Events):** 원격 연결을 위한 초기 메커니즘으로, 서버에서 클라이언트로의 단방향 스트리밍을 허용했습니다. 이 방식은 최근 프로토콜 버전에서 <span style="background:#fff88f">더 발전된 방식으로 대체</span>되었습니다
- **Streamable HTTP:** SSE를 대체하는 현대적인 방식으로, 단일 표준 HTTP 연결을 통해 더 확장 가능하고 효율적인 양방향 통신을 가능하게 합니다. 주로 청크 분할 전송 인코딩(chunked transfer encoding)을 사용하며, 이는 클라우드 배포(예: AWS Lambda) 및 엄격한 방화벽 규칙이 있는 엔터프라이즈 네트워크 환경에 더 적합합니다.
- **WebSocket:** 최대의 상호작용성이 요구되는 시나리오를 위한 전송 방식으로 언급되며, 완전한 양방향(full-duplex) 통신을 제공합니다. 이는 스트리밍 데이터, 진행 상황 업데이트, 협업 상호작용 등이 포함된 복잡한 AI 워크플로우에 특히 유용할 수 있습니다.

전송 계층이 STDIO/SSE에서 Streamable HTTP로 발전한 것은 MCP가 개발자 중심의 로컬 우선 도구에서 엔터프라이즈급 클라우드 네이티브 프레임워크로 전략적으로 전환하고 있음을 명확히 보여주는 지표입니다. Streamable HTTP는 단방향 통신이라는 SSE의 한계와 웹소켓의 운영 복잡성을 극복하고, <u>원격 보안 통신을 위한 강력하고 널리 호환되는 솔루션</u>을 제공합니다.

**표 1: MCP 전송 계층 비교**

| **전송 방식**       | **주요 사용 사례**             | **통신 모델**            | **지연 시간** | **확장성**     | **네트워크 호환성**     | **현재 상태**            |
| --------------- | ------------------------ | -------------------- | --------- | ----------- | ---------------- | -------------------- |
| STDIO           | 로컬 프로세스 간 통신 (예: 데스크톱 앱) | 양방향                  | 매우 낮음     | 제한적 (단일 머신) | 해당 없음 (로컬)       | 활성                   |
| HTTP + SSE      | 초기 원격 연결                 | 단방향 (서버→클라이언트)       | 낮음-중간     | 중간          | 표준 HTTP/S 포트     | 사용되지 않음 (Deprecated) |
| Streamable HTTP | 원격/클라우드 배포               | 양방향 (단일 연결)          | 낮음-중간     | 높음          | 표준 HTTP/S 포트     | **현재 표준**            |
| WebSocket       | 고도의 실시간 상호작용             | 완전 양방향 (Full-duplex) | 매우 낮음     | 높음          | 별도 프로토콜/포트 필요 가능 | 고려 대상                |

### 1.3. 언어 서버 프로토콜(LSP)을 넘어서: 반응형에서 능동형 에이전시로

MCP는 코드 편집기와 언어별 도구 간의 통신을 표준화한 언어 서버 프로토콜(Language Server Protocol, LSP)에서 명시적으로 영감을 받았습니다. 그러나 MCP는 이 모델을 훨씬 더 확장합니다. LSP는 대체로 **반응적(reactive)** 입니다. 즉, IDE에서 사용자가 코드를 입력하거나 마우스를 올리는 등의 행동에 반응하여 진단 정보나 자동 완성을 제공합니다.

이와 대조적으로, MCP는 능동적인 **에이전트 중심 실행 모델(agent-centric execution model)** 을 지원하도록 설계되었습니다. 여기서 핵심적인 차이점은 제어의 주체입니다. LSP에서는 인간 사용자가 주된 에이전트입니다. 반면, MCP에서는 **AI 모델**이 에이전트입니다. 이는 MCP가 AI가 자율적으로 도구를 발견하고, 여러 도구를 연계하며(chaining), 다단계 계획을 실행하는 자율적 워크플로우를 지원해야 함을 의미합니다. 이러한 능동적인 특성 덕분에 MCP는 단순히 인간 주도 작업을 돕는 도우미를 넘어, 자율 에이전트의 중추적인 역할을 할 수 있습니다.

### 1.4. 서버 주도 상호작용: `Sampling`, `Elicitation`, `Roots`

MCP의 능동적이고 양방향적인 특성을 가장 잘 보여주는 핵심 기능은 서버가 클라이언트에게 다시 요청을 시작할 수 있는 능력입니다. 이 기능은 경직된 클라이언트-요청/서버-응답 주기를 깨뜨립니다. 사양에서는 다음과 같은 서버 주도 상호작용을 정의합니다:

- **`Sampling`:** 서버가 <span style="background:#fff88f">클라이언트의 LLM에게 추론 작업(예: 텍스트 생성, 콘텐츠 요약)을 수행하고 그 결과를 반환하도록 요청</span>할 수 있습니다. 서버는 모델, 시스템 프롬프트, temperature와 같은 매개변수를 지정할 수 있습니다. Python SDK는 이를 위해 `ctx.session.create_message` 메서드를 제공합니다. 이 기능은 전문화된 도구가 범용 추론이나 창의적 능력을 가진 호스트 LLM을 활용할 수 있게 하여, 도구가 다른 도구를 사용하는 것과 같은 구성 가능한 시스템을 만듭니다. 여기서 LLM은 일종의 "추론 도구" 역할을 하게 됩니다.
- **`Elicitation`:** 서버가 워크플로우를 일시 중지하고, 클라이언트를 통해 최종 <span style="background:#fff88f">사용자에게 추가적인 구조화된 정보를 요청</span>할 수 있습니다. 서버는 필요한 입력에 대한 스키마를 정의합니다. Python SDK 예제에서는 `book_table` 도구가 특정 날짜에 예약이 불가능할 경우 `ctx.elicit`을 사용하여 사용자에게 대체 날짜를 묻는 것을 보여줍니다. 이 기능은 에이전트가 중요한 결정 지점에서 사용자에게 명확한 설명이나 승인을 요청할 수 있는 <u>"인간 참여형(human-in-the-loop)" 워크플로우를 구현</u>하는 공식적인 메커니즘입니다.
- **`Roots`:** 서버가 자신이 작동할 수 있도록 <span style="background:#fff88f">허용된 호스트의 파일 시스템이나 URI 경계에 대해 문의</span>할 수 있습니다.

이러한 기능들은 앞서 논의된 "협력적 인지" 모델의 기술적 구현체입니다. 이는 보다 강력하고 유연한 에이전트를 구축하기 위한 심오한 아키텍처 패턴을 제시합니다.


## Section 1: MCP 통신 프로토콜의 작동 원리: JSON-RPC 및 전송 계층 심층 탐구

MCP 통신의 가장 근본적인 계층을 분석함으로써, 프로토콜 설계의 기술적 선택이 어떻게 전체 생태계의 기능, 유연성, 그리고 상호운용성을 결정하는지 탐구한다. 이는 MCP가 어떻게 안정적이면서도 다양한 환경에 적용 가능한 통신 기반을 마련했는지를 이해하는 첫걸음이다.

### 1.1 메시징의 근간, JSON-RPC 2.0 심층 분석

MCP는 모든 클라이언트-서버 통신의 기반으로 JSON-RPC 2.0을 채택했다. 이는 경량성, 명확한 사양, 그리고 무엇보다 다양한 프로그래밍 언어 환경에서의 상호운용성을 보장하는 전략적 선택이다. JSON-RPC는 사람이 읽기 쉬운 JSON 형식을 사용하므로 디버깅이 용이하며, 이미 널리 채택된 표준이기에 개발자들이 쉽게 접근할 수 있다.8 MCP는 이 표준 위에 세 가지 핵심 메시지 유형을 정의하여 통신을 구조화한다.

- **요청(Request):** 요청 메시지는 클라이언트가 서버의 특정 기능을 호출하기 위해 전송하는 통신의 시작점이다. 이 메시지는 `jsonrpc`, `method`, `params`, 그리고 고유한 `id` 필드를 포함한다.8 `method` 필드는 `tools/call`이나 `resources/list`와 같이 호출할 함수의 이름을 명시한다. 가장 중요한 것은 `id` 필드로, 모든 요청을 고유하게 식별하여 비동기적인 환경에서도 요청과 응답을 정확하게 연결하는 역할을 한다. 이 `id`의 존재는 MCP가 단순한 단방향 호출이 아닌, 상태를 추적하고 관리하는 상태 기반(stateful) 상호작용을 전제로 설계되었음을 보여주는 핵심적인 증거다.8
    
- **응답(Response):** 서버는 요청을 처리한 후, 반드시 해당 요청의 `id`를 포함하는 응답 메시지를 반환한다. 작업이 성공했을 경우 `result` 필드에 결과 데이터를 담아 보내고, 실패했을 경우에는 `error` 필드에 에러 코드와 메시지를 담아 보낸다.8 이 명확한 성공/실패 구조는 클라이언트가 견고한 오류 처리 로직을 구현할 수 있게 하며, 복잡한 워크플로우에서 각 단계의 성공 여부를 안정적으로 추적할 수 있는 기반을 제공한다.
    
- **알림(Notification):** 알림은 요청과 달리 `id` 필드가 없어 서버로부터의 응답을 요구하지 않는 단방향 메시지다.8 이는 서버가 자신의 상태 변화를 클라이언트에게 능동적으로 전파해야 할 때 사용된다. 예를 들어, 서버에 새로운 도구가 추가되거나 기존 도구가 제거되었을 때, 서버는 `notifications/tools/list_changed` 알림을 보내 클라이언트가 최신 도구 목록을 유지할 수 있도록 한다.9 이 메커니즘은 MCP 환경을 정적인 상태가 아닌, 동적으로 변화하고 반응하는 생태계로 만드는 핵심 요소로 작용한다.
    

### 1.2 전송 메커니즘: 시나리오 기반 비교 분석

MCP는 특정 전송 기술에 종속되지 않도록 설계(transport-agnostic)되어, 다양한 배포 시나리오와 요구사항에 유연하게 대응할 수 있다.11 프로토콜은 주로 두 가지 전송 방식을 표준으로 지원하며, 각각은 뚜렷한 장단점과 사용 사례를 가진다.

- **`stdio` (Standard Input/Output):** 이 방식은 MCP 서버가 호스트 애플리케이션(예: IDE, 데스크톱 앱)의 로컬 서브프로세스로 실행될 때 사용된다. 통신은 운영체제의 표준 입력(stdin)과 표준 출력(stdout) 스트림을 통해 이루어진다.3 가장 큰 장점은 네트워크 스택을 거치지 않아 <u>지연 시간이 마이크로초 단위로 극도로 낮고</u>, 운영체제 수준의 프로세스 격리를 통해 외부 네트워크로부터의 접근이 원천적으로 차단되어 <u>보안성이 매우 높다</u>는 점이다.11 이러한 특성 때문에 VS Code나 Claude Desktop과 같은 개발 도구에서 사용자의 로컬 파일 시스템에 접근하거나 로컬 스크립트를 실행하는 등 민감한 작업을 안전하고 신속하게 처리하는 데 최적화되어 있다.
    
- **`HTTP+SSE` (Server-Sent Events) 및 `Streamable HTTP`:** 이 방식은 원격 서버와의 통신을 위해 설계되었다. 클라이언트에서 서버로의 요청은 일반적인 HTTP POST 요청을 사용하고, 서버에서 클라이언트로의 지속적인 데이터 스트리밍은 Server-Sent Events(SSE)를 통해 이루어진다.3 SSE는 단방향(서버→클라이언트) 통신 채널을 오랫동안 유지하며 업데이트를 푸시하는 데 특화되어 있다. 이 방식은 기존 웹 인프라(프록시, 방화벽, 로드밸런서)와 완벽하게 호환되므로, Stripe, GitHub, Sentry 등 클라우드 기반의 원격 SaaS API를 MCP 서버로 연동하는 데 이상적이다.3 다만, 양방향 통신을 위해 요청(HTTP POST)과 응답 스트림(SSE)을 별도의 채널로 관리해야 하는 복잡성이 존재한다. 최신 MCP 사양에서는 이러한 복잡성을 줄이기 위해 단일 HTTP 연결 내에서 양방향 스트리밍을 지원하는 `Streamable HTTP`로의 통합을 추진하고 있다.
    

이처럼 이중화된 전송 메커니즘은 MCP가 '보안'을 중시하는 로컬 환경과 '확장성'을 중시하는 원격 클라우드 환경이라는 두 가지 핵심 가치를 동시에 추구하기 위한 의도적인 설계적 타협임을 보여준다. 개발자는 자신의 사용 사례에 맞춰 최적의 전송 방식을 선택할 수 있지만, 이는 동시에 MCP 클라이언트(호스트)가 두 가지 상이한 통신 모델을 모두 안정적으로 처리해야 하는 기술적 과제를 안게 됨을 의미한다.

**Table 1: MCP 전송 메커니즘 비교 분석**

| 특성             | `stdio` (Standard Input/Output)                                              | `HTTP+SSE` / `Streamable HTTP`                                     | `WebSockets` (대안)                          |
| -------------- | ---------------------------------------------------------------------------- | ------------------------------------------------------------------ | ------------------------------------------ |
| **통신 유형**      | 로컬, 양방향                                                                      | 원격, 단방향 스트림 (SSE) / 양방향 (Streamable HTTP)                          | 원격, 양방향                                    |
| **주요 장점**      | - 매우 낮은 지연 시간 - 네트워크 설정 불필요 - OS 수준의 높은 보안 (샌드박싱)                            | - 기존 웹 인프라와 호환 - 서버리스 환경 지원 - 실시간 결과 스트리밍 가능                       | - 진정한 실시간 양방향 통신 - 단일 연결 관리로 인한 단순성        |
| **주요 단점/고려사항** | - 원격 서버 연결 불가 - 호스트가 서버 프로세스 생명주기 관리 필요                                      | - 양방향 통신을 위한 채널 관리 복잡성 (HTTP+SSE) - 장기 연결을 위한 프록시/로드밸런서 설정 필요      | - 일부 기업 네트워크에서 제한될 수 있음 - 초기 핸드셰이크 오버헤드 존재 |
| **대표 사용 사례**   | - IDE 플러그인 (VS Code, Cursor) - 로컬 파일 시스템 접근 - 데스크톱 AI 어시스턴트 (Claude Desktop) | - 원격 API 연동 (Stripe, Sentry) - 클라우드 기반 데이터 소스 연결 - 웹 브라우저 기반 클라이언트 | - 고빈도 상호작용이 필요한 채팅 애플리케이션 - 실시간 협업 도구      |


### 1.3 상호작용 생명주기(Lifecycle)와 기능 협상(Capability Negotiation)

MCP 세션은 단순한 요청-응답의 나열이 아니라, 명확한 단계를 거치는 상태 기반 연결(stateful connection)이다.2 이 생명주기의 핵심은 '기능 협상' 과정으로, 클라이언트와 서버가 서로가 제공하고 지원하는 기능을 동적으로 확인하고 합의하는 절차다.

1. **초기화 (`initialize`):** 연결이 시작되면, 클라이언트는 먼저 `initialize` 요청을 서버에 보낸다. 이 요청에는 클라이언트가 지원하는 프로토콜 버전 정보와 함께, 클라이언트가 제공할 수 있는 기능(예: 서버로부터 LLM 추론 요청을 받을 수 있는 `sampling` 기능 지원 여부)에 대한 정보가 포함된다.8
    
2. **기능 협상 (Response to `initialize`):** `initialize` 요청을 받은 서버는 자신의 정보(이름, 버전 등)와 함께 자신이 제공할 수 있는 기능의 목록을 담아 응답한다. 예를 들어, 서버는 자신이 `tools`와 `resources` 프리미티브를 제공하는지, 그리고 도구 목록이 변경될 때 `listChanged` 알림을 보낼 수 있는지 여부를 `capabilities` 객체에 담아 클라이언트에 알린다.9 이 교환 과정을 통해 양측은 앞으로의 세션에서 어떤 종류의 상호작용이 가능한지에 대해 명시적으로 합의하게 된다.
    
3. **초기화 완료 (`initialized`):** 서버로부터 기능 목록을 성공적으로 수신한 클라이언트는 `initialized` 알림을 서버에 보내 협상 과정이 완료되었음을 알린다.8 이 시점부터 본격적인 상호작용이 시작될 수 있다.
    
4. **실행 및 종료:** 초기화가 완료되면, 클라이언트는 협상된 기능을 바탕으로 `tools/list`, `tools/call`과 같은 구체적인 메서드를 호출하여 작업을 수행한다.9 세션은 연결이 끊어지면 종료되며, 이 과정에서 **세션 지속성** 메커니즘이 데이터 유실을 방지하는 역할을 할 수 있다.14
    

이러한 생명주기와 협상 과정은 MCP가 LSP의 성공적인 아키텍처를 AI 에이전트 생태계에 맞게 전략적으로 진화시켰음을 보여준다. LSP가 IDE와 언어 서버 간의 상호작용을 표준화하여 생태계를 폭발적으로 성장시킨 것처럼, MCP는 JSON-RPC 기반의 유사한 구조를 통해 AI 애플리케이션과 외부 기능 간의 "N:M" 연결 문제를 해결하고자 한다.1 특히, LSP가 주로 사용자의 입력에 반응하는 '수동적(reactive)' 모델인 반면, MCP는 `Sampling`과 같은 기능을 통해 서버가 클라이언트의 LLM을 호출하는 '능동적(proactive)' 상호작용을 지원함으로써, 단순한 도구 연동을 넘어 자율적인 AI 에이전트 워크플로우를 지원하도록 한 단계 더 나아갔다.


## 마치며


> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.