---
title: 모델 서빙 시 고려사항
description: 모델 서빙은 어떤 문제를 해결하기 위해 등장했고, 무엇을 목표로 할까요?
date: 2025-09-18T19:03:00
lastmod: 2025-09-18
slug: consideration
comments: true
math: false
categories:
  - Systems
tags:
  - Model-Serving
keywords:
  - Model-Serving
  - MLOps
---
## 개요


## 모델 관리

### 모델 배포 전략

프로덕션 환경에서 모델은 정적인 존재가 아닙니다. 새로운 데이터가 축적되고 비즈니스 환경이 변화함에 따라 모델은 지속적으로 개선되고 업데이트되어야 합니다. <u>단순히 기존 모델을 새로운 모델로 덮어쓰는 방식은 서비스 중단, 예측 성능 저하, 비즈니스 손실 등 심각한 위험을 초래</u>할 수 있습니다. 

성숙한 MLOps(Machine Learning Operations) 프랙티스는 이러한 <u>위험을 체계적으로 관리하고, 서비스 연속성을 보장하며, 데이터 기반의 의사결정을 통해 최적의 모델을 선택하기 위한 고급 배포 전략</u>을 활용합니다.

모델 역시 소프트웨어의 배포 전략을 사용합니다. 모델을 배포할 때 사용하는 대표적인 전략들은 아래와 같습니다.

#### 블루-그린 배포: 무중단 전환 보장

블루-그린 배포는 '블루'와 '그린'으로 명명된 두 개의 동일하고 격리된 프로덕션 환경을 유지하는 전략입니다. 현재 라이브 서비스를 제공하는 환경이 '블루'라면, 새로운 버전의 모델은 '그린' 환경에 배포됩니다. 

이 그린 환경은 <u>외부 트래픽으로부터 완전히 차단된 상태에서 철저한 테스트</u>를 거칩니다. 모든 <u>검증이 완료되면, 라우터나 로드 밸런서를 통해 전체 트래픽을 블루에서 그린으로 순간적으로 전환</u>합니다. 이전 블루 환경은 롤백을 위해 대기 상태로 유지됩니다.

이 전략의 가장 큰 장점은 배포 과정에서 <u>다운타임이 전혀 발생하지 않는다는 것과, 문제가 발생했을 때 즉각적인 롤백이 가능</u>하다는 점입니다. 만약 예기치 않은 문제가 발견되면, 트래픽을 다시 블루 환경으로 전환하기만 하면 되므로 서비스 안정성을 매우 높은 수준으로 유지할 수 있습니다.

하지만 블루-그린 배포는 명확한 단점을 가집니다. <u>동일한 프로덕션 환경을 두 배로 유지해야 하므로 인프라 비용과 자원 소모가 크다는 것</u>입니다. 또한, 트래픽 전환이 '전부 아니면 전무(all-or-nothing)' 방식으로 이루어지기 때문에, <u>모든 사용자가 동시에 새로운 모델에 노출</u>됩니다. 이는 미처 발견하지 못한 미묘한 버그가 전체 사용자에게 영향을 미칠 수 있는 위험이 있습니다.


#### 카나리 배포: 점진적 출시를 통한 위험 완화

카나리 배포는 과거 광부들이 유독가스를 감지하기 위해 카나리아 새를 먼저 탄광에 내려보냈던 것에서 유래한 이름처럼, 새로운 모델 버전을 극소수의 사용자 그룹('카나리 그룹')에게만 먼저 노출시키는 전략입니다. 대부분의 사용자는 기존의 안정적인 버전을 계속 사용하며, 카나리 그룹에 노출된 새로운 모델의 성능은 면밀히 모니터링됩니다. 만약 새로운 모델이 기대대로 작동하면, <u>트래픽을 점진적으로(예: 1%, 10%, 50%, 100%) 새로운 버전으로 이전</u>시켜 최종적으로 전체 배포를 완료합니다.

카나리 배포의 장점은 <u>잠재적인 장애의 영향 범위('blast radius')를 최소화</u>할 수 있다는 것입니다. 문제가 발생하더라도 소수의 사용자에게만 영향을 미치므로, 전체 서비스의 안정성을 해치지 않으면서 새로운 버전을 검증할 수 있습니다. 문제(예: 더 높은 오류율, 증가된 지연 시간)가 발생하면 트래픽은 즉시 안정적인 버전으로 다시 라우팅되고 카나리 인스턴스는 종료됩니다.

또한, <u>실제 프로덕션 환경에서 사용자 피드백과 성능 데이터를 수집하여 최종 배포 결정</u>을 내릴 수 있습니다. <u>블루-그린 배포보다 인프라 비용이 저렴</u>하다는 특징도 있습니다.

반면, 카나리 배포는 구현 및 관리가 더 복잡합니다. <u>정교한 트래픽 라우팅, 실시간 모니터링, 자동화된 분석 도구가 필요</u>합니다. 점진적인 출시 과정은 블루-그린 배포의 즉각적인 전환보다 시간이 더 오래 걸립니다. 

Amazon SageMaker와 같은 일부 플랫폼은 카나리 트래픽 전환(Canary traffic shifting) 기능을 제공하여, 블루-그린의 안전성과 카나리의 점진적 검증을 결합한 하이브리드 전략을 지원하기도 합니다.

| 구분           | 블루-그린 배포 (Blue-Green Deployment)                    | 카나리 배포 (Canary Deployment)                             |
| ------------ | --------------------------------------------------- | ------------------------------------------------------ |
| **주요 목표**    | 무중단 배포 및 즉각적인 롤백                                    | 점진적 출시를 통한 리스크 최소화                                     |
| **복잡성**      | 조율이 더 간단함 (일회성 전환).                                 | 더 복잡함. 정교한 트래픽 관리 및 실시간 모니터링 필요.                       |
| **리스크 프로파일** | 중간 (전체 사용자 동시 노출)                                   | 낮음 (영향 범위 제한적)                                         |
| **인프라 비용**   | 높음 (완벽한 이중 환경 필요)                                   | 낮음-중간 (추가 인스턴스 필요)                                     |
| **배포 속도**    | 빠름 (단일 트래픽 전환)                                      | 느림 (점진적 트래픽 증가)                                        |
| **롤백 메커니즘**  | 매우 간단 (라우터 재전환)                                     | 간단 (트래픽을 구 버전으로 되돌림)                                   |
| **피드백 유형**   | 배포 후 전체 성능 모니터링                                     | 실시간 성능 및 사용자 피드백                                       |
| **최적 상황**    | 위험이 낮은 업데이트, 상태 분리가 쉬운 애플리케이션, 인프라 비용이 주요 제약이 아닐 때. | 위험이 높은 업데이트, 성능에 민감한 변경, 전체 배포 전 라이브 트래픽으로 테스트가 필요할 때. |

#### A/B 테스팅: 배포를 넘어 실시간 실험으로

A/B 테스팅은 카나리 배포와 마찬가지로 트래픽을 분할하는 메커니즘을 사용하지만, 그 목적은 안전한 배포를 넘어 *비교 실험*에 있습니다. <u>트래픽은 사전에 정의된 비율(예: 모델 A에 50%, 모델 B에 50%)로 두 개 이상의 모델 버전에 분산되어 일정 기간 동안 운영</u>됩니다. 이 실험의 목표는 클릭률, 전환율, 매출과 같은 특정 <u>비즈니스 지표를 기준으로 어떤 모델이 더 우수한 성과를 내는지 정량적으로 측정</u>하는 것입니다.

A/B 테스팅을 다른 전략과 구분 짓는 핵심 요소는 통계적 가설 검정에 대한 의존성입니다. 실험을 통해 관찰된 <u>모델 간의 성능 차이가 우연에 의한 것인지, 아니면 통계적으로 유의미한 차이인지를 검증</u>하는 과정이 필수적입니다. 이를 위해 실험 시작 전에 명확한 목표, 평가 지표, 필요한 샘플 크기 등을 사전에 설계해야 합니다.

머신러닝 분야에서 A/B 테스팅은 오프라인 평가(예: 더 높은 정확도)에서 기술적으로 우수해 보이는 <u>새로운 모델이 실제 프로덕션 환경에서도 더 나은 비즈니스 성과를 가져오는지 검증하는 가장 확실한 방법</u>입니다. 이는 모델 평가의 기준을 기술적 지표에서 비즈니스 KPI로 전환시키는 중요한 과정입니다.

 A/B 테스팅은 배포 과정을 비즈니스 가치 측정 및 데이터 기반 의사결정과 완전히 통합하는 가장 높은 수준의 성숙도를 보여줍니다. 이 과정은 조직이 '모델이 잘 작동한다'는 것의 의미를 IT 안정성에서 리스크 관리, 그리고 최종적으로 비즈니스 성과로 점차 발전시켜 나가는 과정을 반영합니다.

| 구분           | A/B 테스팅 (A/B Testing)   |
| ------------ | ----------------------- |
| **주요 목표**    | 통계적 비교를 통한 최적 모델 선정     |
| **리스크 프로파일** | 낮음 (통제된 실험 환경)          |
| **인프라 비용**   | 낮음-중간 (추가 인스턴스 필요)      |
| **배포 속도**    | 느림 (통계적 유의성 확보 기간 필요)   |
| **롤백 메커니즘**  | 간단 (성과가 낮은 버전을 비활성화)    |
| **피드백 유형**   | 비즈니스 KPI 기반의 정량적 성과 데이터 |

현대의 모델 서빙 플랫폼들은 이러한 전략들의 경계를 허물고 있습니다. 예를 들어, 카나리 배포는 A/B 테스트의 초기 단계로 활용될 수 있으며, 블루-그린 환경의 <u>'그린' 플릿에서 카나리 테스트를 먼저 수행</u>한 후 전체 트래픽을 전환하는 하이브리드 방식도 가능합니다. 이는 각 전략이 상호 배타적인 선택이 아니라, 조합하여 사용할 수 있는 패턴임을 의미합니다. 근본적인 기술(트래픽 분할 및 라우팅)은 동일하지만, 그 의도(안정성, 리스크 완화, 실험)와 평가에 사용되는 기간 및 지표는 차이가 있습니다.

### 모델 버전 관리 및 자동 롤백

#### 모델 버전 관리의 기둥

효과적인 버전 관리는 단순히 파일 이름을 `model_v2.pkl`로 지정하는 것 이상입니다. 이는 Git과 같은 버전 관리 시스템(VCS)을 사용하는 체계적인 접근 방식을 포함합니다.

- **모든 것을 추적:** <u>모델 코드뿐만 아니라 모델 구성 파일, 학습 데이터 버전(또는 그에 대한 포인터), 그리고 결과적인 성능 지표까지 모두 버전 관리</u>해야 합니다. 이는 완전한 재현성을 보장합니다.
- **안정적인 릴리스 태그 지정:** Git 태그를 사용하여 특정 커밋을 안정적이고 프로덕션 준비가 된 릴리스로 표시합니다. 이는 명확하고 감사 가능한 이력을 생성하며, 특정하고 검증된 버전을 체크아웃하여 재배포하는 것을 매우 쉽게 만듭니다.

#### CI/CD를 통한 자동 롤백

롤백 프로세스는 수동적이고 당황스러운 과정이 되어서는 안 됩니다. CI/CD 파이프라인에 통합된 자동화되고 테스트된 절차여야 합니다.

- **롤백 트리거:** 파이프라인은 새로 배포된 모델의<u> 핵심 성능 지표(예: Prometheus를 통해)를 지속적으로 모니터링</u>해야 합니다. 지표가 미리 정의된 임계값을 위반하면(예: 오류율 급증, 지연 시간이 SLA 초과), 파이프라인은 이전에 태그된 안정적인 버전으로의 롤백을 자동으로 트리거해야 합니다.
- **롤백 테스트:** 애플리케이션 코드를 테스트하는 것과 마찬가지로, 실제 사고 발생 시 예상대로 작동하는지 확인하기 위해 스테이징 환경에서 롤백 절차를 정기적으로 테스트해야 합니다.

버전 관리는 자동화되고 위험이 낮은 운영을 위한 전제 조건입니다. "이전 버전"으로 안정적으로 롤백하려면 해당 버전이 무엇인지에 대한 정확하고 명확한 정의가 있어야 합니다. 견고한 버전 관리 시스템(Git 태그, 모델 레지스트리)은 이러한 정확한 정의를 제공하며, 이는 프로덕션 환경의 "저장 지점"과 같습니다. CI/CD 파이프라인은 자동화 엔진을 제공하고, 실시간 모니터링은 이 엔진의 트리거 신호를 제공합니다. 이 세 가지 구성 요소가 결합되면 **배포 -> 모니터링 -> 이상 감지 -> 검증된 버전으로의 자동 롤백 트리거**라는 폐쇄 루프 시스템이 만들어집니다. 결론적으로, 견고한 모델 버전 관리는 단순히 정리를 위한 "모범 사례"가 아니라, <span style="background:#fff88f">자동 롤백 및 GitOps 기반 배포와 같은 고급 운영 패턴을 가능하게 하는 기초 기술</span>입니다. 이것 없이는 프로덕션 환경에서의 안전하고 빠른 반복이 불가능합니다.


## 성능 및 비용 최적화

모델 서빙 시스템을 운영할 때, 추론 지연 시간을 줄여 사용자 경험을 향상시키는 '성능'과 인프라 비용을 최소화하는 '비용'은 종종 상충하는 목표처럼 보입니다. 그러나 현대 MLOps에서는 이 두 가지 목표가 밀접하게 연결되어 있으며, 한쪽의 <u>최적화가 다른 쪽에 긍정적인 영향</u>을 미치는 경우가 많습니다. 특히 거대 언어 모델(LLM)과 같이 계산 집약적인 모델의 등장은 추론 성능과 비용 효율성을 동시에 달성하기 위한 고급 최적화 기술의 중요성을 더욱 부각시키고 있습니다.

### 추론 성능 공학

LLM의 등장은 모델 서빙의 패러다임을 바꾸었습니다. 수천억 개의 파라미터를 가진 모델을 효율적으로 서빙하기 위해 과거에는 선택 사항이었던 최적화 기법들이 이제는 필수가 되었습니다.

- **경량화 (Quantization):** 모델의 <span style="background:#fff88f">가중치(weight)와 활성화 값(activation)의 수치 정밀도를 낮추는 기술</span>입니다. 예를 들어, 32비트 부동소수점(FP32)을 8비트 정수(INT8)로 변환하는 것입니다. 이 과정은 모델의 크기를 줄여 <u>메모리 사용량을 낮추고, 더 빠른 계산을 가능하게 하여 추론 속도를 향상</u>시킵니다. <u>대부분의 경우, 정확도 손실은 미미한 수준으로 제어</u>할 수 있습니다.65
- **지식 증류 (Knowledge Distillation):** 크고 복잡하지만 성능이 좋은 '교사(teacher)' 모델의 지식을 작고 효율적인 '학생(student)' 모델에게 전달하여 학습시키는 기법입니다. 학생 모델은 <u>교사 모델의 예측 결과(soft label)를 모방하도록 학습함으로써, 훨씬 작은 크기에도 불구하고 교사 모델의 성능 대부분을 유지</u>할 수 있습니다. 이를 통해 배포 비용과 속도를 크게 개선할 수 있습니다.
- **동적 배치 (Dynamic Batching):** 실시간으로 들어오는 <span style="background:#fff88f">개별 추론 요청들을 잠시 대기시킨 후, 하나의 배치(batch)로 묶어 동시에 처리</span>하는 기술입니다. GPU와 같은 가속기는 병렬 처리에 최적화되어 있어, 개별 요청을 순차적으로 처리하는 것보다 <u>배치를 통해 한 번에 처리할 때 훨씬 높은 효율</u>을 보입니다. 이는 GPU 활용률을 극대화하고 전체 처리량을 크게 향상시키는 데 결정적인 역할을 합니다.
- **기타 기법:** 이 외에도 LLM 서빙을 위해 <span style="background:#fff88f">추측 디코딩(speculative decoding), 커널 퓨전(kernel fusion), 효율적인 KV 캐시(Key-Value Cache) 관리</span> 등 다양한 기법들이 활발히 연구 및 적용되고 있습니다.

### 4.2. 비용 관리 및 최적화 전략

모델 서빙 비용의 주요 구성 요소는 <u>컴퓨팅 인프라(CPU/GPU 인스턴스), 데이터 저장소, 그리고 네트워크를 통한 데이터 전송 비용</u>입니다. <u>모델의 크기, 선택하는 인스턴스 유형, 그리고 서비스의 트래픽 패턴이 이 비용들을 직접적으로 결정</u>합니다.

- **클라우드 가격 모델 활용:** 클라우드 제공업체들은 다양한 가격 모델을 제공하며, 워크로드의 특성에 맞는 모델을 선택하는 것이 비용 절감의 핵심입니다.
  - **온디맨드 (On-Demand):** 약정 없이 사용한 만큼 지불하는 방식으로, 유연성이 높지만 시간당 비용이 가장 비쌉니다. 예측 불가능한 트래픽에 적합합니다.
  - **예약 인스턴스 (Reserved Instances) / 절감형 플랜 (Savings Plans):** 1년 또는 3년의 장기 사용을 약정하는 대신 대폭 할인(최대 75%)을 받는 방식입니다. 안정적이고 예측 가능한 프로덕션 워크로드에 이상적입니다.
  - **스팟 인스턴스 (Spot Instances):** 클라우드의 유휴 컴퓨팅 자원을 경매 방식으로 매우 저렴하게(최대 90% 할인) 사용하는 방식입니다. 언제든지 중단될 수 있는 위험이 있어, <u>장애 허용성이 높은 배치 추론과 같은 비정규 워크로드</u>에 적합합니다.
- **적정 규모 설정(Right-Sizing) 및 자동 확장(Autoscaling):** <u>CPU, 메모리 등의 자원 사용률을 지속적으로 모니터링하고, 트래픽 수요에 맞춰 실행 중인 인스턴스 수를 동적으로 조절</u>하는 자동 확장 기능을 활용해야 합니다. 이는 필요 이상의 자원을 프로비저닝하여 발생하는 유휴 비용을 방지하는 가장 효과적인 방법 중 하나입니다.
- **관리형 서비스 및 MLOps 자동화:** Amazon SageMaker나 Google Vertex AI와 같은 관리형 ML 서비스를 사용하면 인프라 관리, 확장, 유지보수에 드는 운영 부담을 클라우드 제공업체에 위임하여 총소유비용(TCO)을 절감할 수 있습니다. 또한, <u>CI/CD 파이프라인 구축, 자동 재학습 등 MLOps 전반을 자동화하면 수작업에 드는 엔지니어링 비용을 크게 줄일 수</u> 있습니다.

성능 공학과 비용 최적화는 별개의 활동이 아니라, 서로 긴밀하게 연결된 공생 관계에 있습니다. 예를 들어, **경량화** 기술을 적용하여 모델의 메모리 사용량을 줄이면 <u>더 작고 저렴한 인스턴스 유형에서 모델을 실행</u>할 수 있게 됩니다. **동적 배치**를 통해 처리량을 높이면, <u>동일한 트래픽을 더 적은 수의 인스턴스로 처리</u>할 수 있어 직접적인 비용 절감으로 이어집니다. 이처럼 기술적인 성능 최적화 활동은 재무적인 비용 절감에 직접적이고 인과적인 영향을 미칩니다.

또한, 모든 워크로드를 단일 인프라 전략으로 운영하는 것은 비용 측면에서 비효율적입니다. 가장 비용 효율적인 아키텍처는 <u>워크로드의 특성을 적절한 가격 모델과 매칭하는 하이브리드 전략을 채택</u>하는 것입니다. 예를 들어, 트래픽이 안정적인 핵심 온라인 서비스는 예약 인스턴스로 운영하고, 트래픽 변동이 심한 신규 서비스는 온디맨드 인스턴스와 자동 확장을 결합하며, 주기적인 대규모 배치 작업은 스팟 인스턴스를 활용하는 방식입니다. 이러한 구분을 하지 않고 모든 워크로드를 온디맨드로 운영한다면 불필요한 비용이 발생할 수밖에 없습니다. 이는 비용 최적화가 단순히 인스턴스 유형을 선택하는 문제를 넘어, 아키텍처 설계 단계에서부터 고려되어야 할 핵심 요소임을 보여줍니다.


## 결론

본 보고서는 인공지능 모델 서빙의 고급 개념들을 체계적으로 분석하여, 프로덕션 환경에서 AI 시스템을 설계, 배포, 운영하는 데 필요한 심층적인 통찰을 제공하고자 했습니다. 분석을 통해 도출된 핵심 결론은 다음과 같습니다.

첫째, 모델 서빙 아키텍처의 선택은 기술적 선호가 아닌, <span style="background:#fff88f">비즈니스 요구사항에 의해 결정</span>되는 전략적 행위입니다. 온라인, 배치, 엣지, 서버리스와 같은 다양한 패러다임은 지연 시간, 처리량, 비용, 운영 복잡성이라는 다차원적인 스펙트럼 위에 존재하며, 각 애플리케이션의 고유한 제약 조건에 가장 부합하는 패러다임을 선택하는 것이 성공의 첫걸음입니다.

둘째, 모델 배포는 일회성 이벤트가 아니라, <u>리스크 관리와 지속적인 개선을 위한 동적인 프로세스</u>입니다. 블루-그린, 카나리, A/B 테스팅과 같은 고급 배포 전략들은 단순히 모델을 업데이트하는 것을 넘어, 서비스 안정성을 보장하고, 장애의 영향을 최소화하며, 최종적으로는 비즈니스 가치를 극대화하는 방향으로 진화해왔습니다. MLOps 성숙도가 높아질수록 배포는 IT 운영 활동에서 데이터 기반의 비즈니스 실험 활동으로 그 성격이 변화합니다.

셋째, 프로덕션 환경에서의 모니터링은 <u>시스템 상태, 모델 성능, 데이터 무결성이라는 세 가지 축을 모두 포괄하는 다층적 접근을 요구</u>합니다. 시스템 장애는 즉각적인 문제를, 데이터 드리프트는 잠재적 문제를, 모델 성능 저하는 이미 발생한 문제를 나타내는 계층적 관계를 가집니다. 따라서 선행 지표인 데이터 무결성 모니터링을 통해 문제를 조기에 감지하고 대응하는 것이 안정적인 서비스 운영의 핵심입니다.

마지막으로, 성능, 비용, 보안은 독립적인 고려사항이 아니라 서로 긴밀하게 연결된 최적화의 세 축입니다. 경량화나 동적 배치와 같은 성능 최적화 기술은 직접적인 비용 절감으로 이어지며, 비용 효율적인 클라우드 가격 모델의 선택은 아키텍처 설계 단계에서부터 고려되어야 합니다. 동시에, AI 시스템의 확장된 공격 표면을 인지하고, 인프라 보안과 더불어 모델 자체의 취약점을 방어하는 설계 기반 보안 원칙을 MLOps 수명주기 전반에 통합하는 것이 필수적입니다.

결론적으로, 성공적인 모델 서빙은 개별 기술의 구현을 넘어, 이러한 고급 개념들을 종합적으로 이해하고 비즈니스 목표에 맞춰 전략적으로 조합하는 능력에 달려 있습니다. 이는 기술과 비즈니스, 데이터 과학과 소프트웨어 공학의 경계를 넘나드는 MLOps 전문가의 핵심 역량이라 할 수 있습니다.





### 추론 워크로드를 위한 다차원 자동 확장

이 섹션에서는 현대 오케스트레이션 플랫폼이 변동하는 수요에 맞춰 리소스를 자동으로 조정하는 방법, 즉 비용 효율적인 대규모 서빙을 위한 핵심 기능에 대해 심층적으로 살펴봅니다.

#### Kubernetes 네이티브 스케일링: 세 가지 차원

Kubernetes는 함께 작동하는 강력하지만 복잡한 자동 확장 도구 세트를 제공합니다.

- **수평적 파드 자동 확장기 (HPA):** 파드 *복제본*의 수를 확장합니다("스케일 아웃"). 일반적으로 CPU 또는 메모리 사용량과 같은 지표에 의해 구동됩니다. AI의 경우, 더 많은 모델 서빙 파드를 추가하여 다양한 요청률을 처리하는 데 사용됩니다.
- **수직적 파드 자동 확장기 (VPA):** 기존 파드의 CPU 및 메모리 *요청/제한*을 조정합니다("스케일 업"). AI의 경우, 리소스 집약적인 훈련 또는 추론 파드에 대한 리소스 할당을 적정 크기로 조정하여 메모리 부족 오류를 방지하는 데 사용될 수 있습니다.
- **클러스터 자동 확장기 (CA):** 클러스터에서 전체 _노드_(VM)를 추가하거나 제거합니다. 이것은 매크로 수준의 스케일러입니다. HPA가 더 많은 파드를 추가하려고 하지만 필요한 리소스(예: GPU)가 있는 가용 노드가 없는 경우, 파드는 "보류(Pending)" 상태로 남게 됩니다. 클러스터 자동 확장기는 이를 감지하고 이들을 수용하기 위해 새 노드를 프로비저닝합니다.

#### HPA/VPA 충돌

중요한 미묘한 점은 HPA와 VPA가 동일한 지표(CPU/메모리)에 대해 작동할 때 종종 호환되지 않는다는 것입니다. 이들은 충돌하는 스케일링 신호를 생성할 수 있습니다. 가장 좋은 방법은 서로 다른 목적으로 사용하는 것입니다: HPA는 사용자 정의 지표(초당 요청 수 등)에 따라 복제본을 확장하고, VPA는 "권장" 모드에서 해당 복제본의 리소스 요청을 적정 크기로 조정하는 데 사용합니다.

#### Knative를 사용한 서버리스 및 이벤트 기반 스케일링

Kubernetes 기반 서버리스 플랫폼인 Knative는 자체 자동 확장기인 **Knative Pod Autoscaler (KPA)** 를 도입했습니다.

- **0으로 확장(Scale-to-Zero):** KPA의 가장 유명한 기능입니다. 서비스가 트래픽을 받지 않으면 KPA는 복제본을 0으로 축소하여 모든 리소스 소비를 제거할 수 있습니다. 새 요청이 도착하면 "액티베이터(Activator)" 구성 요소가 이를 가로채서 보류하고, 서비스를 0에서 확장한 다음 요청을 전달합니다.
- **패닉 모드(Panic Mode):** 갑작스러운 트래픽 급증을 처리하기 위해 KPA는 "패닉 모드"에 들어갑니다. 관찰된 동시성이 목표를 급격히 초과하면 KPA는 버스트를 흡수하기 위해 공격적이고 신속하게 파드를 확장하여 완벽한 리소스 활용보다 가용성을 우선시합니다. 용량이 구성된 "안정 창(stable window)" 동안 안정될 때까지 이 모드를 유지합니다.
- **이벤트 기반 스케일링 (KEDA):** CPU 또는 동시성 지표에 잘 매핑되지 않는 워크로드의 경우, **Kubernetes Event-driven Autoscaling (KEDA)** 는 메시지 큐의 길이(예: RabbitMQ, Kafka)와 같은 외부 이벤트 소스를 기반으로 스케일링을 허용합니다. 이는 비동기식, 배치 추론 시스템에 완벽합니다.



### 4.2: 비용 최적화를 위한 인프라 전략

특히 GPU 집약적인 워크로드의 경우, 모델 서빙의 높은 비용을 관리하기 위해서는 올바른 배포 환경과 가격 책정 모델을 선택하는 것이 중요합니다.

#### 4.2.1: 서버리스 vs. 스팟 인스턴스: 추론 워크로드를 위한 트레이드오프 분석

- **서버리스 추론(Serverless Inference):** 간헐적이거나 예측 불가능한 트래픽이 있는 워크로드에 이상적입니다. 클라우드 제공업체가 인프라를 자동으로 관리하며, 요청이 있을 때 0에서부터 확장하고 트래픽이 없으면 다시 축소하여 유휴 시간에 대한 비용을 제거합니다. 주요 단점은 "콜드 스타트(cold start)" 지연 시간으로, <u>비활성 기간 후 첫 번째 요청이 컨테이너와 모델이 로드되는 동안 지연</u>을 겪는 것입니다. 이로 인해 엄격하고 초저지연 시간 요구사항이 있는 애플리케이션에는 덜 적합합니다.
- **스팟 인스턴스(Spot Instances):** 예비 클라우드 용량에 대해 막대한 비용 절감(최대 90%)을 제공하지만, <u>예고 없이 선점(회수)</u>될 수 있습니다. 이로 인해 모델 학습이나 배치 추론과 같이 내결함성이 있고 시간에 민감하지 않은 워크로드에 이상적이지만, 시스템이 중단을 원활하게 처리하도록 설계되지 않은 경우(예: 체크포인팅 및 자동 재시도) 실시간 서빙에는 위험합니다.
- **하이브리드 접근법:** 많은 프로덕션 시스템은 혼합된 방식을 사용합니다. 보장된 가용성을 위해 온디맨드 또는 예약 인스턴스의 기준선을 유지하고, 예측 불가능한 급증을 처리하기 위해 서버리스를 보완하며, 우선순위가 낮은 배치 작업을 위해 스팟 인스턴스를 활용합니다.



## 마치며


> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.