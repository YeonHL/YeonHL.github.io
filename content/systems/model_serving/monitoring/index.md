---
title: 모델 서빙
description:
date: 2025-09-20T19:03:00
lastmod: 2025-09-20
slug: optimize
comments: true
math: false
categories:
  - Systems
tags:
  - Model-Serving
keywords:
  - Model-Serving
  - MLOps
---
## 개요


## 프로덕션 모니터링의 핵심 요소

모델을 성공적으로 배포하는 것은 MLOps 수명주기의 시작입니다. 프로덕션 환경에 배포된 모델은 끊임없이 변화하는 데이터와 외부 환경의 영향을 받기 때문에, 지속적인 모니터링 없이는 성능과 안정성을 보장할 수 없습니다. 머신러닝 시스템의 모니터링은 전통적인 소프트웨어 모니터링의 범위를 넘어, <u>모델 자체의 예측 품질과 입력 데이터의 통계적 특성까지 포괄</u>해야 합니다. 

### 시스템 상태: 네 가지 황금 신호

구글의 사이트 신뢰성 엔지니어링(Site Reliability Engineering, SRE) 프랙티스에서 유래한 '네 가지 황금 신호(Four Golden Signals)'는 모든 서빙 인프라의 상태를 종합적으로 파악할 수 있는 핵심 지표입니다. 이 신호들은 시스템 수준의 문제를 감지하는 첫 번째 방어선 역할을 합니다.

- **지연 시간 (Latency):** <u>요청을 처리하고 응답을 반환하는 데 걸리는 시간</u>입니다. 성공한 요청과 실패한 요청의 지연 시간을 구분하여 추적하는 것이 중요하며, 특히 p95, p99와 같은 백분위수(percentile)를 모니터링하여 일부 사용자가 겪는 최악의 경험을 파악해야 합니다. LLM의 경우, 사용자가 체감하는 응답성은 여러 단계로 나뉘어 측정됩니다.
	- **첫 토큰까지의 시간 (Time to First Token, TTFT):** 사용자가 요청을 보낸 후 <u>응답의 첫 번째 조각(토큰)이 생성될 때까지 걸리는 시간</u>입니다. 이 지표는 챗봇과 같은 대화형 애플리케이션에서 사용자가 느끼는 '즉각적인 반응성'을 결정하는 가장 중요한 요소입니다. 특히 긴 컨텍스트나 문서를 입력으로 사용하는 검색 증강 생성(RAG)과 같은 애플리케이션에서는 입력 프롬프트를 처리하는 데 상당한 시간이 소요되므로 TTFT가 전체 지연 시간에서 큰 비중을 차지하게 됩니다.
	- **출력 토큰당 시간 (Time Per Output Token, TPOT) / 초당 출력 토큰 수 (Output Tokens Per Second, OTPS):** 첫 토큰이 생성된 후, <u>후속 토큰들이 생성되는 속도</u>입니다. 이 지표는 응답이 얼마나 '매끄럽게' 생성되는지를 나타내며, 긴 형식의 콘텐츠를 생성하는 작업에서 중요합니다. 높은 OTPS는 사용자가 응답을 읽는 속도에 맞춰 자연스러운 스트리밍 경험을 제공합니다.
	- **종단간 지연 시간 (End-to-End Latency, E2E):** 요청 <u>시작부터 최종 응답이 완료될 때까지 걸리는 총 시간</u>으로, 네트워크 오버헤드, 전처리, 전체 생성 주기를 모두 포함합니다.
- **처리량 (Throughput) 또는 트래픽 (Traffic):** <u>시스템에 가해지는 부하의 양</u>으로, 주로 QPS(Queries Per Second) 또는 RPS(Requests Per Second) 단위로 측정됩니다. 트래픽을 모니터링하면 용량 계획을 수립하고 비정상적인 부하 패턴을 식별하는 데 도움이 됩니다.
- **동시성 (Concurrency):** 시스템이 <u>동시에 처리할 수 있는 요청의 수</u>입니다. 이 지표는 Knative Pod Autoscaler(KPA)와 같은 오토스케일링 시스템의 핵심적인 스케일링 기준으로 사용됩니다.
- **오류율 (Error Rate):** <u>실패하는 요청의 비율</u>입니다. 이는 시스템 문제의 직접적인 지표이므로, 오류율의 급격한 증가는 즉각적인 대응이 필요한 경고 신호로 간주해야 합니다.
- **포화도 (Saturation):** 시스템이 얼마나 '가득 찼는지'를 나타내는 지표로, CPU, 메모리, GPU 사용률과 같이 가장 제약이 심한 <u>자원의 활용도를 측정</u>합니다. 포화도는 미래의 문제를 예측하는 선행 지표입니다. 포화도가 높아지면 지연 시간이 증가하고 오류율이 상승하는 경향이 있습니다.

### 모델 성능: 실제 환경에서의 예측 품질 추적

시스템 상태와 달리, 모델의 예측 성능은 <u>'실제 값(ground truth)', 즉 예측 대상의 실제 결과가 확인되어야만 정확하게 측정</u>할 수 있습니다. 실제 값은 즉시 확인되지 않고 지연되어 도착하거나, 경우에 따라서는 아예 획득이 불가능할 수도 있어 모델 성능을 직접적으로 모니터링하는 것은 상당한 도전 과제일 수 있습니다.

모델 성능을 평가하는 핵심 지표는 해결하려는 과제의 종류에 따라 달라집니다.

- **분류 (Classification):** 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-점수(F1-Score), AUC-ROC(Area Under the Receiver Operating Characteristic Curve) 등이 사용됩니다.
- **회귀 (Regression):** 평균 절대 오차(Mean Absolute Error, MAE), 평균 제곱 오차(Mean Squared Error, MSE), 평균 제곱근 오차(Root Mean Squared Error, RMSE) 등이 주로 사용됩니다.

모델의 성공은 비즈니스 핵심 성과 지표(KPI)에 미치는 영향으로 평가됩니다. 매출 증대, 사용자 참여도 향상, 비용 절감과 같은 <u>비즈니스 지표를 측정하기 위해서는 모델 예측 결과를 다운스트림의 비즈니스 이벤트 데이터와 결합하여 분석</u>하는 과정이 필요합니다.

### 데이터 무결성: 드리프트 탐지 및 완화

모델의 성능은 시간이 지남에 따라 자연스럽게 저하되는 경향이 있는데, 이는 프로덕션 환경에서 모델이 마주하는 실제 데이터('추론 데이터')가 모델을 학습시켰던 과거의 데이터('학습 데이터')와 달라지기 때문입니다. 이러한 현상을 '드리프트(drift)'라고 합니다.

드리프트는 여러 형태로 나타날 수 있습니다.

- **데이터 드리프트 (Data Drift) 또는 피처 드리프트 (Feature Drift):** 모델 <u>입력 피처의 통계적 분포가 변화하는 현상</u>입니다. 예를 들어, 사용자의 평균 구매 금액이 시간이 지남에 따라 점차 증가하는 경우입니다. 이는 콜모고로프-스미르노프(Kolmogorov-Smirnov) 검정과 같은 통계적 검정이나 분포 간의 거리를 측정하는 지표를 통해 탐지할 수 있습니다.
- **개념 드리프트 (Concept Drift):** 입력 피처와 목표 변수(target variable) 사이의 관계 자체가 변화하는 현상입니다. 예를 들어, 새로운 경쟁사의 마케팅 캠페인으로 인해 고객 이탈을 예측하는 <u>주요 요인이 바뀌는 경우</u>입니다. 개념 드리프트는 직접 탐지하기 어려우며, 보통 <span style="background:#fff88f">모델 성능 지표의 하락을 통해 간접적으로 추론</span>됩니다.
- **예측 드리프트 (Prediction Drift):** 모델이 출력하는 <u>예측 값의 분포가 시간이 지남에 따라 변화하는 현상</u>입니다. 이는 데이터 드리프트나 개념 드리프트의 발생을 암시하는 조기 경고 신호가 될 수 있습니다.
- **학습-서빙 편향 (Training-Serving Skew):** 모델 학습 시 사용된 데이터 전처리 파이프라인과 실제 서빙 환경의 전처리 <u>파이프라인 간에 불일치</u>가 존재하여 발생하는 특별한 형태의 데이터 드리프트입니다. 이는 모델 배포 직후 성능 저하의 주요 원인이 됩니다.

이러한 모니터링 요소들은 문제 발생 시 <u>서로 다른 시간적 특성을 보이며 계층적 관계를 형성</u>합니다. 예를 들어, 상위 데이터 소스의 스키마가 변경되면(데이터 무결성 문제), 모델은 예상치 못한 입력을 받게 되어 예측 오류가 급증할 수 있습니다(시스템 상태 문제). 시간이 지나면서 이러한 부정확한 예측들은 비즈니스 성과에 악영향을 미치고, 최종적으로 실제 값 데이터가 수집되었을 때 정확도 하락으로 나타납니다(모델 성능 문제). 효과적인 모니터링 전략은 이 인과 사슬의 가장 앞 단계, 즉 데이터 무결성 단계에서 문제를 포착하는 것을 목표로 해야 합니다.

또한, 모니터링 전략은 <span style="background:#fff88f">실제 값 획득의 비용과 지연 시간에 따라 결정</span>됩니다. 만약 실제 값이 실시간으로 확인 가능하다면(예: 추천 시스템의 클릭 여부), <u>정밀도와 같은 모델 성능 지표를 직접 모니터링하고 경고 기준</u>으로 삼을 수 있습니다. 그러나 실제 값 확인에 수 주가 걸린다면(예: 대출 부도 예측), 실시간 장애 대응을 위해 모델 정확도를 모니터링하는 것은 무의미합니다. <u>이런 시나리오에서는 데이터 드리프트나 예측 드리프트와 같은 대리 지표(proxy metrics)를 주요 경고 메커니즘으로 활용</u>할 수밖에 없습니다. 이는 모니터링 아키텍처가 모든 경우에 적용되는 단일 해법이 아니라, 특정 비즈니스 문제와 데이터 수명주기에 맞춰 설계되어야 함을 시사합니다.

| 구분              | 지표명                             | 정의                                  | 중요성                                           |
| ----------------- | ---------------------------------- | ------------------------------------- | ------------------------------------------------ |
| **시스템 상태**   | 지연 시간 (p99 Latency)            | 요청의 99%를 처리하는 데 걸리는 시간  | 대부분의 사용자가 경험하는 서비스 응답성 측정    |
|                   | 처리량 (Throughput)                | 단위 시간당 처리하는 요청 수 (RPS)    | 시스템 부하 및 용량 계획의 기준                  |
|                   | 오류율 (Error Rate)                | 전체 요청 중 실패한 요청의 비율 (%)   | 서비스 안정성 및 즉각적인 장애 감지              |
|                   | 자원 활용도 (Resource Utilization) | CPU/GPU/메모리 사용률 (%)             | 시스템 포화도 및 잠재적 성능 저하 예측           |
| **모델 성능**     | 정확도 (Accuracy)                  | 전체 예측 중 올바르게 예측한 비율     | 모델의 전반적인 예측 정확성 평가                 |
|                   | 정밀도/재현율 (Precision/Recall)   | 예측의 질과 커버리지를 평가하는 지표  | 불균형 데이터셋에서 모델 성능을 다각도로 평가    |
|                   | MAE/MSE                            | 실제 값과 예측 값의 평균 오차         | 회귀 모델의 예측 오차 크기 정량화                |
|                   | 비즈니스 KPI                       | 클릭률, 전환율, 매출 등               | 모델이 비즈니스 목표에 기여하는 정도를 직접 측정 |
| **데이터 무결성** | 데이터 드리프트 점수               | 학습 데이터와 추론 데이터의 분포 차이 | 모델 성능 저하의 선행 지표                       |
|                   | 예측 드리프트 점수                 | 시간 경과에 따른 예측 값 분포의 변화  | 데이터 또는 개념 드리프트의 조기 경고            |
|                   | 피처 Null 비율                     | 입력 피처의 결측치 비율               | 데이터 파이프라인의 품질 및 안정성 확인          |
|                   | 학습-서빙 편향                     | 학습과 서빙 환경 간의 데이터 불일치   | 배포 직후 성능 저하의 원인 진단                  |


### 1.2. 내재된 상충 관계: 지연 시간 대 처리량

모델 서빙 시스템 설계 시 가장 근본적인 상충 관계 중 하나는 <u>개별 요청의 지연 시간을 최소화하는 것과 시스템 전체의 처리량을 최대화하는 것 사이에서 발생</u>합니다.

예를 들어, **배치(Batching)** 기술은 여러 요청을 하나로 묶어 GPU에서 한 번에 처리함으로써 GPU의 활용률을 높여 전체 처리량을 향상시킵니다. 하지만 이 방식은 배치가 채워질 때까지 기다려야 하므로, 배치에 포함된 각 개별 요청의 지연 시간은 증가하게 됩니다. 반대로, 모든 요청을 도착하는 즉시 개별적으로 처리하면 지연 시간은 최소화되지만, GPU가 충분히 활용되지 않아 전체 처리량은 낮아질 수 있습니다. 이처럼 지연 시간과 처리량은 서로 반비례 관계에 있는 경우가 많으며, 서비스의 요구사항에 따라 이 <span style="background:#fff88f">둘 사이의 적절한 균형점을 찾는 것</span>이 시스템 아키텍처 설계의 핵심 과제입니다.

### 1.3. 벤치마킹 방법론: 이론에서 실제로

하드웨어 선택, 모델 아키텍처, 최적화 전략에 대한 정보에 입각한 결정을 내리기 위해서는 신뢰할 수 있는 벤치마킹이 필수적입니다. 효과적인 벤치마킹은 단순히 스크립트를 실행하는 것을 넘어, 실제 운영 환경을 정확하게 모사하고 의미 있는 결과를 도출하는 체계적인 과정입니다.

- **핵심 벤치마킹 실천 방안:**
  - **현실적인 워크로드 사용:** <span style="background:#fff88f">실제 프로덕션 환경의 트래픽 패턴(예: 요청 크기 분포, 동시 사용자 수)을 모방한 부하 테스트를 수행</span>해야 합니다.
  - **세분화된 지표 측정:** <span style="background:#fff88f">TTFT와 TPOT를 별도로 측정</span>하여 <u>성능 병목 현상이 입력 처리 단계(pre-fill)에 있는지, 아니면 토큰 생성 단계(decoding)에 있는지 명확히 구분</u>해야 합니다.
  - **변수 통제 및 편향 보정:** LLM 평가 시, <u>정답의 위치가 프롬프트 내 어디에 있는지에 따라 성능이 달라지는 '위치 편향'과 같은 잠재적 변수를 통제</u>해야 합니다. 이를 위해 정답 위치를 무작위로 바꾸어 여러 번 측정하고 평균을 내는 등의 기법이 사용될 수 있습니다.
  - **표준화된 벤치마크 활용:** 모델의 순수한 성능뿐만 아니라 지식 및 추론 능력을 평가하기 위해 <span style="background:#fff88f">ARC(AI2 Reasoning Challenge)와 같은 표준화된 벤치마크 데이터셋을 활용</span>하는 것이 중요합니다. 이는 성능 지표와 모델 품질 간의 균형을 평가하는 데 도움을 줍니다.
  - **전문 도구 활용:** NVIDIA Triton Performance Analyzer와 같은 전문 도구를 사용하면 다양한 부하 시나리오를 체계적으로 시뮬레이션하고, 지연 시간, 처리량, GPU 활용률 등 상세한 성능 지표를 수집하여 병목 지점을 정확히 분석할 수 있습니다.

이러한 성능 지표와 벤치마킹 방법론을 이해하는 것은 단순히 시스템의 현재 상태를 측정하는 것을 넘어, 미래의 아키텍처를 결정하는 나침반 역할을 합니다. 서비스의 핵심적인 사용자 상호작용 모델이 무엇인지 정의하는 것에서부터 최적화 여정이 시작됩니다. 예를 들어, 짧은 문답 위주의 챗봇 서비스는 E2E 지연 시간이 가장 중요한 지표일 수 있습니다. 반면, 긴 문서를 요약하거나 분석하는 RAG 애플리케이션의 경우, 사용자는 긴 입력이 처리되는 동안 발생하는 TTFT를 가장 민감하게 느낄 것입니다. 이 경우 TTFT를 줄이기 위해 <u>텐서 병렬화(Tensor Parallelism)와 같은 기술을 도입하여 여러 GPU에 걸쳐 입력 처리 작업을 분산시키는 아키텍처적 결정</u>이 필요할 수 있습니다. 한편, 긴 글을 생성하는 서비스에서는 약간의 TTFT 지연은 허용되더라도, 생성된 텍스트가 끊김 없이 부드럽게 스트리밍되는 것이 중요하므로 높은 TPOT(또는 OTPS)를 확보하는 것이 최우선 목표가 됩니다. 이처럼, 어떤 성능 지표에 우선순위를 둘 것인지 결정하는 것이 하드웨어 선택, 모델 최적화 전략, 그리고 궁극적으로는 비용 구조까지 모든 후속 단계를 좌우하는 첫 번째 전략적 선택입니다.

---




### 4.4. 장기적 신뢰성 확보: 모니터링과 드리프트 탐지

- **관측 가능성 (Observability) vs. 모니터링 (Monitoring):** 단순한 지표(CPU, 메모리)를 보는 모니터링을 넘어, 시스템의 외부 출력(로그, 메트릭, 트레이스)을 통해 내부 상태를 추론하고 이해하는 관측 가능성을 확보하는 것이 중요합니다.
- **모델 드리프트: 성능 저하의 조용한 암살자:** 프로덕션 데이터의 통계적 특성이 모델 학습 시점의 데이터와 달라지면서 시간이 지남에 따라 모델 성능이 저하되는 현상입니다.
  - **컨셉 드리프트 (Concept Drift):** 입력 피처와 목표 변수 간의 관계 자체가 변하는 경우입니다. 즉, 예측 대상의 '개념'이 바뀝니다 (예: '스팸 메일'의 패턴이 진화하는 경우).
  - **데이터 드리프트 (Data Drift):** 입력 데이터 자체의 통계적 분포가 변하는 경우입니다 (예: 새로운 연령대의 사용자가 서비스를 사용하기 시작하는 경우).
- **드리프트 탐지: 통계적 방법론:**
  - **Population Stability Index (PSI):** 두 시점 간에 변수의 분포가 얼마나 변했는지를 정량적으로 측정하는 지표입니다.
  - **Kolmogorov-Smirnov (K-S) Test:** 두 데이터 샘플의 누적 분포 함수를 비교하는 비모수 통계 검정입니다.
  - **KL 다이버전스 & JS 다이버전스:** 두 확률 분포 간의 차이를 측정하는 정보 이론 기반의 지표입니다.
- **해결 전략:**
  - **재학습 (Retraining):** 가장 일반적인 해결책으로, 최신 데이터를 사용하여 모델을 다시 학습시키고 재배포합니다.
  - **온라인 학습 (Online Learning):** <u>새로운 데이터를 작은 미니 배치 단위로 지속적으로 모델에 주입하여 실시간으로 업데이트</u>하는 방식입니다.
  - **모델 재설계:** 심각한 <u>컨셉 드리프트가 발생한 경우, 새로운 피처를 추가하거나 모델 아키텍처 자체를 변경</u>해야 할 수 있습니다.

이러한 MLOps의 접근 방식은 모델 관리를 수동적이고 사후 대응적인 활동에서 자동화된 사전 예방적 활동으로 전환시킵니다. 과거에는 비즈니스 KPI(매출, 사용자 참여도 등)가 하락한 뒤에야 원인을 분석하다가 모델 성능 저하를 발견하고 부랴부랴 재학습에 들어갔습니다. 이 과정은 느리고 비즈니스 손실을 유발합니다. 반면, 선진적인 MLOps는 PSI, K-S 테스트와 같은 통계적 모니터링 도구를 자동화하여, 모델 성능 저하가 비즈니스에 심각한 영향을 미치기 _전에_ 드리프트를 감지하고 경고를 보냅니다. 더 나아가, 설명가능 AI(XAI) 기법을 활용하면 단순히 드리프트 발생 여부뿐만 아니라, _어떤 피처에서_ 드리프트가 발생했는지 근본 원인을 진단하여 문제 해결 과정을 가속화할 수 있습니다. 결국 MLOps의 목표는 드리프트 발생을 막는 것이 아니라(이는 불가능에 가깝다), 드리프트 탐지까지의 시간(Time-to-Detection)과 해결까지의 시간(Time-to-Remediation)을 최소화하는 것입니다.


## 파트 4: ML 시스템을 위한 선제적 모니터링 및 사고 관리

마지막 파트에서는 모델 상태를 유지하고, 성능 저하를 감지하며, 프로덕션 환경에서의 장애에 대응하는 중요한 "Day 2" 운영 과제를 다룹니다. 이는 MLOps 성숙도가 진정으로 드러나는 부분입니다.

### 모델 및 시스템 상태의 실시간 모니터링

이 섹션에서는 프로덕션 ML 시스템을 관찰하는 "무엇을"과 "어떻게"에 대해 자세히 설명합니다.

#### 핵심 지표 정의 (무엇을 모니터링할 것인가)

모니터링은 단순히 시스템 상태를 넘어섭니다.

- **운영 지표:** 지연 시간, 처리량(초당 추론 수), 오류율, CPU/GPU/메모리 사용률. 이는 모든 서비스의 표준 지표입니다.
- **모델 성능 지표:** 실제 정답 레이블을 사용할 수 있는 경우(지연이 있더라도), 정확도, 정밀도, 재현율, F1-점수 또는 RMSE와 같은 비즈니스 관련 지표를 추적합니다.
- **데이터 및 예측 지표:** 입력 피처와 모델 예측의 통계적 분포를 추적합니다. 이러한 분포의 변화는 종종 문제의 가장 빠른 지표가 됩니다.

#### 모니터링 스택 구현 (어떻게 모니터링할 것인가)

- **계측(Instrumentation):** 애플리케이션 코드(예: Flask/FastAPI 서버 또는 Triton Python 백엔드)는 이러한 지표를 노출하도록 계측되어야 합니다. 이는 `prometheus-client`와 같은 클라이언트 라이브러리를 사용하여 수행됩니다.
- **프로메테우스(Prometheus):** 애플리케이션이 노출하는 `/metrics` 엔드포인트를 정기적으로 "스크랩"하여 수집된 데이터를 저장하는 오픈 소스 시계열 데이터베이스입니다.
- **그라파나(Grafana):** 프로메테우스를 데이터 소스로 연결하는 시각화 도구입니다. 수집된 지표를 시각화하고 지표가 미리 정의된 임계값을 초과할 때 경고를 설정하기 위한 그래프, 게이지 및 테이블이 포함된 실시간 대시보드를 구축할 수 있습니다.

ML 모니터링은 전통적인 소프트웨어 모니터링의 상위 집합입니다. 전통적인 SRE/DevOps는 애플리케이션의 운영 상태, 즉 '작동 중인가?', '빠른가?', '오류가 발생하는가?'와 같은 "운영 지표"에 중점을 둡니다. 그러나 ML 시스템에는 추가적인, 조용한 실패 모드가 있습니다. 시스템이 운영적으로는 완벽하게 건강하더라도(낮은 지연 시간, 오류 없음), 쓸모없는 예측을 생성하여 비즈니스에 부정적인 가치를 초래할 수 있습니다. 따라서 ML 모니터링은 애플리케이션 상태 모니터링에 더해 모델의 논리적 정확성과 통계적 안정성을 추적하기 위한 "모델 성능" 및 "데이터/예측" 지표를 반드시 포함해야 합니다. 이를 위해서는 관련 모델/데이터 지표를 정의하는 데이터 과학자와 모니터링 인프라를 구현하는 MLOps/SRE 간의 긴밀한 협력이 필요합니다. 결론적으로, 효과적인 ML 모니터링은 단순히 애플리케이션 상태를 모니터링하는 것에서 벗어나, 애플리케이션 상태, 데이터 상태, 모델 상태를 모두 모니터링하는 패러다임 전환을 요구합니다. 모니터링 스택(프로메테우스, 그라파나)은 동일하지만, 수집되는 지표 집합은 훨씬 더 광범위하고 통계 지향적입니다.

### 모델 성능 저하 감지 및 완화

이 섹션에서는 모델 성능이 시간이 지남에 따라 필연적으로 저하되는 "드리프트(drift)"라는 특정 과제에 중점을 둡니다.

#### 데이터 드리프트 대 개념 드리프트: 적을 이해하기

두 가지 주요 드리프트 유형을 구별하는 것이 중요합니다.

- **데이터 드리프트 (공변량 변화, Covariate Shift):** 입력 데이터의 통계적 분포(P(X))는 변하지만, 입력과 출력 간의 근본적인 관계는 동일하게 유지됩니다. 예: 여름 사진으로 학습된 이미지 분류기가 겨울 사진을 더 많이 받기 시작합니다. 픽셀 분포는 변하지만, 고양이는 여전히 고양이입니다.
- **개념 드리프트 (Concept Drift):** 입력 피처와 목표 변수 간의 관계(P(Y∣X))가 변합니다. 데이터 자체의 의미가 바뀐 것입니다. 예: 사기 탐지 모델이 새로운 규제나 경제 변화로 인해 고객 행동이 변하는 것을 봅니다. 동일한 거래 피처가 이제 사기 위험 측면에서 다른 의미를 갖게 됩니다.

#### 탐지 기법 개요

- **데이터 드리프트용 (레이블 불필요):** 들어오는 프로덕션 데이터의 분포를 참조 분포(예: 학습 데이터)와 비교합니다.
  - **통계적 검정:** 단변량 연속 데이터에 대한 콜모고로프-스미르노프(KS) 검정, 범주형 데이터에 대한 카이제곱 검정.
  - **거리 측정:** 인구 안정성 지수(PSI), 젠슨-섀넌 발산, 바서슈타인 거리.
- **개념 드리프트용 (레이블 필요 또는 프록시 사용):**
  - **직접 성능 모니터링:** 가장 신뢰할 수 있는 방법입니다. 레이블이 지정된 프로덕션 데이터에 대한 모델 정확도, F1-점수 등을 추적합니다. 상당한 하락은 개념 드리프트를 나타냅니다.
  - **예측 드리프트 모니터링 (프록시):** 즉각적인 레이블이 없는 경우, 모델의 _출력_ 분포를 모니터링합니다. 이전에 "스팸"을 5% 예측하던 모델이 갑자기 50%를 예측하기 시작하면, 무언가 변경되었을 가능성이 높습니다. 이는 조기 경고 신호입니다.
  - **드리프트 탐지 알고리즘:** DDM(Drift Detection Method) 또는 ADWIN(Adaptive Windowing)과 같은 특수 알고리즘을 모델의 오류율이나 다른 성능 지표에 적용하여 시간 경과에 따른 변화를 탐지할 수 있습니다.

#### 표 4.1: 이상 감지: 데이터 드리프트 대 개념 드리프트

이 구분은 프로덕션 모델 문제를 진단하는 데 근본적입니다. 엔지니어는 무엇을 찾고 어떤 도구를 사용해야 하는지 알아야 합니다. 이 표는 그 목적을 위한 명확하고 간결한 가이드를 제공합니다. 두 개념을 분리하고, 수학적 및 실제적 차이점을 설명하며, 각 개념에 특정 탐지 방법을 매핑하여 실행 가능한 진단 프레임워크를 제공합니다.

### ML 모델 사고에 대한 SRE 플레이북

이 마지막 섹션에서는 사이트 신뢰성 엔지니어링(SRE)의 원칙을 ML 시스템의 고유한 과제에 적용하여 사고 대응에 대한 구조화된 접근 방식을 제공합니다.

#### SRE 원칙을 MLOps에 적용하기

SRE는 IT 운영을 자동화하고 높은 신뢰성을 달성하기 위해 소프트웨어 엔지니어링 관행을 사용하는 것에 관한 것입니다. ML의 경우 이는 다음을 의미합니다.

- **서비스 수준 목표(SLO) 정의:** 표준 지연 시간 및 가용성 SLO를 넘어섭니다. **데이터 신선도**(모델이 학습하는 데이터가 얼마나 오래되었는가?), **예측 품질**(예: 28일 동안 정확도가 95% 이상이어야 함), **학습 파이프라인 완료율**과 같은 ML 관련 문제에 대한 SLO를 정의합니다.
- **오류 예산(Error Budgets):** SLO가 목표를 정의하고, 오류 예산은 허용 가능한 실패 수준입니다. 이 예산은 팀이 전체 오류 예산을 "소비"하지 않는 한 혁신하고 위험을 감수할 수 있도록 권한을 부여합니다.

#### 문제 진단을 위한 구조화된 플레이북

모델 성능 경고가 발생했을 때, 엔지니어는 임시방편적인 디버깅이 아닌 구조화된 계획이 필요합니다.

- **1단계: 분류 (실제 상황인가?):** 경고가 오탐이 아닌지 확인합니다. 모니터링 대시보드(Grafana)를 확인하여 문제의 범위와 기간을 파악합니다.
- **2단계: 도메인 격리 (시스템 대 데이터 대 모델):**
  - **시스템 문제인가?** 운영 지표를 확인합니다. 지연 시간이 높은가? 서버가 충돌하는가? 이는 전통적인 SRE 사고입니다.
  - **데이터 문제인가?** 데이터 드리프트 및 품질 대시보드를 확인합니다. null 값이 급증했는가? 입력 분포가 급격히 변했는가(데이터 드리프트)? 이는 상위 데이터 파이프라인 문제를 가리킵니다.
  - **모델 문제인가?** 시스템 및 데이터 지표는 정상이지만 예측 품질(정확도 등)이 떨어지는 경우, 이는 개념 드리프트 또는 모델 코드 자체의 버그를 가리킵니다.
- **3단계: 즉각적인 완화 (피해 확산 방지):**
  - 잘못된 배포인 경우, 이전 버전으로의 자동 **롤백**을 트리거합니다.
  - 특정 소스의 데이터 품질 문제인 경우, 가능하다면 해당 소스를 일시적으로 차단하는 것을 고려합니다.
- **4. 단계: 근본 원인 분석 (사후 검토):** 완화 조치 후, 근본 원인을 이해하기 위해 비난 없는 사후 검토를 수행합니다. 상위에서 데이터 스키마가 변경되었는가? 새로운 사용자 행동이 나타났는가?.
- **5단계: 수정 및 자동화:** 근본 원인을 수정합니다. 더 중요하게는, 이 특정 종류의 실패가 다시 발생하지 않도록 새로운 모니터링 검사나 자동화된 테스트를 추가합니다.

성숙한 MLOps는 성숙한 SRE와 구별할 수 없습니다. 초기 단계의 MLOps는 모델을 프로덕션 환경에 배포하는 데 중점을 둡니다(CI/CD, 배포). 시스템이 성숙해짐에 따라 초점은 배포에서 신뢰성과 유지보수로 이동하며, 이는 SRE의 핵심 영역입니다. SRE가 소프트웨어에 사용하는 원칙들(SLO, 오류 예산, 모니터링, 자동화된 사고 대응, 비난 없는 사후 검토)은 ML 시스템에 직접 적용될 수 있습니다. 유일한 차이점은 모니터링 및 관리 대상의 *범위*입니다. ML을 위한 SRE는 이러한 원칙을 <u>애플리케이션 코드뿐만 아니라 데이터 파이프라인과 모델의 통계적 행동까지 포괄하도록 확장</u>합니다. 결론적으로, MLOps의 최종 목표는 별개의 학문 분야가 되는 것이 아니라, SRE의 전문화된 한 분야가 되는 것입니다. 목표는 모델, 데이터, 코드를 단일의 신뢰할 수 있고 자동화된 프로덕션 시스템의 구성 요소로 취급하고, SRE가 전통적인 소프트웨어에 적용하는 것과 동일한 엔지니어링 엄격함으로 관리하는 것입니다.

## 마치며


> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.