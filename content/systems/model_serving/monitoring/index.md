---
title: 모델 서빙 모니터링
description: 모델 서빙을 위한 모니터링은 어떤 차이점이 있을까요?
date: 2025-09-18T19:03:00
lastmod: 2025-09-26
slug: monitoring
comments: true
math: false
categories:
  - Systems
tags:
  - Model-Serving
keywords:
  - Model-Serving
  - MLOps
---
## 개요

모델을 성공적으로 배포하는 것은 MLOps 수명주기의 시작입니다. 프로덕션 환경에 배포된 모델은 끊임없이 변화하는 데이터와 외부 환경의 영향을 받기 때문에, 지속적인 모니터링 없이는 성능과 안정성을 보장할 수 없습니다. 머신러닝 시스템의 모니터링은 전통적인 소프트웨어 모니터링의 범위를 넘어, <u>모델 자체의 예측 품질과 입력 데이터의 통계적 특성까지 포괄</u>해야 합니다.

 CI/CD, 드리프트 모니터링, 자동화된 재훈련의 조합은 피드백 루프를 형성합니다. 시스템은 단순히 배포되는 것이 아니라, <u>모니터링을 통해 환경을 능동적으로 '인식'하고, 원하는 상태(메트릭 임계값)와 성능을 비교하며, 항상성(비즈니스 가치)을 유지하기 위해 수정 조치(재훈련/재배포)</u>합니다. 전통적인 CI/CD 파이프라인이 선형적인 "푸시" 시스템이라면, MLOps는 라이브 서비스로부터 <u>통계를 수집하여 드리프트를 감지하고, 이를 파이프라인 재실행의 트리거로 사용</u>하는 피드백 경로를 추가합니다.

중요한 모니터링 대상에는 <u>시스템 성능뿐만 아니라, 시간이 지남에 따라 발생하는 드리프트(drift)도 포함</u>됩니다. 이러한 변화는 실제 환경의 변화에 대응하여 모델이 "엉망이 되는(go haywire)" 것을 방지하는 데 중요합니다.

이번 포스트에서는 모델 서빙 단계에서 수집하는 지표들과 목적을 이해하고, 목표 설정 시 고려해야 할 점을 알아보겠습니다.

## 목표 별 모니터링 지표

AI 모델 서빙은 세 가지 핵심 목표를 갖습니다.

1. **성능 (지연 시간/처리량):** 서비스가 얼마나 빠르고 반응성이 좋은가.
2. **정확도:** 모델의 예측이 얼마나 정확한가 (F1-점수, 정밀도, 재현율 등으로 측정).
3. **비용:** 하드웨어, 클라우드 리소스, 엔지니어링 노력을 포함한 총소유비용(TCO).

<span style="background:#fff88f">지연 시간과 처리량은 전적으로 서빙 시스템의 특성에 따라 결정</span>됩니다. 모델의 예측 품질은 학습 단계의 영향력이 가장 크지만, 서빙 단계의 영향력도 확대되고 있습니다.

비용은 아키텍처와 관련이 깊습니다. 이에 대해서는 다음 포스트에서 아키텍처와 함께 알아보고, 이번 포스트에서는 나머지 두 목표를 먼저 알아보겠습니다.

### 시스템 상태

여기에서도 구글의 사이트 신뢰성 엔지니어링(Site Reliability Engineering, SRE) 프랙티스에서 유래한 '**네 가지 황금 신호(Four Golden Signals)**'는 모든 서빙 인프라의 상태를 종합적으로 파악할 수 있는 핵심 지표입니다. 이 신호들은 시스템 수준의 문제를 감지하는 첫 번째 방어선 역할을 합니다.

#### 지연 시간 (Latency)

<u>클라이언트가 요청을 보낸 후 응답을 받기까지의 전체 왕복 시간</u>을 의미하며, 네트워크 오버헤드와 모델 실행 시간을 모두 포함합니다. 이는 사용자 경험에 직접적인 영향을 미치는 가장 중요한 지표 중 하나입니다.

성공한 요청과 실패한 요청의 지연 시간을 구분하여 추적하는 것이 중요하며, 특히 p95, p99와 같은 백분위수(percentile)를 모니터링하여 일부 사용자가 겪는 최악의 경험을 파악해야 합니다. 

LLM의 경우, 사용자가 체감하는 응답성은 여러 단계로 나뉘어 측정됩니다.

##### 첫 토큰까지의 시간 (Time to First Token, TTFT)

사용자가 요청을 보낸 후 <u>응답의 첫 번째 조각(토큰)이 생성될 때까지 걸리는 시간</u>입니다. 이 지표는 챗봇과 같은 대화형 애플리케이션에서 사용자가 느끼는 '즉각적인 반응성'을 결정하는 가장 중요한 요소입니다. 

특히 긴 컨텍스트나 문서를 입력으로 사용하는 검색 증강 생성(RAG)과 같은 애플리케이션에서는 입력 프롬프트를 처리하는 데 상당한 시간이 소요되므로 TTFT가 전체 지연 시간에서 큰 비중을 차지하게 됩니다.

##### 초당 출력 토큰 수 (Output Tokens Per Second, OTPS)

첫 토큰이 생성된 후, <u>후속 토큰들이 생성되는 속도</u>입니다. 이 지표는 응답이 얼마나 '매끄럽게' 생성되는지를 나타내며, 긴 형식의 콘텐츠를 생성하는 작업에서 중요합니다. 높은 OTPS는 사용자가 응답을 읽는 속도에 맞춰 자연스러운 스트리밍 경험을 제공합니다. **출력 토큰당 시간 (Time Per Output Token, TPOT)** 으로도 나타냅니다.

##### 종단간 지연 시간 (End-to-End Latency, E2E)

요청 <u>시작부터 최종 응답이 완료될 때까지 걸리는 총 시간</u>으로, 네트워크 오버헤드, 전처리, 전체 생성 주기를 모두 포함합니다.

#### 처리량 (Throughput)

시스템이 주어진 시간 동안 처리할 수 있는 요청의 양, 즉 시스템의 용량을 나타내며 초당 요청 수(RPS, Requests Per Second) 또는 초당 쿼리 수(QPS, Queries Per Second)로 측정됩니다.

<u>시스템에 가해지는 부하의 양</u>인 트래픽 (Traffic)을 모니터링하면 용량 계획을 수립하고 비정상적인 부하 패턴을 식별하는 데 도움이 됩니다.

##### 동시성 (Concurrency)

시스템이 <u>동시에 처리할 수 있는 요청의 수</u>입니다. 이 지표는 오토스케일링 시스템의 핵심적인 스케일링 기준으로 사용됩니다.

#### 오류율 (Error Rate)

<u>실패하는 요청의 비율</u>입니다. 오류율의 급격한 증가는 즉각적인 대응이 필요한 경고 신호로 간주해야 합니다.

#### 포화도 (Saturation)

시스템이 얼마나 '가득 찼는지'를 나타내는 지표로, CPU, 메모리, GPU 사용률과 같이 가장 제약이 심한 <u>자원의 활용도를 측정</u>합니다. 포화도는 미래의 문제를 예측하는 선행 지표입니다. 포화도가 높아지면 지연 시간이 증가하고 오류율이 상승하는 경향이 있습니다.

### 예측 성능

모델의 예측 품질을 나타내는 지표입니다. 시스템 상태와 달리, 모델의 예측 성능은 <u>'실제 값(ground truth)', 즉 예측 대상의 실제 결과가 확인되어야만 정확하게 측정</u>할 수 있습니다. 

실제 값은 즉시 확인되지 않고 지연되어 도착하거나, 경우에 따라서는 아예 획득이 불가능할 수도 있어 모델 성능을 직접적으로 모니터링하는 것은 상당한 도전 과제일 수 있습니다.

모델 성능을 평가하는 핵심 지표는 해결하려는 과제의 종류에 따라 달라집니다.

- **분류 (Classification):** 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-점수(F1-Score), AUC-ROC(Area Under the Receiver Operating Characteristic Curve) 등이 사용됩니다.
- **회귀 (Regression):** 평균 절대 오차(Mean Absolute Error, MAE), 평균 제곱 오차(Mean Squared Error, MSE), 평균 제곱근 오차(Root Mean Squared Error, RMSE) 등이 주로 사용됩니다.

#### 서빙 시스템의 역할 확대

현대적인 서빙 시스템에서는 "**정확도 스케일링(Accuracy Scaling)**"이 중요해지고 있습니다. 이는 시스템에 과부하가 걸렸을 때, 지연 시간 SLO를 준수하기 위해 정확도가 약간 낮지만 더 빠른 모델 변형(variant)을 동적으로 사용하여 전체 시스템의 안정성을 유지하는 전략입니다.

이는 서빙 시스템이 정적인 컴포넌트가 아니라, 실시간으로 성능과 정확도 간의 트레이드오프를 관리하는 동적인 시스템임을 시사합니다.

## 선제적 탐지 목표: 드리프트

모델의 성능은 시간이 지남에 따라 자연스럽게 저하되는 경향이 있는데, 이는 프로덕션 환경에서 모델이 마주하는 실제 데이터('추론 데이터')가 모델을 학습시켰던 과거의 데이터('학습 데이터')와 달라지기 때문입니다. 이러한 현상을 '**드리프트(drift)**'라고 합니다.

배포된 모델은 정적인 자산이 아니라, 세상에 대한 동적인 가설이며 <span style="background:#fff88f">지속적으로 검증</span>되어야 합니다. 이는 쉽게 변경되지 않는 전통 소프트웨어의 결정론적인 특성과의 차이점입니다.

### 개념 드리프트 (Concept Drift)

<u>입력 피처와 목표 변수(target variable) 사이의 관계 자체가 변화</u>하는 현상입니다. 예를 들어, 새로운 경쟁사의 마케팅 캠페인으로 인해 고객 이탈을 예측하는 <u>주요 요인이 바뀌는 경우</u>나, 2020년에 스팸을 탐지하도록 훈련된 모델이 2025년에는 실패하는 경우입니다. 이는 스팸을 구성하는 _개념_ 자체가 진화했기 때문입니다.

개념 드리프트는 직접 탐지하기 어려우며, 보통 <span style="background:#fff88f">모델 성능 지표의 하락을 통해 간접적으로 추론</span>됩니다. 탐지를 위해 레이블이 필요합니다.

- **직접 성능 모니터링:** 가장 신뢰할 수 있는 방법입니다. 레이블이 지정된 프로덕션 데이터에 대한 모델 정확도, F1-점수 등을 추적합니다. 상당한 하락은 개념 드리프트를 나타냅니다.
- **드리프트 탐지 알고리즘:** DDM(Drift Detection Method) 또는 ADWIN(Adaptive Windowing)과 같은 특수 알고리즘을 모델의 오류율이나 다른 성능 지표에 적용하여 시간 경과에 따른 변화를 탐지할 수 있습니다.

> <font color="#245bdb"><b>NOTE: 개념 드리프트 감지 모니터링 신호</b></font>
> 
> 드리프트 감지를 위한 필수 모니터링 신호는 다음과 같습니다.
> 
> - **모델 성능 메트릭:** <span style="background:#fff88f">실제 값(ground truth)</span>을 얻을 수 있는 경우, <u>정확도, 정밀도, 재현율, F1-score</u>와 같은 직접적인 측정 지표를 추적합니다.
> - **예측 드리프트:** <span style="background:#fff88f">모델 출력의 통계적 분포</span>를 모니터링합니다. 대출 승인 모델이 갑자기 30%가 아닌 90%의 신청자를 승인하기 시작한다면, 드리프트 발생 가능성이 높습니다.
> - **데이터 드리프트 및 품질:** <span style="background:#fff88f">입력 데이터의 통계적 분포와 무결성</span>을 모니터링합니다. 여기에는 <u>null 값 비율, 데이터 유형 오류, 피처 분포의 변화(Kolmogorov-Smirnov 테스트, PSI 등) 추적</u>이 포함됩니다.

### 데이터 드리프트 (Data Drift)

**피처 드리프트 (Feature Drift)** 로도 불립니다. 모델 <u>입력 피처의 통계적 분포가 변화하는 현상</u>입니다. 예를 들어, 사용자의 평균 구매 금액이 시간이 지남에 따라 점차 증가하는 경우나, 새로운 연령대의 사용자가 서비스를 사용하기 시작하는 경우입니다.

프로덕션 입력 데이터의 분포를 참조 분포(예: 학습 데이터)와 비교합니다. 콜모고로프-스미르노프(Kolmogorov-Smirnov) 검정과 같은 통계적 검정이나 분포 간의 거리를 측정하는 지표를 통해 탐지할 수 있습니다. (레이블 불필요)

  - **통계적 검정:** 단변량 연속 데이터에 대한 콜모고로프-스미르노프(KS) 검정, 범주형 데이터에 대한 카이제곱 검정.
      - **Kolmogorov-Smirnov (K-S) Test:** 두 데이터 샘플의 누적 분포 함수를 비교하는 비모수 통계 검정입니다.
  - **거리 측정:** 인구 안정성 지수(PSI), 젠슨-섀넌 발산, 바서슈타인 거리.
      - **Population Stability Index (PSI):** 두 시점 간에 변수의 분포가 얼마나 변했는지를 정량적으로 측정하는 지표입니다.
      - **KL 다이버전스 & JS 다이버전스:** 두 확률 분포 간의 차이를 측정하는 정보 이론 기반의 지표입니다.

> <font color="#245bdb"><b>NOTE: 학습-서빙 편향 (Training-Serving Skew)</b></font>
>
> 모델 학습 시 사용된 데이터 전처리 파이프라인과 실제 서빙 환경의 전처리 <u>파이프라인 간에 불일치</u>가 존재하여 발생하는 특별한 형태의 데이터 드리프트입니다. 이는 모델 배포 직후 성능 저하의 주요 원인이 됩니다.

> <font color="#245bdb"><b>TIP: 데이터 드리프트와 개념 드리프트의 차이점</b></font>
> 
> - **데이터 드리프트 (공변량 변화, Covariate Shift):** 입력 데이터의 통계적 분포(P(X))는 변하지만, 입력과 출력 간의 근본적인 관계는 동일하게 유지됩니다. 예: 여름 사진으로 학습된 이미지 분류기가 겨울 사진을 더 많이 받기 시작합니다. 픽셀 분포는 변하지만, 고양이는 여전히 고양이입니다.
> - **개념 드리프트 (Concept Drift):** 입력 피처와 목표 변수 간의 관계(P(Y∣X))가 변합니다. 데이터 자체의 의미가 바뀐 것입니다. 예: 사기 탐지 모델이 새로운 규제나 경제 변화로 인해 고객 행동이 변하는 것을 봅니다. 동일한 거래 피처가 이제 사기 위험 측면에서 다른 의미를 갖게 됩니다.

### 예측 드리프트 (Prediction Drift)

모델이 출력하는 <u>예측 값의 분포가 시간이 지남에 따라 변화하는 현상</u>입니다. 이는 데이터 드리프트나 개념 드리프트의 조기 경고 신호가 될 수 있습니다.

- **프록시 사용:** 즉각적인 레이블이 없는 경우, 모델의 _출력_ 분포를 모니터링합니다. 이전에 "스팸"을 5% 예측하던 모델이 갑자기 50%를 예측하기 시작하면, 무언가 변경되었을 가능성이 높습니다.

### 해결 전략

  - **재학습 (Retraining):** 가장 일반적인 해결책으로, 최신 데이터를 사용하여 모델을 다시 학습시키고 재배포합니다.
  - **온라인 학습 (Online Learning):** <u>새로운 데이터를 작은 미니 배치 단위로 지속적으로 모델에 주입하여 실시간으로 업데이트</u>하는 방식입니다.
  - **모델 재설계:** 심각한 <u>컨셉 드리프트가 발생한 경우, 새로운 피처를 추가하거나 모델 아키텍처 자체를 변경</u>해야 할 수 있습니다.



## 관측 가능성 (Observability) 확보

전통적인 모니터링은 <u>CPU/메모리 사용량, 지연 시간, 오류율</u>과 같은 운영 메트릭에 중점을 둡니다. MLOps 모니터링은 <u>이를 포함하면서도 더 나아가</u> 모델을 위한 "인식" 시스템으로서 기능해야 합니다. 이를 위해선 단순한 지표(CPU, 메모리)를 보는 모니터링을 넘어, 시스템의 외부 출력(로그, 메트릭, 트레이스)을 통해 내부 상태를 추론하고 이해하는 관측 가능성을 확보하는 것이 중요합니다.

### 모니터링 스택

모니터링을 위해 사용되는 기술 스택은 다른 소프트웨어와 유사합니다:

- **계측(Instrumentation):** 애플리케이션 코드(예: Flask/FastAPI 서버 또는 Triton Python 백엔드)는 이러한 지표를 노출하도록 계측되어야 합니다. 이는 `prometheus-client`와 같은 클라이언트 라이브러리를 사용하여 수행됩니다.
- **프로메테우스(Prometheus):** 애플리케이션이 노출하는 `/metrics` 엔드포인트를 정기적으로 "스크랩"하여 수집된 데이터를 저장하는 오픈 소스 시계열 데이터베이스입니다.
- **그라파나(Grafana):** 프로메테우스를 데이터 소스로 연결하는 시각화 도구입니다. 수집된 지표를 시각화하고 지표가 미리 정의된 임계값을 초과할 때 경고를 설정하기 위한 그래프, 게이지 및 테이블이 포함된 실시간 대시보드를 구축할 수 있습니다.

### 주요 지표

효과적인 ML 모니터링은 애플리케이션 상태 뿐만 아니라 데이터 상태, 모델 상태를 모두 모니터링하는 패러다임 전환을 요구합니다. 모니터링 스택(프로메테우스, 그라파나)은 동일하지만, 수집되는 지표 집합은 훨씬 더 광범위하고 통계 지향적입니다.

- **운영 지표:** 지연 시간, 처리량(초당 추론 수), 오류율, CPU/GPU/메모리 사용률. (모든 서비스의 표준 지표)
- **모델 성능 지표:** 정확도, 정밀도, 재현율, F1-점수 또는 RMSE와 같은 비즈니스 관련 지표 추적 (실제 정답 레이블을 사용할 수 있는 경우)
- **데이터 및 예측 지표:** 입력 피처와 모델 예측의 통계적 분포 추적

| 구분              | 지표명                             | 정의                                  | 중요성                                           |
| ----------------- | ---------------------------------- | ------------------------------------- | ------------------------------------------------ |
| **시스템 상태**   | 지연 시간 (p99 Latency)            | 요청의 99%를 처리하는 데 걸리는 시간  | 대부분의 사용자가 경험하는 서비스 응답성 측정    |
|                   | 처리량 (Throughput)                | 단위 시간당 처리하는 요청 수 (RPS)    | 시스템 부하 및 용량 계획의 기준                  |
|                   | 오류율 (Error Rate)                | 전체 요청 중 실패한 요청의 비율 (%)   | 서비스 안정성 및 즉각적인 장애 감지              |
|                   | 자원 활용도 (Resource Utilization) | CPU/GPU/메모리 사용률 (%)             | 시스템 포화도 및 잠재적 성능 저하 예측           |
| **모델 성능**     | 정확도 (Accuracy)                  | 전체 예측 중 올바르게 예측한 비율     | 모델의 전반적인 예측 정확성 평가                 |
|                   | 정밀도/재현율 (Precision/Recall)   | 예측의 질과 커버리지를 평가하는 지표  | 불균형 데이터셋에서 모델 성능을 다각도로 평가    |
|                   | MAE/MSE                            | 실제 값과 예측 값의 평균 오차         | 회귀 모델의 예측 오차 크기 정량화                |
|                   | 비즈니스 KPI                       | 클릭률, 전환율, 매출 등               | 모델이 비즈니스 목표에 기여하는 정도를 직접 측정 |
| **데이터 무결성** | 데이터 드리프트 점수               | 학습 데이터와 추론 데이터의 분포 차이 | 모델 성능 저하의 선행 지표                       |
|                   | 예측 드리프트 점수                 | 시간 경과에 따른 예측 값 분포의 변화  | 데이터 또는 개념 드리프트의 조기 경고            |
|                   | 피처 Null 비율                     | 입력 피처의 결측치 비율               | 데이터 파이프라인의 품질 및 안정성 확인          |
|                   | 학습-서빙 편향                     | 학습과 서빙 환경 간의 데이터 불일치   | 배포 직후 성능 저하의 원인 진단                  |

전통적인 SRE/DevOps는 애플리케이션의 운영 상태, 즉 '작동 중인가?', '빠른가?', '오류가 발생하는가?'와 같은 "운영 지표"에 중점을 둡니다. 하지만 시스템이 건강하더라도, 쓸모없는 예측을 생성하여 비즈니스에 부정적인 가치를 초래할 수 있습니다.

따라서 ML 모니터링은 애플리케이션 상태 모니터링에 더해 모델의 논리적 정확성과 통계적 안정성을 추적하기 위한 <u>"모델 성능" 및 "데이터/예측" 지표를 반드시 포함</u>해야 합니다. 그리고 이 지표들로 <span style="background:#fff88f">드리프트를 탐지</span>해야 합니다. 이러한 MLOps의 접근 방식은 모델 관리를 수동적이고 사후 대응적인 활동에서 자동화된 사전 예방적 활동으로 전환시킵니다. 

과거에는 비즈니스 KPI(매출, 사용자 참여도 등)가 하락한 뒤에야 원인을 분석하여 모델 성능 저하를 발견하고 재학습을 수행했습니다. 이 과정은 느리고 비즈니스 손실을 유발합니다.

반면, MLOps는 PSI, K-S 테스트와 같은 통계적 모니터링 도구를 자동화하여, 모델 성능 저하가 비즈니스에 심각한 <span style="background:#fff88f">영향을 미치기 전에 드리프트를 감지하고 경고</span>를 보냅니다. 더 나아가, 설명가능 AI(XAI) 기법을 활용하면 단순히 드리프트 발생 여부뿐만 아니라, _어떤 피처에서_ 드리프트가 발생했는지 근본 원인을 진단하여 문제 해결 과정을 가속화합니다. 

MLOps의 목표는 드리프트 발생을 막는 것이 아니라, 드리프트 탐지까지의 시간(Time-to-Detection)과 해결까지의 시간(Time-to-Remediation)을 최소화하는 것입니다.

### 모니터링 아키텍처

하나의 위협이 전체 모니터링 지표에 어떤 영향을 끼칠까요? 예를 들어 상위 데이터 소스의 스키마가 변경되면(데이터 무결성 문제), 모델은 예상치 못한 입력을 받게 되어 예측 오류가 급증할 수 있습니다(시스템 상태 문제). 시간이 지나면서 이러한 부정확한 예측들은 비즈니스 성과에 악영향을 미치고, 최종적으로 실제 값 데이터가 수집되었을 때 정확도 하락으로 나타납니다(모델 성능 문제).

이처럼 ML 모니터링 요소들은 문제 발생 시 <u>서로 다른 시간적 특성을 보이며 계층적 관계를 형성</u>합니다. 효과적인 모니터링 전략은 인과 사슬의 가장 앞 단계, 즉 <span style="background:#fff88f">데이터 무결성 단계에서 문제를 포착</span>하는 것을 목표로 해야 합니다.

모니터링 전략은 <span style="background:#fff88f">실제 값을 획득하기 위한 비용과 지연 시간에 따라 결정</span>됩니다. 만약 실제 값이 실시간으로 확인 가능하다면(예: 추천 시스템의 클릭 여부), <u>정밀도와 같은 모델 성능 지표를 직접 모니터링하고 경고 기준</u>으로 삼을 수 있습니다. 

그러나 실제 값 확인에 수 주가 걸린다면(예: 대출 부도 예측), 실시간 장애 대응을 위해 모델 정확도를 모니터링하는 것은 무의미합니다. <u>이런 시나리오에서는 데이터 드리프트나 예측 드리프트와 같은 대리 지표(proxy metrics)를 주요 경고 메커니즘으로 활용</u>할 수밖에 없습니다. 

이는 모니터링 아키텍처가 모든 경우에 적용되는 단일 해법이 아니라, <span style="background:#fff88f">특정 비즈니스 문제와 데이터 수명주기에 맞춰 설계되어야 함</span>을 시사합니다.


## 평가 지표

모델의 성공은 비즈니스 핵심 성과 지표(KPI)에 미치는 영향으로 평가됩니다. 매출 증대, 사용자 참여도 향상, 비용 절감과 같은 <u>비즈니스 지표를 측정하기 위해서는 모델 예측 결과를 다운스트림의 비즈니스 이벤트 데이터와 결합하여 분석</u>하는 과정이 필요합니다.

모델 서빙 시스템의 성공은 궁극적으로 비즈니스 가치에 얼마나 기여하는지로 측정됩니다. 따라서 모든 기술적 결정은 비즈니스 요구사항에서 시작해야 합니다. 머신러닝 시스템에 대한 일반적인 비즈니스 기준은 <u>높은 품질의 결과, 낮은 지연 시간(Latency), 그리고 높은 처리량(Throughput)</u>입니다. 

### 삼중고 (Trilemma)

성능, 정확도, 비용의 세 목표는 서로 긴밀하게 연결되어 있어 하나를 개선하면 다른 하나가 저하되는 경우가 많습니다. 이처럼 목표 간 균형을 잡아야 하는 경우를 '**삼중고(Trilemma)**'라 합니다.

예를 들어, 더 크고 복잡한 모델은 일반적으로 더 높은 정확도를 보이지만, 추론에 더 많은 시간과 컴퓨팅 자원을 필요로 하므로 성능(지연 시간)이 저하되고 비용은 증가합니다. 반대로, 양자화와 같은 최적화 기법은 모델 크기를 줄여 성능을 높이고 비용을 절감하지만, 정확도가 낮아질 수 있습니다. 

이러한 상충 관계는 최적화 과정을 복잡하게 만들었습니다:

1. **처리량 극대화.** 한 번에 많은 요청을 처리하도록 배치 크기를 늘립니다.
2. **KV 캐시 문제 발생.** 배치 크기가 커지면 동시 요청이 증가합니다. 각 요청은 동적으로 커지는 KV 캐시를 가지고 있으며, 모든 KV 캐시에 필요한 총 메모리는 GPU의 VRAM을 빠르게 초과하므로 최대 배치 크기를 제한하여 처리량을 제한합니다.
3. **자기회귀 문제 (지연 시간).** 요청들은 서로 다른 길이를 가집니다. 단순한 <u>"정적 배치(static batching)" 시스템에서는 전체 배치가 가장 긴 요청이 토큰 생성을 마칠 때까지 기다려야</u> 합니다. 이는 막대한 유휴 시간(GPU 비활용)을 발생시키고 모든 짧은 요청의 평균 지연 시간을 증가시킵니다. 이는 선두 차단(Head-of-Line, HOL) 블로킹으로 알려져 있습니다.

위는 다음의 상충 관계가 발생했습니다:

   - **높은 처리량**(큰 배치)을 얻으려면 더 많은 메모리가 필요하지만, HOL 블로킹으로 인해 **높은 지연 시간**과 **낮은 활용률**이 나타납니다.
   - **낮은 지연 시간**(작은 배치 또는 순차 처리)을 얻으려면 **처리량**과 GPU **활용률**이 매우 낮아집니다.
   - **높은 활용률**을 얻으려면 GPU를 작업으로 가득 채워야 하지만, 이는 다시 메모리 및 지연 시간 문제로 이어집니다.

현대 LLM 서빙의 핵심 과제는 이 삼중고를 해결하기 위해 PagedAttention, 동적 배치, 반복 수준 스케줄링 등의 기술을 시도하고 있습니다. 이 기술들은 메모리를 더 효율적으로 관리하고 작업을 더 세밀하게 스케줄링함으로써 지연 시간을 희생하지 않으면서 높은 활용률과 처리량을 달성하는 것을 목표로 합니다.

> <font color="#245bdb"><b>NOTE: PagedAttention</b></font>
> 
> PagedAttention은 KV 캐시를 고정된 크기의 "페이지" 또는 "블록"으로 분할합니다. 이 페이지들은 물리적 GPU 메모리에 비연속적으로 저장될 수 있습니다. "블록 테이블"은 토큰의 논리적 시퀀스를 이러한 비연속적인 물리적 블록에 매핑하는 역할을 합니다.
> 
> 이 방식은 메모리가 <u>작은 블록 단위로 필요에 따라 할당</u>되므로 내부 단편화를 제거합니다. 이를 통해 훨씬 더 큰 배치 크기를 사용할 수 있게 되어 처리량을 향상시킵니다. 또한 복잡한 샘플링 전략을 위한 효율적인 메모리 공유(쓰기 시 복사, copy-on-write)를 가능하게 합니다.

> <font color="#245bdb"><b>NOTE: 동적 배치</b></font>
> 
> 동적 배치는 서버 측에서 짧은 시간 동안 도착하는 개별 추론 요청들을 수집하여 하나의 더 큰 배치로 묶은 다음 GPU로 보내는 기술입니다.
> 
> GPU는 병렬 처리에 매우 효율적이므로, 더 큰 데이터 배치에서 더 효율적으로 작동합니다. 이 기법은 많은 모델에서 처리량을 3배에서 10배까지 향상시킬 수 있습니다.

> <font color="#245bdb"><b>NOTE: 반복 수준 스케줄링</b></font>
> 
> 스케줄러는 전체 요청을 스케줄링하는 대신, _매 단일 토큰 생성 단계마다_ 결정을 내립니다. 실행 중인 배치에 <u>새로운 요청을 추가하거나 완료된 요청을 제거</u>할 수 있습니다. 
> 
> 이 방식은 패딩의 필요성을 제거하고 GPU 유휴 시간을 최소화하여 처리량과 활용률을 크게 향상시킵니다. 이는 모든 현대 서빙 시스템의 기초적인 최적화 기술입니다.

#### 지연 시간 대 처리량

대표적인 상충 관계 중 하나는 <u>개별 요청의 지연 시간을 최소화하는 것과 시스템 전체의 처리량을 최대화하는 것</u>입니다.

<u>낮은 지연 시간</u>(한 사용자에 대한 빠른 응답)을 위해 최적화하는 것은 종종 요청을 개별적으로 처리하는 것을 포함하며, 이는 <u>전체 처리량을 제한</u>할 수 있습니다. 반면 <u>높은 처리량</u>(초당 많은 사용자)을 위해 최적화하는 것은 종종 요청을 일괄 처리하는 것을 포함하며, 이는 각 <u>개별 요청에 대한 지연 시간을 증가</u>시킵니다.

예를 들어, **배치(Batching)** 기술은 여러 요청을 하나로 묶어 GPU에서 한 번에 처리함으로써 GPU의 활용률을 높여 전체 처리량을 향상시킵니다. 하지만 이 방식은 배치가 채워질 때까지 기다려야 하므로, 배치에 포함된 각 개별 요청의 지연 시간은 증가하게 됩니다. 반대로, 모든 요청을 도착하는 즉시 개별적으로 처리하면 지연 시간은 최소화되지만, GPU가 충분히 활용되지 않아 전체 처리량은 낮아질 수 있습니다. 

이처럼 지연 시간과 처리량은 서로 반비례 관계에 있는 경우가 많습니다. 서비스의 요구사항에 따라 이 둘 사이의 적절한 균형점을 찾는 것이 시스템 아키텍처 설계의 핵심 과제입니다.

> <font color="#245bdb"><b>NOTE: 실시간 서빙</b></font>
> 
> 사용자와 시스템이 즉각적인 응답을 기다리는 동기식, 저지연 예측을 위해 설계된 아키텍처입니다. 일반적으로 REST API 엔드포인트나 gRPC 서비스 형태로 구현되어, 요청이 들어오면 실시간으로 추론을 수행하고 결과를 반환합니다.
> 
> <u>높은 처리량보다는 낮은 지연 시간을 최우선으로 고려</u>합니다. 따라서 고가용성의 반응성이 뛰어난 인프라가 필수적입니다.

> <font color="#245bdb"><b>NOTE: 배치 서빙</b></font>
> 
> 대량의 데이터를 비동기적으로 처리하는 아키텍처입니다. 모델은 정해진 스케줄(예: 매일 밤)에 따라 대규모 추론 작업을 수행하고, 그 결과를 데이터베이스나 데이터 웨어하우스에 저장하여 필요할 때 애플리케이션에서 가져다 사용합니다.
> 
> 지연 시간이 중요하지 않은 대신, <u>높은 처리량과 비용 효율성을 우선시</u>합니다. 컴퓨팅 자원을 필요할 때만 집중적으로 사용하므로 비용을 최적화할 수 있습니다.

#### 비용 대 성능

더 강력한 하드웨어(예: GPU 대 CPU)는 더 나은 성능을 제공하지만 더 높은 비용이 필요합니다. 적절한 균형점은 <u>모델의 특정 요구 사항과 속도의 비즈니스 가치</u>에 따라 다릅니다.

#### 예측 성능 대 속도

더 <u>복잡한 모델이 더 정확할 수</u> 있지만, <u>실행 속도가 느리고 서빙 비용이 더 비싼 경우</u>가 많습니다. "실용적 정확성(practical accuracy)"의 원칙은 순위표에서 가장 높은 점수를 받은 모델이 아니라, <u>비즈니스 문제에 "충분히 좋은" 모델을 선택할 것</u>을 권장합니다.

#### 전략적 의사결정 프레임워크: 파레토 최적 전선

이러한 복잡한 상충 관계 속에서 '최고의' 단일 솔루션을 찾는 것은 거의 불가능합니다. 대신, '파레토 최적(Pareto Optimal)'이라는 개념을 활용하여 합리적인 의사결정 프레임워크를 구축할 수 있습니다.

> <font color="#245bdb"><b>NOTE: 파레토 최적</b></font>
> 
> <u>다른 목표를 악화시키지 않고서는 하나의 목표를 더 이상 개선할 수 없는 상태</u>를 의미합니다. 예를 들어, 현재 모델보다 정확도를 높이려면 반드시 비용이나 지연 시간이 증가해야만 하는 경우, 현재 모델은 파레토 최적 상태에 있다고 할 수 있습니다.
> 
> 다양한 모델과 그 구성(예: 양자화 적용 여부, 하드웨어 종류)을 2차원 또는 3차원 그래프(예: X축-비용, Y축-지연 시간, 색상-정확도)에 표시하면, '파레토 최적 전선(Pareto Frontier)'을 시각적으로 확인할 수 있습니다. 이 전선 위에 있는 모든 점들은 기술적으로 '효율적인' 선택지들입니다. 전선 안쪽에 있는 점들은 비효율적인데, 왜냐하면 동일하거나 적은 비용 및 지연 시간으로 더 높은 정확도를 달성하는 다른 점이 전선 위에 존재하기 때문입니다.


어떤 파레토 최적점을 선택할지는 비즈니스와 제품 요구사항에 달려 있습니다. 예를 들어, 생명이 달린 의료 영상 진단 모델은 비용이 아무리 많이 들더라도 정확도가 가장 높은 점을 선택해야 합니다. 반면, 무료 사용자에게 제공되는 비핵심적인 추천 기능은 정확도를 다소 희생하더라도 비용이 가장 저렴한 점을 선택하는 것이 합리적입니다.

이 프레임워크는 "가장 정확한 모델이 무엇인가?"라는 질문을 "우리의 비즈니스 제약 조건 하에서 가장 효율적인 모델은 무엇인가?"라는 더 전략적인 질문으로 전환시킵니다. 

종종 최고의 정확도 점수를 내는 모델을 '최고'라고 여기는 경향이 있지만, 프로덕션 환경은 <u>비용과 성능이라는 두 가지 치명적인 제약 조건</u>을 추가합니다.

99%의 정확도를 가졌지만 응답에 10초가 걸리고 시간당 10달러의 비용이 드는 모델은, 100ms의 지연 시간과 엄격한 예산이 요구되는 실시간 애플리케이션에서는 사실상 쓸모가 없습니다. 이 경우, 97%의 정확도를 가졌지만 50ms 내에 응답하고 시간당 1달러의 비용이 드는 모델이 훨씬 더 가치 있습니다. 2%의 정확도 하락은 200배의 속도 향상과 10배의 비용 절감을 위한 합리적인 트레이드오프입니다. 

프로덕션에서 '최고의' 모델은 학술적인 정확도 리더보드의 최상단에 있는 모델이 아니라, 비용-성능-정확도라는 파레토 최적 전선 위에서 비즈니스 목표와 가장 잘 부합하는 지점에 위치한 모델입니다.

- **비즈니스 목표에서 시작:** 개발을 시작하기 전에 <u>허용 가능한 지연 시간, 최소 정확도, 그리고 예산 한도를 명확히 정의</u>해야 합니다.
- **반복적인 최적화:** MLOps 원칙에 따라 다양한 모델, 하드웨어(CPU vs. 다양한 GPU), 최적화 기법을 체계적으로 실험하고 그 결과를 파레토 전선에 플로팅하여 최적의 조합을 찾아야 합니다.
- **자원의 적정 규모화 (Right-Sizing):** 오토스케일링과 MIG 같은 하드웨어 관리 기법을 적극 활용하여, 실제로 <u>필요한 만큼의 리소스에 대해서만 비용을 지불하도록 시스템을 구성</u>해야 합니다.
- **모델 캐스케이딩 (Model Cascading):** 간단하고 저렴한 모델로 대부분의 쉬운 요청을 처리하고, <u>어려운 요청만 복잡하고 비싼 모델로 전달되도록 라우팅</u>하는 고급 전략입니다. 이는 시스템 전체의 비용-성능 곡선을 최적화하는 데 매우 효과적일 수 있습니다

### SRE 원칙 적용

<u>비즈니스 요구사항을 측정 가능하고 실행 가능한 기술적 목표</u>로 전환하는 과정은 **서비스 수준 목표(Service Level Objectives, SLOs)** 를 설정하는 것입니다. SLO는 시스템이 달성해야 할 구체적인 성능 목표를 정의하며, 서빙 아키텍처 설계의 기반이 됩니다. 

예를 들어, 실시간 상호작용이 중요한 챗봇 애플리케이션은 100ms 미만의 매우 낮은 지연 시간을 SLO로 설정해야 하는 반면, 대규모 문서 요약을 처리하는 배치 시스템은 높은 처리량을 SLO로 설정할 수 있습니다.

SRE는 IT 운영을 자동화하고 높은 신뢰성을 달성하기 위해 소프트웨어 엔지니어링 관행을 사용하는 것에 관한 것입니다. ML의 경우 이는 다음을 의미합니다.

- **서비스 수준 목표(SLO) 정의:** 표준 지연 시간 및 가용성 SLO 뿐만 아니라, **데이터 신선도**(모델이 학습하는 데이터가 얼마나 오래되었는가?), **예측 품질**(예: 28일 동안 정확도가 95% 이상이어야 함), **학습 파이프라인 완료율**과 같은 ML 관련 문제에 대한 SLO를 정의합니다.
- **오류 예산(Error Budgets):** 오류 예산은 허용 가능한 실패 수준입니다. 이 예산은 팀이 전체 오류 예산을 "소비"하지 않는 한 혁신하고 위험을 감수할 수 있도록 권한을 부여합니다.

성숙한 MLOps는 성숙한 SRE와 구별할 수 없습니다. 초기 단계의 MLOps는 모델을 프로덕션 환경에 배포하는 데 중점을 둡니다(CI/CD, 배포). 시스템이 성숙해짐에 따라 초점은 <u>배포에서 신뢰성과 유지보수로 이동</u>하며, 이는 SRE의 핵심 영역입니다. 

SRE가 소프트웨어에 사용하는 원칙들(SLO, 오류 예산, 모니터링, 자동화된 사고 대응, 비난 없는 사후 검토)은 ML 시스템에 직접 적용될 수 있습니다. 유일한 차이점은 모니터링 및 관리 대상의 *범위*입니다. 

ML을 위한 SRE는 이러한 원칙을 <u>애플리케이션 코드뿐만 아니라 데이터 파이프라인과 모델의 통계적 행동까지 포괄하도록 확장</u>합니다. 결론적으로, MLOps의 최종 목표는 별개의 학문 분야가 되는 것이 아니라, SRE의 전문화된 한 분야가 되는 것입니다. 목표는 모델, 데이터, 코드를 단일의 신뢰할 수 있고 자동화된 프로덕션 시스템의 구성 요소로 취급하고, SRE가 전통적인 소프트웨어에 적용하는 것과 동일한 엔지니어링 엄격함으로 관리하는 것입니다.

#### 문제 진단을 위한 구조화된 플레이북

모델 성능 경고가 발생했을 때, 엔지니어는 임시방편적인 디버깅이 아닌 구조화된 계획이 필요합니다.

**1단계: 분류 (실제 상황인가?):** 

경고가 오탐이 아닌지 확인합니다. 모니터링 대시보드(Grafana)를 확인하여 문제의 범위와 기간을 파악합니다.

**2단계: 도메인 격리 (시스템 대 데이터 대 모델):**
- **시스템 문제 확인**: 지연 시간이 높은지, 서버 충돌이 발생했는지 운영 지표를 확인합니다. 이는 기본적인 SRE 사고입니다.
- **데이터 문제 확인**: null 값이 급증했는지, 입력 분포가 급격히 변했는지 데이터 드리프트 및 품질 대시보드를 확인합니다. 이는 상위 데이터 파이프라인 문제를 가리킵니다.
- **모델 문제 확인**: 시스템 및 데이터 지표는 정상이지만 예측 품질(정확도 등)이 떨어지는 경우, 이는 개념 드리프트 또는 모델 코드 자체의 버그를 가리킵니다.

**3단계: 즉각적인 완화 (피해 확산 방지):**
- 잘못된 배포인 경우, 이전 버전으로의 자동 **롤백**을 트리거합니다.
- 특정 소스의 데이터 품질 문제인 경우, 가능하다면 해당 소스를 일시적으로 차단하는 것을 고려합니다.

**4단계: 근본 원인 분석 (사후 검토):** 

완화 조치 후, 근본 원인을 이해하기 위해 비난 없는 사후 검토를 수행합니다. 상위에서 데이터 스키마가 변경되었는지, 새로운 사용자 행동이 나타났는지 확인합니다.

**5단계: 수정 및 자동화:** 

근본 원인을 수정합니다. 그리고 같은 실패가 다시 발생하지 않도록 새로운 모니터링 검사나 자동화된 테스트를 추가합니다.


## 마치며

이번 포스트에서는 모델 서빙의 목표를 나타내는 기술 지표들을 알아보고, 비즈니스 환경에서 평가를 위해 지표를 어떻게 정해야 하는지 알아보았습니다.

기본적인 지표 위주로 알아보았기에, 실제 환경에서는 비즈니스 목표에 따라 위에서 언급하지 않은 지표도 고려해야 할 것입니다. 그러한 경우에도 지표를 정하는 이유와 최종 목적은 같을 것이라 생각합니다.

다음 포스트에서는 모델 서빙의 구성 요소와 서빙 형태를 살펴보겠습니다.

> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.