---
title: 모델 서빙
description:
date: 2025-09-22T19:03:00
lastmod: 2025-09-22
slug: optimize
comments: true
math: false
categories:
  - Systems
tags:
  - Model-Serving
keywords:
  - Model-Serving
  - MLOps
---
## 개요


## 섹션 2: 배포의 청사진: 서빙 아키텍처 비교 분석

AI 모델을 성공적으로 배포하기 위해서는 비즈니스 요구사항과 기술적 제약 조건을 모두 만족시키는 적절한 아키텍처를 선택해야 합니다. 모델 서빙 아키텍처는 크게 온라인(실시간), 배치(오프라인), 스트리밍, 그리고 임베디드/엣지 네 가지 패턴으로 분류할 수 있습니다. 각 패턴은 고유한 특징과 장단점을 가지며, 특정 사용 사례에 최적화되어 있습니다.

### 2.1. 온라인 (실시간) 서빙

- **설명:** 사용자와 시스템이 즉각적인 응답을 기다리는 동기식, 저지연 예측을 위해 설계된 아키텍처입니다. 일반적으로 REST API 엔드포인트나 gRPC 서비스 형태로 구현되어, 요청이 들어오면 실시간으로 추론을 수행하고 결과를 반환합니다.
- **특징:** <u>높은 처리량보다는 낮은 지연 시간을 최우선으로 고려</u>합니다. 따라서 고가용성의 반응성이 뛰어난 인프라가 필수적입니다.
- **사용 사례:** 거래가 완료되기 전에 사기 여부를 판별하는 실시간 사기 탐지, 사용자와의 대화를 지연 없이 처리해야 하는 인터랙티브 챗봇, 실시간 광고 입찰 시스템 등이 대표적입니다.
- **아키텍처:** 모델을 독립적인 마이크로서비스로 래핑하는 방식이 널리 사용됩니다. 이를 통해 모델 서비스만 독립적으로 확장하고 관리할 수 있어 유연성과 안정성을 높일 수 있습니다.

### 2.2. 배치 (오프라인) 서빙

- **설명:** 대량의 데이터를 비동기적으로 처리하는 아키텍처입니다. 모델은 정해진 스케줄(예: 매일 밤)에 따라 대규모 추론 작업을 수행하고, 그 결과를 데이터베이스나 데이터 웨어하우스에 저장하여 필요할 때 애플리케이션에서 가져다 사용합니다.
- **특징:** 지연 시간이 중요하지 않은 대신, <u>높은 처리량과 비용 효율성을 우선시</u>합니다. 컴퓨팅 자원을 필요할 때만 집중적으로 사용하므로 비용을 최적화할 수 있습니다.
- **사용 사례:** 모든 사용자를 위한 일일 제품 추천 목록 생성, 대규모 고객 데이터에 대한 신용 등급 평가, 분석을 위한 대용량 데이터셋의 일괄 분류 작업 등이 있습니다.
- **아키텍처:** 데이터 파이프라인이 정해진 시간에 배치 추론 작업을 트리거하고, 결과는 애플리케이션에서 빠르게 조회할 수 있도록 키-값 저장소와 같은 서빙 레이어에 저장하는 구조를 가집니다.

### 2.3. 스트리밍 추론

- **설명:** 온라인과 배치의 중간적 성격을 가진 하이브리드 접근 방식으로, 지속적으로 유입되는 데이터 스트림을 거의 실시간으로 처리합니다. 이는 <span style="background:#fff88f">'항상 켜져 있는' 애플리케이션이 새로운 데이터 이벤트가 발생하는 즉시 반응</span>해야 할 때 사용됩니다.
- **핵심 기술:**
  - **Apache Kafka:** 사용자 클릭, IoT 센서 데이터, 금융 거래와 같은 실시간 데이터 스트림을 안정적으로 수집하고 전달하는 고처리량, 내결함성 메시지 버스 역할을 합니다.
  - **Apache Flink / Spark Streaming:** Kafka로부터 데이터를 소비하여 실시간으로 변환, 집계하고 즉석에서 모델 추론을 수행하는 스트림 처리 엔진입니다.
- **사용 사례:** 금융 서비스에서의 실시간 사기 탐지, 전자상거래에서의 동적 가격 책정 및 실시간 개인화 추천, 스마트 팩토리나 스마트 시티에서의 IoT 데이터 기반 이상 징후 탐지 등이 있습니다.

### 2.4. 임베디드 / 엣지 서빙

- **설명:** 모델을 클라우드 서버가 아닌 사용자 기기(예: 스마트폰, IoT 장치)나 엣지 서버에 직접 배포하는 방식입니다.
- **특징:** 네트워크 지연이 전혀 없어 가장 낮은 지연 시간을 제공하며, 인터넷 연결 없이도 오프라인으로 동작할 수 있습니다. 하지만 기기의 제한된 컴퓨팅 자원(메모리, CPU/GPU 성능)으로 인해 모델의 크기가 매우 작고 가벼워야 합니다.13
- **사용 사례:** 스마트폰 카메라의 실시간 객체 인식, 음성 비서의 로컬 명령어 처리, 산업용 IoT 센서의 엣지 분석 등이 있습니다.
- **아키텍처:** TensorFlow Lite, PyTorch Mobile과 같은 특화된 모바일/엣지 런타임과 양자화, 프루닝 등 강력한 모델 최적화 기법에 크게 의존합니다.20

각 아키텍처 패턴의 특징을 명확히 이해하고 비즈니스 요구사항에 가장 적합한 패턴을 선택하는 것은 성공적인 AI 서비스 구축의 첫걸음입니다. 아래 표는 각 아키텍처의 핵심적인 특성을 비교하여 의사결정을 돕습니다.

**표 1: 모델 서빙 아키텍처 패턴 비교**

| 아키텍처            | 일반적인 지연 시간  | 처리량 프로필 | 비용 프로필                                     | 데이터 최신성     | 주요 사용 사례                                         |
| ------------------- | ------------------- | ------------- | ----------------------------------------------- | ----------------- | ------------------------------------------------------ |
| **온라인 (실시간)** | 수 밀리초 ~ 수 초   | 낮음 ~ 중간   | 항상 켜져 있어야 하므로 유휴 비용 발생 가능     | 실시간            | 사기 탐지, 인터랙티브 챗봇, 실시간 입찰                |
| **배치 (오프라인)** | 수 분 ~ 수 시간     | 매우 높음     | 작업 실행 시에만 비용 발생, 비용 효율적         | 낮음 (일/주 단위) | 일일 추천 생성, 대규모 데이터 분류, 신용 평가          |
| **스트리밍**        | 수백 밀리초 ~ 수 초 | 높음          | 지속적인 데이터 처리를 위해 항상 켜져 있음      | 거의 실시간       | 실시간 이상 징후 탐지, 동적 가격 책정, IoT 데이터 분석 |
| **임베디드/엣지**   | 수 밀리초 이하      | 기기당 낮음   | 클라우드 비용 없음, 기기 비용 및 전력 소모 고려 | 실시간 (기기 내)  | 온디바이스 AI, 스마트 어시스턴트, 자율주행 보조        |


# 프로덕션 등급 AI: 고급 모델 서빙 아키텍처 가이드

## 섹션 1: 모델 서빙 패러다임의 분류

인공지능(AI) 모델을 실제 프로덕션 환경에 배포하는 모델 서빙은 단순한 <u>예측 API 구축을 넘어, 비즈니스 요구사항과 기술적 제약 사이의 균형</u>을 맞추는 복잡한 아키텍처 설계 과정입니다. 모델의 추론(inference)이 언제, 어디서, 어떻게 생성되어야 하는지에 따라 다양한 서빙 패러다임이 존재하며, 각 패러다임은 지연 시간(latency), 처리량(throughput), 비용, 운영 복잡성 측면에서 뚜렷한 장단점을 가집니다. 따라서 <u>특정 사용 사례에 가장 적합한 아키텍처를 선택</u>하는 것은 성공적인 AI 서비스의 핵심 전제 조건이 됩니다. 본 섹션에서는 모델 서빙의 근간을 이루는 핵심 패러다임들을 체계적으로 분류하고, 각 패러다임의 기술적 특성과 전략적 함의를 심도 있게 분석합니다.

### 1.1. 핵심 이분법: 온라인(실시간) 추론 대 배치(오프라인) 추론

모델 서빙 아키텍처를 결정하는 가장 근본적인 분기점은 예측 결과를 즉시 필요로 하는지, 아니면 일정 시간 이후에 일괄적으로 처리해도 되는지에 따라 온라인 서빙과 배치 서빙으로 나뉩니다. 이 두 패러다임은 <u>기술적 요구사항, 인프라 구성, 비용 모델이 근본적으로 다르기 때문</u>에, 애플리케이션의 핵심 요구사항에 따라 신중하게 선택해야 합니다.

#### 온라인(실시간) 서빙

온라인 서빙은 사용자의 요청에 대해 실시간으로 예측 결과를 반환하는 동기식(synchronous) 처리 방식입니다.1 일반적으로 REST(Representational State Transfer) 또는 gRPC(gRPC Remote Procedure Call) API 엔드포인트를 통해 구현되며, <u>모델 서버는 항상 실행 상태를 유지하면서 개별 데이터 또는 소규모 데이터 묶음이 도착하는 즉시 처리하여 즉각적인 응답을 제공</u>합니다. 이러한 특성 때문에 사용자와의 상호작용이 필수적인 애플리케이션에 절대적으로 필요합니다.

온라인 서빙 아키텍처의 <u>핵심 요구사항은 높은 가용성(high availability), 낮은 지연 시간, 그리고 변동하는 요청량을 처리하기 위한 동적 확장성(dynamic scalability)</u>입니다. 지연 시간은 종종 수십 밀리초(ms) 이내로 유지되어야 하며, 이를 위해 강력한 인프라가 필수적입니다. Kubernetes와 같은 컨테이너 오케스트레이션 플랫폼이나 서버리스 함수(serverless functions)는 이러한 요구사항을 충족시키기 위해 널리 사용되는 기술입니다.

이 패러다임은 즉각적인 피드백이 비즈니스 가치를 창출하는 분야에 이상적입니다. 예를 들어, 금융 거래에서의 실시간 사기 탐지, 전자상거래 웹사이트에서의 개인화된 상품 추천, 의료 영상 분석을 통한 즉각적인 진단 지원 등이 대표적인 적용 사례입니다.

#### 배치(오프라인) 서빙

배치 서빙은 대량의 데이터를 한 번에 모아 비동기식(asynchronous)으로 처리하는 방식입니다. 이 과정은 일반적으로 사전에 정의된 일정(예: 매일 자정, 매시간)에 따라 실행되는 작업(job) 형태로 이루어집니다.7 배치 작업은 <u>대규모 데이터셋을 읽어 각 레코드에 대한 예측을 생성한 후, 그 결과를 데이터베이스나 파일 저장소에 저장하여 나중에 다른 시스템에서 활용할 수 있도록</u> 합니다. 이 방식에서는 모델이 실시간 요청을 처리하기 위해 항상 활성화된 서비스 형태로 존재하지 않습니다.

배치 서빙의 설계 목표는 낮은 지연 시간보다는 <u>높은 처리량과 비용 효율성</u>에 맞춰져 있습니다. 인프라는 작업이 실행되는 동안에만 프로비저닝되고 작업이 끝나면 회수될 수 있어, 유휴 자원에 대한 비용을 최적화할 수 있다는 큰 장점이 있습니다.

이 패러다임은 예측 결과가 실시간으로 필요하지 않은 시나리오에 적합합니다. 예를 들어, 전체 고객을 대상으로 일일 이탈 점수(churn score)를 계산하거나, 주간 판매 데이터를 기반으로 물류 재고를 최적화하거나, 모든 사용자를 위한 개인화된 콘텐츠 추천 목록을 미리 생성하는 등의 작업에 활용됩니다.

#### 비교 분석

온라인 서빙과 배치 서빙은 추론 아키텍처 설계의 양 극단에 위치합니다. 온라인 서빙은 지연 시간을 최소화하기 위해 상시 가동되는 고가용성 인프라를 요구하며, 요청당 비용이 발생하는 반면, 배치 서빙은 처리량을 극대화하고 유휴 시간을 제거하여 전체 작업 비용을 절감하는 데 중점을 둡니다. 따라서 어떤 패러다임을 선택할지는 단순히 기술적 선호의 문제가 아니라, 애플리케이션이 <u>제공해야 할 서비스 수준 협약(SLA)과 비즈니스 모델에 의해 결정</u>되는 전략적 선택입니다.

### 1.2. 엣지 서빙: 지능을 주변부로 확장

엣지 서빙은 중앙 집중식 클라우드 서버가 아닌, 사물 인터넷(IoT) 센서, 스마트폰, 임베디드 시스템과 같은 로컬 엣지 디바이스에서 직접 머신러닝 모델을 배포하고 실행하는 패러다임을 의미합니다. 이는 극도로 낮은 지연 시간, 오프라인 환경에서의 동작, 강화된 데이터 프라이버시에 대한 요구가 증가하면서 부상한 근본적인 아키텍처의 전환입니다.

이 패러다임은 독특한 기술적 과제를 동반합니다. 엣지 디바이스는 일반적으로 컴퓨팅 자원이 제한적이므로, 모델은 <span style="background:#fff88f">경량화(quantization), 가지치기(pruning) 등의 최적화 기법</span>을 통해 크기를 대폭 줄여야 합니다. 모델 배포는 <u>최적화된 모델을 컨테이너나 네이티브 애플리케이션 형태로 패키징하여 대상 디바이스로 전송하는 과정을 포함</u>합니다. MLOps 수명주기 또한 복잡해집니다. 수많은 분산된 디바이스에 배포된 모델을 <u>무선 업데이트(Over-the-Air, OTA)하는 강력한 메커니즘</u>이 필요하며, 모델 재학습을 위해 엣지에서 수집된 데이터를 클라우드로 전송하는 하이브리드 접근 방식이 요구됩니다.

엣지 서빙의 가장 큰 장점은 <u>네트워크 지연 시간을 제거하여 수 밀리초 수준의 응답 시간을 달성</u>할 수 있다는 점입니다. 또한, 클라우드로 전송되는 데이터 양을 최소화하여 네트워크 대역폭을 절약하고, 인터넷 연결이 불안정하거나 끊어진 상황에서도 서비스 연속성을 보장하며, 민감한 데이터를 디바이스 내에서 처리함으로써 데이터 프라이버시와 주권을 강화할 수 있습니다. 반면, 디바이스 자체의 <u>제한된 컴퓨팅 성능, 분산된 모델들을 관리하고 업데이트하는 복잡성, 그리고 물리적 디바이스가 직면할 수 있는 보안 위협</u> 등은 해결해야 할 과제입니다.

### 1.3. 서버리스 서빙: 사용량 기반의 패러다임

서버리스 컴퓨팅은 개발자가 기본 인프라(서버, 운영체제 등)를 직접 관리할 필요 없이, 모델을 함수(function) 형태로 배포하고 요청이 있을 때만 실행되도록 하는 패러다임입니다. 클라우드 제공업체가 인프라 프로비저닝, 확장(요청이 없을 경우 0으로 축소 포함), 유지보수를 모두 담당하므로, 트래픽이 간헐적이거나 예측 불가능한 워크로드에 이상적입니다.

그러나 서버리스 패러다임에는 '콜드 스타트(cold start)'라는 중요한 단점이 존재합니다. 함수가 한동안 호출되지 않아 유휴 상태에 있다가 첫 요청을 받으면, 클라우드 제공업체는 새로운 컨테이너를 프로비저닝하고, 런타임을 초기화하며, 모델 코드를 로드해야 합니다. <u>이 과정은 첫 번째 요청의 응답 시간에 수백 밀리초에서 수 초에 이르는 상당한 지연을 추가</u>할 수 있습니다.

이러한 콜드 스타트 문제를 완화하기 위한 몇 가지 전략이 존재합니다.

- **프로비저닝된 동시성(Provisioned Concurrency):** 일정 수의 함수 인스턴스를 항상 '웜(warm)' 상태로 유지하여 즉시 요청을 처리할 수 있도록 준비시키는 방식입니다. 이는 지연 시간을 줄이는 대신 <u>유휴 상태에서도 비용이 발생</u>하는 트레이드오프를 가집니다.
- **런타임 및 패키지 최적화:** <u>Java나 C#과 같은 컴파일 언어보다 초기화 시간이 빠른 Python, Node.js와 같은 스크립팅 언어를 런타임으로 선택</u>하고, 배포 패키지의 크기를 최소화하여 로딩 시간을 단축하는 방법입니다.
- **함수 워밍(Function Warming):** 스케줄러를 사용하여 주기적으로 함수를 호출('ping')함으로써 <u>인스턴스가 유휴 상태로 전환되는 것을 방지</u>합니다.
- **함수 융합(Function Fusion):** 여러 단계로 구성된 워크플로우에서 <u>연속적인 함수들을 하나로 통합</u>하여 잠재적인 콜드 스타트 발생 횟수 자체를 줄이는 기법입니다.

이처럼 서빙 패러다임의 선택은 단순히 기술적 선호도를 넘어, <span style="background:#fff88f">비즈니스의 근본적인 요구사항에 의해 결정</span>됩니다. <u>실시간 상호작용의 필요성은 온라인 아키텍처를 강제하고, 지연 시간 허용과 대규모 데이터 처리는 배치 아키텍처를 가능</u>하게 합니다. <u>오프라인 기능이나 데이터 프라이버시 요구는 엣지 아키텍처를 필수적으로 만들며, 불규칙한 트래픽과 유휴 비용 최소화에 대한 요구는 서버리스 접근 방식의 채택을 유도</u>합니다.

전통적으로 온라인과 배치를 <u>이분법적으로 바라보는 시각에서 벗어나, 이들을 하나의 스펙트럼으로 이해</u>하는 것이 중요합니다. 엣지 서빙은 네트워크 지연을 완전히 제거함으로써 온라인 추론의 지연 시간 최소화 목표를 극단으로 추구하는 형태이며, 서버리스는 인프라 관리 방식을 추상화하여 온라인(예: 실시간 API를 위한 Azure Functions)과 배치(예: 스케줄링된 Databricks 작업) 양쪽에 모두 적용될 수 있는 직교적 개념입니다. 따라서 아키텍트가 내려야 할 핵심 결정은 "온라인인가, 배치인가?"를 넘어 <span style="background:#fff88f">"애플리케이션의 추론이 지연 시간-처리량-비용 스펙트럼의 어느 지점에 위치해야 하는가?</span>"라는 더 근본적인 질문에 답하는 것입니다.


## 제3부: 철학의 아키텍처적 구현

### 섹션 5. 의도와 아키텍처의 조화: 배치, 스트리밍, 실시간 추론

#### 5.1 배치 추론: 효율성과 성찰의 철학

- **철학:** <u>즉시성보다 처리량과 비용 효율성을 우선시</u>한다. 통찰력은 가치가 있지만 <u>시간에 민감하지 않은 주기적이고 대규모 분석에 대한 비즈니스 요구를 반영</u>한다. 이는 "성찰"의 아키텍처다.
- **사용 사례:** 일일 비즈니스 보고서 생성, 대규모 문서 컬렉션 분류, 추천 시스템을 위한 임베딩 사전 계산.
- **아키텍처:** 데이터는 일정 기간 동안 수집되어 대규모 배치로 처리되고, <u>결과는 나중에 사용하기 위해 저장</u>된다. 비용 효율적인 컴퓨팅 옵션을 활용하며, <u>비수요 시간에 예약 실행</u>될 수 있다.

#### 5.2 실시간(온라인) 추론: 즉시성과 상호작용의 철학

- **철학:** 즉각적이고 상호작용적인 사용자 경험을 가능하게 하기 위해 <u>낮은 지연 시간을 우선시</u>한다. 예측이 사용자 또는 시스템과의 직접적이고 동기적인 상호작용의 일부인 비즈니스 요구를 반영한다. 이는 "반응"의 아키텍처다.
- **사용 사례:** 금융 사기 탐지(거래가 완료되기 _전에_ 차단), 실시간 상품 추천, 채팅 앱의 언어 번역.
- **아키텍처:** 모델은 상시 가동되는 <u>엔드포인트(예: REST API)에 배포</u>되며, 개별 요청을 최소한의 지연으로 처리하도록 설계된다. <u>고가용성과 낮은 지연 시간을 보장하기 위해</u> 신중한 자원 관리가 필요하다.

#### 5.3 스트리밍 추론: 지속적 인식의 철학

- **철학:** 연속적이고 무한한 이벤트 스트림을 거의 실시간으로 처리하는 하이브리드 방식이다. 실시간 추론과 같은 요청-응답 패턴이 아니라, 데이터가 흐름에 따라 작동하는 이벤트 기반 프로세스다. 이는 "지속적 인식"의 아키텍처다.
- **사용 사례:** 예측 유지보수를 위한 IoT 센서 데이터 모니터링, 감성 동향 분석을 위한 소셜 미디어 피드 분석, 사기 탐지 모델의 피처 실시간 업데이트.
- **차이점:** 실시간 추론과의 핵심적인 차이는 트리거에 있다. 실시간 추론은 일반적으로 사용자 요청(`GET /predict`)에 의해 트리거된다. 스트리밍 추론은 <u>데이터 스트림에 새로운 이벤트가 도착하는 것(예: Kafka 토픽의 새 메시지)에 의해 트리거</u>된다. 둘 다 낮은 지연 시간을 목표로 하지만, 아키텍처 패턴(요청/응답 대 발행/구독)이 다르다.

#### 표 2: 추론 전략 비교 분석

"실시간"과 "스트리밍"이라는 용어는 종종 혼용되거나 부정확하게 사용된다. 다음 표는 기술적 특성(지연 시간, 아키텍처)을 _철학적 의도_(효율성, 즉시성, 인식)와 명시적으로 연결하여 명확성을 제공하고 강력한 의사결정 프레임워크를 제시한다.

| 패러다임          | 지도 철학         | 주요 목표                | 지연 시간              | 처리량      | 비용 모델                 | 대표 아키텍처                  | 사용 사례 예시                     |
| ----------------- | ----------------- | ------------------------ | ---------------------- | ----------- | ------------------------- | ------------------------------ | ---------------------------------- |
| **배치 추론**     | 효율성과 성찰     | 비용 효율성, 대규모 처리 | 높음 (수 분 ~ 수 시간) | 매우 높음   | 작업당/리소스 시간당      | 예약된 작업, 데이터 파이프라인 | 일일 보고서, 데이터 레이블링       |
| **실시간 추론**   | 즉시성과 상호작용 | 낮은 응답 시간           | 매우 낮음 (밀리초)     | 낮음 ~ 중간 | 상시 가동 인스턴스 비용   | REST API, gRPC 엔드포인트      | 사기 탐지, 실시간 추천             |
| **스트리밍 추론** | 지속적 인식       | 이벤트 기반 즉각 처리    | 낮음 (밀리초 ~ 초)     | 높음        | 상시 가동 스트림 프로세서 | Kafka/Flink, 이벤트 버스       | IoT 모니터링, 실시간 피처 업데이트 |

### 섹션 6. 다음 개척지: 분산화, 추상화, 그리고 조합

#### 6.1 서버리스 추론: 궁극적 추상화의 철학

- **철학:** 기본 인프라를 완전히 <u>추상화하여 개발자가 모델의 기능에만 집중할 수 있도록</u> 하는 것이다. 이는 "사용한 만큼만 지불"하는 정신을 구현하며, 0에서 대규모로, 그리고 다시 0으로 확장되어, 산발적이거나 예측 불가능한 워크로드에 대해 궁극적인 비용 효율성을 달성한다.
- **패러다임 전환:** 이는 서버(컨테이너화된 서버 포함) 관리에서 함수 관리로의 전환이다. 이는 AI 배포를 민주화하여, 심층적인 인프라 전문 지식이 없는 사람들도 접근할 수 있게 만든다.
- **과제:** <u>첫 번째 호출에 대한 지연 시간인 콜드 스타트(cold start)</u>가 극복해야 할 주요 기술적 장애물이다.

#### 6.2 엣지 & 분산 추론: 분산화와 자율성의 철학

- **철학:** 계산을 중앙 집중식 클라우드에서 데이터가 생성되는 장치인 엣지(edge)로 이동시키는 것이다. 이는 사용자 **프라이버시**(민감한 데이터가 장치를 떠나지 않음), **자율성**(지속적인 연결 없이 작동), 그리고 **초저지연 시간**(네트워크 왕복 제거)을 우선시하는 중대한 철학적 전환을 나타낸다.
- **대규모 모델(LLM)의 경우:** 모델이 단일 엣지 장치에 비해 너무 클 때, **분산 추론(distributed inference)** 이 등장한다. 모델은 여러 장치에 분할되어 계산을 협력적으로 수행한다. 이는 엣지에서의 "집단 지성" 철학이다.

#### 6.3 다중 모델 아키텍처: 조합의 철학

- **철학:** 단일의 거대한 "범용" 모델을 찾는 대신, 여러 개의 작고 전문화된 모델을 결합하여 복잡한 문제를 해결하는 접근 방식이다. 이는 소프트웨어 아키텍처의 마이크로서비스(microservices) 경향을 반영하는 "분할 정복"과 조합의 철학이다.
- **아키텍처 패턴:**
  - **전처리 체인:** 간단한 모델이 더 복잡한 모델을 위해 데이터를 정리/준비한다.
  - **선택적 라우팅:** 라우터 모델이 입력을 기반으로 <u>요청을 적절한 전문 모델로</u> 보낸다.
  - **앙상블/조합:** 여러 모델의 출력을 결합하여 최종적으로 <u>더 견고한 결과를 생성</u>한다.
- **이점:** 이는 더 큰 효율성(간단한 작업에 저렴한 모델 사용), 더 나은 성능(전문화된 모델이 뛰어남), 그리고 더 쉬운 유지보수(한 구성 요소 업데이트가 전체 시스템 재훈련을 요구하지 않음)로 이어진다.61

---

## 제4부: 인간 인터페이스

### 섹션 7. 계약으로서의 API: 확률적 진실의 전달

#### 7.1 엔드포인트를 넘어: 신뢰 구축 메커니즘으로서의 API

ML 모델을 위한 API는 기술적 인터페이스 이상이다. 그것은 모델 제공자와 소비자 사이의 계약이다. ML의 확률적 특성을 고려할 때, 이 계약은 사용자 신뢰를 구축하고 유지하기 위해 <u>모델의 불확실성에 대한 명확한 소통을 포함</u>해야 한다. 단일 예측 값은 종종 오해를 불러일으킬 만큼 절대적으로 보일 수 있다.

#### 7.2 응답의 구조화: 불확실성 전달을 위한 모범 사례

확률 분포를 JSON과 같은 구조화되고 기계가 읽을 수 있는 형식으로 어떻게 표현할 것인가? 이 문제에 대한 접근 방식은 정교함의 수준에 따라 나눌 수 있다.

1. **레벨 1: 예측 + 신뢰도 점수:** 가장 일반적인 접근 방식이다. API는 최상위 예측과 단일 신뢰도 점수(0과 1 사이의 확률)를 반환한다. 이는 간단하지만 다른 예측들이 거의 비슷한 확률을 가질 경우 불충분할 수 있다.

```json
{ "prediction": "cat", "confidence": 0.85, "deployedModelId": "..." }
```

2. **레벨 2: Top-k 예측과 확률:** API는 상위 'k'개의 <u>가능한 예측 목록을 각각의 관련 확률과 함께 반환</u>한다. 이는 소비자에게 모델의 "사고 과정"에 대한 훨씬 풍부한 그림을 제공한다. Google의 `logprobs` 기능은 이의 고급 버전이다.

```json
{ "predictions": [ {"label": "cat", "probability": 0.85}, {"label": "dog", "probability": 0.10}, {"label": "fox", "probability": 0.05} ], "deployedModelId": "..." }
```

3. **레벨 3: 예측 구간 (회귀용):** 수치 예측의 경우, 단일 값 대신 API는 실제 값이 특정 확률(예: 95% 예측 구간)로 존재할 것으로 예상되는 범위(구간)를 반환한다.

```json
{ "prediction": 450000, "prediction_interval": { "confidence": 0.95, "lower_bound": 420000, "upper_bound": 480000 }, "deployedModelId": "..." }
```

4. **레벨 4: 전체 분포 매개변수:** 고급 사용 사례의 경우, API는 예측된 확률 분포 자체의 매개변수(예: 가우시안 분포의 평균 및 분산)를 반환할 수 있다.

```json
// Google Gemini 예시
{ "candidates": }, "finishReason": "STOP", "safetyRatings":, "logprobs": {... } } ] }
```

## 결론: 모델 서빙의 통합적 철학

효과적인 모델 서빙은 세 가지 철학의 삼위일체 위에 구축된 학문이다: **과학적 철학**의 재현성과 경험적 검증; **엔지니어링 철학**의 추상화, 자동화, 그리고 견고한 시스템; 그리고 **서비스 철학**의 지속적인 적응과 투명한 소통.

성공은 데이터 과학자의 통계적 엄격함, 소프트웨어 엔지니어의 시스템적 사고, 그리고 DevOps 실무자의 운영 규율이 융합된 학제간 노력을 요구한다.

모델 서빙의 미래 궤적은 명확하다. 더 큰 추상화(서버리스), 더 큰 분산화(엣지), 그리고 서빙 시스템 자체의 더 큰 지능(자동화된 드리프트 감지, 다중 모델 조합)을 향해 나아가고 있다. 궁극적인 목표는 강력하고 확장 가능할 뿐만 아니라, 적응적이고, 책임감 있으며, 근본적으로 신뢰할 수 있는 시스템을 만드는 것이다.

### 4.2. 동적 확장성: 수요에 효율적으로 대응하기

실제 서비스 환경에서 트래픽은 예측 불가능하게 변동합니다. 오토스케일링(Autoscaling)은 이러한 트래픽 변화에 맞춰 컴퓨팅 리소스(예: 쿠버네티스의 파드) 수를 자동으로 조절하여, 성능과 비용 사이의 최적의 균형을 유지하는 핵심 기술입니다. 사용량이 많을 때는 리소스를 늘려(Scale-out) 안정적인 서비스를 제공하고, 사용량이 적을 때는 리소스를 줄여(Scale-in) 운영 비용을 절감합니다.

- **두 가지 스케일러 이야기: HPA vs. KPA**
  - **Horizontal Pod Autoscaler (HPA):** 쿠버네티스의 표준 오토스케일러입니다. CPU나 메모리 사용량과 같은 리소스 기반 지표를 기준으로 파드의 수를 조절합니다. 범용적으로 사용하기 좋지만, 실제 애플리케이션의 부하를 간접적으로만 반영하며, 파드 수를 0으로 줄이는 'Scale-to-Zero' 기능을 지원하지 않습니다.
  - **Knative Pod Autoscaler (KPA):** Knative Serving의 기본 오토스케일러입니다. 파드당 처리하는 <u>동시 요청 수(Concurrency)나 초당 요청 수(RPS)를 기준으로 스케일링</u>합니다. 이는 CPU 사용량보다 애플리케이션의 부하를 더 직접적으로 나타내는 지표입니다.
  - **Scale-to-Zero의 힘:** KPA의 가장 큰 특징은 '**0으로 스케일링(Scale-to-Zero)**' 기능입니다. 특정 서비스에 들어오는 트래픽이 없을 때, KPA는 해당 서비스의 파드를 0개로 줄여 리소스 사용량을 완전히 없앨 수 있습니다. 이후 첫 요청이 들어오면, 'Activator'라는 컴포넌트가 요청을 잠시 붙잡아두고, 백그라운드에서 파드를 1개로 스케일업한 뒤, 준비가 완료되면 요청을 전달합니다. 이 기능은 사용 빈도가 낮거나 예측 불가능한 트래픽 패턴을 가진 수많은 모델을 운영해야 하는 환경에서 비용 효율성을 극대화하는 게임 체인저입니다.

**표 3: 오토스케일링 전략 비교 (HPA vs. KPA)**

| 특징                   | Horizontal Pod Autoscaler (HPA)            | Knative Pod Autoscaler (KPA)                                 |
| ---------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| **주요 스케일링 지표** | CPU/메모리 사용량, 커스텀 메트릭           | 동시 요청 수 (Concurrency), 초당 요청 수 (RPS)               |
| **Scale-to-Zero 지원** | 미지원                                     | 지원 (핵심 기능)                                             |
| **이상적인 워크로드**  | 지속적으로 트래픽이 있는 안정적인 워크로드 | 트래픽이 간헐적이거나 예측 불가능한 워크로드, 서버리스       |
| **콜드 스타트 영향**   | 없음 (항상 최소 1개 파드 유지)             | 0에서 스케일업 시 첫 요청에 대한 지연 시간(콜드 스타트) 발생 |
| **복잡도**             | 낮음 (쿠버네티스 기본 기능)                | 중간 (Knative Serving 설치 필요)                             |

### 4.3. 이기종 하드웨어 관리: CPU-GPU 스케줄링 과제

ML 워크로드는 종종 GPU와 같은 특수 하드웨어를 필요로 하지만, 애플리케이션의 다른 부분은 일반 CPU에서 실행됩니다. 쿠버네티스는 이러한 이기종 환경을 효율적으로 관리하기 위한 메커니즘을 제공합니다.

- **쿠버네티스에서의 GPU 스케줄링:** 파드(Pod)의 명세(specification)에 `nvidia.com/gpu: 1`과 같이 필요한 GPU 리소스를 요청할 수 있습니다. 그러면 쿠버네티스 스케줄러는 해당 파드를 <u>가용한 GPU가 있는 노드</u>에 배치합니다.
- **GPU 파편화 문제:** 기본 쿠버네티스 스케줄러는 부하를 분산시키려는 경향이 있어, 작은 GPU 워크로드들을 여러 노드에 흩어지게 배치할 수 있습니다. 그 결과, 클러스터 전체적으로는 충분한 GPU가 남아있음에도 불구하고, 대규모 GPU(예: 8개 GPU)를 필요로 하는 큰 작업을 배치할 단일 노드가 없어 스케줄링에 실패하는 '파편화(Fragmentation)' 문제가 발생할 수 있습니다.
- **효율적 사용 전략:**
  - **노드 테인트(Taints)와 톨러레이션(Tolerations):** <u>특정 노드를 GPU 워크로드 전용으로 지정하여 다른 워크로드가 배치되지 않도록 격리</u>할 수 있습니다.
  - **Multi-Instance GPUs (MIG):** 최신 NVIDIA GPU가 제공하는 기능으로, 단일 물리 GPU를 최대 7개의 완전히 격리된 하드웨어 파티션으로 분할할 수 있습니다. 각 파티션은 쿠버네티스에 의해 독립적인 GPU로 인식되고 스케줄링될 수 있어, 전체 GPU가 필요 없는 작은 워크로드들을 한 GPU에 모아 파편화를 방지하고 활용률을 극대화하는 강력한 도구입니다.
  - **시간 공유 GPU (Time-Sharing GPUs):** 여러 컨테이너가 단일 GPU를 공유하도록 허용하는 방식입니다. GPU 드라이버가 컨텍스트 스위칭을 통해 각 컨테이너에 시분할로 GPU 리소스를 할당합니다. 개발 환경이나 처리량이 낮은 워크로드에 적합합니다.


### 4.5. 장애를 대비한 설계: 내결함성 (Fault Tolerance)

- **개념:** 시스템을 구성하는 일부 구성 요소에 결함이나 고장이 발생하더라도, 시스템 전체가 중단되지 않고 정상적으로 또는 부분적으로 기능을 계속 수행할 수 있는 능력입니다. 이는 고가용성 서비스의 필수 요건입니다.
- **핵심 기법:**
  - **복제 / 이중화 (Replication / Redundancy):** 동일한 서비스의 복제본을 여러 개 실행하여, 하나에 장애가 발생하면 다른 복제본으로 트래픽을 자동 전환하는 방식입니다. 쿠버네티스는 레플리카셋(ReplicaSet)을 통해 이를 기본적으로 지원합니다.
  - **점진적 성능 저하 (Graceful Degradation):** 비핵심적인 구성 요소의 장애가 전체 서비스의 중단으로 이어지지 않도록 설계하는 것입니다.
  - **상태 확인 및 자동 재시작 (Health Checks & Automatic Restarts):** 쿠버네티스는 주기적으로 파드의 상태를 확인하고, 응답이 없는 파드를 자동으로 재시작하여 서비스의 가용성을 유지합니다.

## 파트 2: 고급 서빙 아키텍처 및 패턴

이 파트에서는 저수준 성능 튜닝에서 벗어나 더 높은 수준의 아키텍처 패턴으로 전환합니다. 현대 모델 서빙은 단일 모델 엔드포인트에 관한 것이 아니라, 복잡한 다중 구성 요소 애플리케이션 파이프라인을 구축하는 것에 관한 것입니다.

### 통합된 전처리 및 후처리 파이프라인

이 섹션에서는 데이터 변환 로직을 모델과 함께 단일 배포 단위로 묶는 중요한 관행을 탐구합니다.

#### 통합 파이프라인의 전략적 중요성

모델을 <span style="background:#fff88f">독립적인 아티팩트로 배포하는 것은 위험</span>합니다. 클라이언트 요청의 원시 데이터는 모델이 기대하는 정확한 형식과 거의 일치하지 않습니다. <u>토큰화, 정규화, 이미지 크기 조정과 같은 전처리가 필요</u>합니다. 마찬가지로, <u>모델의 원시 출력(예: 로짓)은 사람이 읽을 수 있거나 애플리케이션 친화적인 형식(예: 클래스 레이블, JSON 객체)으로 후처리</u>되어야 합니다.

#### 학습-서빙 편향 최소화

이러한 단계를 통합하는 가장 중요한 이유는 <u>학습 중에 사용된 것과 정확히 동일한 변환 로직이 추론 중에도 적용되도록 보장하기 위함</u>입니다. 학습 파이프라인과 서빙 파이프라인 간의 불일치는 **학습-서빙 편향(training-serving skew)** 을 유발하며, 이는 조용하지만 치명적인 성능 저하로 이어집니다.

#### 구현 패턴

다양한 서빙 플랫폼은 이러한 통합 파이프라인을 구현하기 위한 고유한 패턴을 제공합니다.

- **NVIDIA Triton의 앙상블 모델:** Triton은 여러 모델의 방향성 비순환 그래프(DAG)를 정의할 수 있는 "앙상블 모델" 기능을 제공합니다. 일반적인 패턴은 `[Python 전처리 모델] -> -> [Python 후처리 모델]`과 같은 3단계 파이프라인입니다. Triton 스케줄러는 한 단계의 출력 텐서를 다음 단계의 입력으로 전달하는 전체 데이터 흐름을 관리하며, 이 모든 과정이 클라이언트의 단일 API 호출 내에서 이루어집니다. 이는 <u>네트워크 오버헤드를 피하고 클라이언트 로직을 단순화</u>합니다.
- **Google Vertex AI의 맞춤형 예측 루틴 (CPR):** Vertex AI는 `preprocess()` 및 `postprocess()` 메서드를 포함하는 `Predictor` 클래스를 모델 아티팩트와 함께 제공할 수 있는 프레임워크를 제공합니다. 플랫폼은 이를 맞춤형 컨테이너로 패키징하여 HTTP 서버 및 상용구 코드를 처리하므로, 개발자는 변환 로직에만 집중할 수 있습니다.
- **프레임워크 네이티브 통합:** TensorFlow나 Scikit-learn과 같은 일부 프레임워크는 <u>전처리 계층을 모델 그래프 자체에 직접 내장할 수 있도록 하여, 모델 아티팩트를 자체적으로 완결된 형태로</u> 만듭니다.

통합 파이프라인은 운영의 단순성과 견고성을 이끌어냅니다. 만약 <u>전/후처리 로직이 클라이언트 애플리케이션에 존재한다면, 모든 클라이언트(웹, 모바일, 다른 마이크로서비스)는 이 로직을 완벽하게 복제</u>해야 합니다. 이는 매우 취약하며 운영상 악몽과도 같습니다. 로직을 변경할 때마다 모든 클라이언트를 업데이트해야 하기 때문입니다. 반면, 전체 로직(전처리 -> 예측 -> 후처리)을 단일 서빙 엔드포인트(예: Triton 앙상블)로 캡슐화하면, 복잡성이 클라이언트로부터 숨겨집니다. 클라이언트는 원시 데이터를 보내고 최종적으로 사용 가능한 결과를 받게 됩니다. 이는 <u>클라이언트 측 코드를 단순화하고, 더 중요하게는 비즈니스 로직을 중앙에서 관리</u>하게 해줍니다. 파이프라인 업데이트는 단일의 원자적인 서버 측 배포로 이루어지게 됩니다. 이러한 중앙 집중화는 특정 모델 버전과 그에 상응하는 전/후처리 로직 간의 중요한 연결을 유지하도록 보장하며, 이는 재현성과 롤백에 필수적입니다. 결론적으로, 처리 파이프라인의 통합은 단순한 성능 최적화를 넘어, 유지보수 가능하고 확장 가능하며 견고한 ML 기반 애플리케이션을 구축하기 위한 근본적인 설계 패턴입니다. 이는 데이터 변환의 책임을 소비자에서 생산자로 이전시켜, 우수한 마이크로서비스 아키텍처의 원칙을 따릅니다.

### AI 워크로드를 위한 지능형 부하 분산

이 섹션에서는 AI 추론의 고유한 특성에 맞춰진 전략에 중점을 두고, 여러 모델 인스턴스 또는 서버에 트래픽이 어떻게 분산되는지 자세히 설명합니다.

#### 정적 알고리즘 대 동적 알고리즘

- **정적 알고리즘:** 서버의 현재 상태를 무시하고 미리 설정된 규칙을 따릅니다. 예로는 요청을 순차적으로 분산하는 **라운드 로빈(Round Robin)** 과 더 강력한 서버에 더 많은 트래픽을 보내는 **가중 라운드 로빈(Weighted Round Robin)** 이 있습니다. 이들은 간단하지만 가변적인 워크로드에는 비효율적일 수 있습니다.
- **동적 알고리즘:** 서버 상태 및 부하에 따라 실시간으로 결정을 내립니다. 이는 AI 워크로드에 매우 중요합니다.
  - **최소 연결(Least Connections):** 활성 연결이 가장 적은 서버로 다음 요청을 보냅니다. 이는 입력에 따라 추론 시간이 크게 달라질 수 있는 AI 워크로드(예: 짧은 텍스트 프롬프트 대 긴 텍스트 프롬프트)에 이상적입니다.
  - **최소 응답 시간(Least Response Time):** 활성 연결과 서버의 평균 응답 시간을 모두 고려하는 더 정교한 버전입니다.
  - **리소스 기반(Resource-Based):** 각 서버의 에이전트를 사용하여 실제 리소스 사용량(CPU, GPU, 메모리)을 보고합니다. 로드 밸런서는 가용 용량이 가장 많은 서버로 트래픽을 보냅니다. 이는 다양한 유형의 가속기가 있는 이기종 환경에 매우 효과적입니다.

#### 글로벌 서버 부하 분산 (GSLB)

전 세계적으로 분산된 애플리케이션의 경우, GSLB는 이러한 개념을 여러 지리적 지역으로 확장하여 사용자를 가장 가까운 데이터센터로 라우팅함으로써 네트워크 지연 시간을 최소화하고 안정성을 향상시킵니다.

AI를 위한 최적의 부하 분산은 콘텐츠와 리소스를 인지해야 합니다. 전통적인 웹 애플리케이션은 종종 균일한 요청 처리 시간을 가지므로, 라운드 로빈 방식만으로도 충분한 경우가 많습니다. 그러나 AI 추론 요청은 매우 불균일합니다. 간단한 분류 요청은 10ms가 걸릴 수 있지만, 긴 텍스트 구절을 생성하는 요청은 10초가 걸릴 수 있습니다. 이러한 시나리오에서 라운드 로빈을 사용하면 재앙이 될 수 있습니다. 한 서버는 장기 실행 요청으로 인해 막혀 있는 동안 다른 서버는 유휴 상태로 있을 수 있기 때문입니다. 따라서 **최소 연결**과 같은 동적 알고리즘은 효과적인 AI 부하 분산을 위한 최소한의 요구 사항입니다. 이들은 장기 실행 요청으로 막히지 않은 서버로 새로운 단기 요청을 라우팅함으로써 가변 처리 시간을 본질적으로 고려합니다. 가장 진보된 접근 방식인 **리소스 기반** 부하 분산은 <u>많은 모델의 실제 병목 지점인 GPU VRAM과 같은 리소스 소비를 직접 측정하므로 연결 수만 계산하는 것보다 훨씬 더 효과적</u>입니다. 결론적으로, AI 서빙을 위한 부하 분산 알고리즘의 선택은 사소한 세부 사항이 아닙니다. 이는 예상되는 워크로드 특성에 기반한 신중한 결정이어야 합니다. 이기종 모델과 가변적인 요청 복잡성을 가진 환경에서는 동적이고 리소스를 인지하는 알고리즘이 병목 현상을 방지하고 값비싼 가속기 하드웨어의 활용도를 극대화하는 데 필수적입니다.

### 고급 추론 그래프: 단순한 앙상블을 넘어서

이 섹션에서는 서빙 플랫폼이 단순한 선형 파이프라인을 훨씬 뛰어넘어, 조건부 논리를 갖춘 복잡한 다중 모델 워크플로우를 지원하기 위해 어떻게 진화하고 있는지 탐구합니다.

#### 선형 파이프라인에서 방향성 비순환 그래프(DAG)로

Triton의 앙상블 모델은 선형 시퀀스에 탁월하지만, 실제 애플리케이션은 종종 콘텐츠에 따라 요청을 다른 모델로 라우팅하거나, 여러 모델을 병렬로 실행한 다음 결과를 결합하는 등 더 복잡한 로직을 필요로 합니다.

> Triton의 Business Logic Scripting으로 처리 가능

#### KServe의 InferenceGraph: 조건부 라우팅을 위한 패러다임

Kubernetes 기반 모델 서빙 플랫폼인 KServe는 `InferenceGraph` 사용자 정의 리소스(Custom Resource)를 통해 이러한 복잡한 로직을 공식화합니다. 이를 통해 노드의 그래프를 정의할 수 있으며, 각 노드는 모델 또는 다른 하위 그래프가 될 수 있습니다. KServe는 흐름을 정의하기 위해 여러 강력한 라우터 유형을 제공합니다 :

- **시퀀스 노드(Sequence Node):** Triton의 앙상블과 유사하게, 정의된 순서대로 일련의 단계를 실행합니다.
- **스플리터 노드(Splitter Node):** 가중치 백분율에 따라 여러 다운스트림 모델 간에 트래픽을 분할하며, A/B 테스트나 카나리 배포에 유용합니다.
- **앙상블 노드(Ensemble Node):** 요청을 모든 자식 노드에 병렬로 보내고 지정된 방법(예: 다수결, 평균)으로 결과를 결합합니다.
- **스위치 노드(Switch Node):** 가장 강력한 유형으로, 진정한 **조건부 라우팅**을 가능하게 합니다. 요청 데이터에 대한 조건을 평가하고, 조건과 일치하는 첫 번째 단계로 요청을 라우팅합니다. 이를 통해 동적인 콘텐츠 기반 워크플로우가 가능해집니다. 예를 들어, "입력 텍스트가 영어이면 영어 감성 모델로 보내고, 스페인어이면 스페인어 모델로 보낸다"와 같은 로직을 구현할 수 있습니다.

#### Seldon Core의 복잡한 그래프

또 다른 Kubernetes 네이티브 서빙 프레임워크인 Seldon Core 역시 라우터, 트랜스포머, 결합기, 스플리터 등을 포함한 복잡한 추론 그래프를 강력하게 지원하여, 정교한 ML 기반 마이크로서비스 아키텍처 구축을 가능하게 합니다.

모델 서빙 플랫폼은 애플리케이션 로직 엔진으로 진화하고 있습니다. 단순한 모델 엔드포인트는 단일 기능을 제공하고, 파이프라인(Triton 앙상블과 같은)은 고정된 기능 시퀀스를 조율합니다. 반면, 조건부 라우팅을 갖춘 고급 추론 그래프(KServe의 스위치 노드와 같은)는 <span style="background:#fff88f">서빙 계층 자체가 비즈니스 로직을 실행</span>할 수 있도록 합니다. 라우팅은 더 이상 정적이지 않고, 데이터에 따라 동적으로 변합니다. 이는 이전에 상위 애플리케이션 마이크로서비스에서 코딩해야 했던 로직을 이제 MLOps 플랫폼 내에서 선언적으로 정의하고 관리할 수 있음을 의미합니다. 이러한 접근 방식은 <u>ML 관련 오케스트레이션 로직을 모델 자체와 함께 버전 관리, 모니터링 및 관리할 수 있는 전문 서빙 계층으로 이전</u>함으로써 전체 애플리케이션 아키텍처를 단순화합니다. 결론적으로, 고급 추론 그래프는 모델 서빙 플랫폼의 역할에 있어 중요한 변화를 나타냅니다. 이는 단순한 '모델 로더 및 실행기'에서 복잡한 ML 기반 애플리케이션 로직을 조율하기 위한 정교하고 선언적인 엔진으로 진화하고 있습니다. 이러한 추세는 전체 시스템 설계를 단순화하고 MLOps 팀이 엔드투엔드 ML 워크플로우를 더 많이 관리할 수 있도록 힘을 실어줍니다.


## Part 2: 고성능 및 확장 가능한 추론

이 파트에서는 "무엇을"에서 "어떻게"로 초점을 옮겨, 엔터프라이즈 수준의 규모를 처리하고 엄격한 성능 요구사항을 충족시키기 위해 필요한 아키텍처 결정과 엔지니어링 기술을 다룹니다.

### 섹션 2.1: 아키텍처 패러다임: 배치 추론 vs. 온라인 추론

모델 서빙 아키텍처를 설계할 때 가장 먼저 내려야 할 근본적인 결정 중 하나는 데이터를 처리하는 방식입니다. 데이터를 대규모로 모아 정해진 일정에 따라 처리하는 **배치(Batch) 추론**과 데이터가 도착하는 즉시 실시간으로 처리하는 **온라인(Online) 추론** 사이의 선택은 전체 시스템 설계에 지대한 영향을 미칩니다.17

#### 배치 (오프라인) 추론

배치 추론(Batch Inference) 또는 오프라인 추론은 일반적으로 정해진 스케줄(예: 매일 자정)에 따라 대규모 데이터셋에 대한 예측을 일괄적으로 생성하고, 그 결과를 데이터베이스나 데이터 웨어하우스에 저장하여 나중에 사용할 수 있도록 하는 방식입니다.17 이 파이프라인은 Apache Airflow와 같은 도구로 오케스트레이션되는 경우가 많습니다.22

- **특징:** 이 방식은 높은 처리량(high throughput)과 비용 효율성에 최적화되어 있습니다. 강력한 하드웨어에서 대규모 작업을 실행한 후 리소스를 종료할 수 있어 유휴 비용을 줄일 수 있습니다. 반면, 예측 결과가 즉시 필요하지 않으므로 높은 지연 시간(high latency)을 갖습니다.17 운영 관리 측면에서는 상대적으로 단순합니다.
- **사용 사례:** 실시간 응답이 필요 없는 작업에 적합합니다. 예를 들어, 모든 사용자를 위한 일일 제품 추천 목록 생성, 대출 신청서 묶음에 대한 신용 위험 점수 평가, 또는 주기적인 문서 분류 작업 등이 해당됩니다.18

#### 온라인 (실시간) 추론

온라인 추론(Online Inference) 또는 실시간 추론은 일반적으로 REST 또는 gRPC API 형태로 상시 실행되는 저지연 서비스로, 개별 요청에 대해 수 밀리초 내에 응답하는 방식입니다.17 이 방식은 고가용성 인프라를 요구합니다.

- **특징:** 낮은 지연 시간(low latency)과 즉각적인 응답성이 핵심입니다. 상시 가동되는 인프라로 인해 잠재적으로 비용이 더 높을 수 있으며, 트래픽 급증과 같은 상황을 처리해야 하므로 운영 복잡성이 더 높습니다.17
- **사용 사례:** 시간이 중요한 애플리케이션에 필수적입니다. 실시간 사기 탐지, 즉석 언어 번역, 동적 광고 입찰과 같은 시나리오가 여기에 속합니다.19

아키텍트와 제품 관리자는 애플리케이션의 특정 요구사항에 따라 이 두 패러다임 간의 트레이드오프를 신중하게 평가해야 합니다. 단순히 실시간이 '멋져 보이기' 때문에 선택하는 것은 비효율적인 시스템 설계로 이어질 수 있습니다.25

| 특징                 | 배치 추론 (Batch Inference)                        | 온라인 추론 (Online Inference)                                 |
| -------------------- | -------------------------------------------------- | -------------------------------------------------------------- |
| **데이터 처리**      | 대규모 데이터 모음을 하나의 작업으로 함께 처리 17  | 단일 데이터 포인트 또는 작은 그룹을 도착하는 즉시 처리 17      |
| **주요 최적화 목표** | 높은 처리량 및 비용 효율성 17                      | 낮은 지연 시간 및 즉각적인 응답성 17                           |
| **지연 시간**        | 높음 (수 분에서 수 시간) 17                        | 매우 낮음 (수 밀리초) 17                                       |
| **호출 방식**        | 스케줄(예: cron job) 또는 온디맨드로 트리거 17     | 직접적인 사용자 요청 또는 시스템 이벤트에 의해 트리거 17       |
| **데이터 최신성**    | 낮음 (데이터는 수집된 후 일정 시간 경과) 19        | 높음 (데이터는 거의 실시간으로 처리됨) 24                      |
| **운영 복잡성**      | 상대적으로 낮음 18                                 | 상대적으로 높음 18                                             |
| **대표 사용 사례**   | 일일 추천 생성, 주기적 리스크 분석, 보고서 생성 18 | 실시간 사기 탐지, 동적 가격 책정, 챗봇 응답 19                 |
| **대표 기술**        | Apache Spark, Apache Airflow, Databricks Jobs 18   | REST/gRPC API, Kubernetes, TensorFlow Serving, NVIDIA Triton 1 |

### 섹션 2.2: 고수요 워크로드를 위한 확장 전략

모델 서빙 시스템은 트래픽 변화에 유연하게 대응할 수 있는 확장 전략을 갖추어야 합니다.

#### 수평적 확장 vs. 수직적 확장

모델 서빙에서는 일반적으로 수직적 확장(단일 인스턴스의 사양을 높이는 것)보다 수평적 확장(더 많은 인스턴스를 추가하는 것)이 선호됩니다. 이는 더 나은 내결함성과 비용 최적화를 제공하기 때문입니다. 하나의 강력한 인스턴스가 실패하면 전체 서비스가 중단될 수 있지만, 여러 인스턴스 중 하나가 실패하더라도 로드 밸런서가 트래픽을 다른 인스턴스로 라우팅하여 서비스를 계속 유지할 수 있습니다.3

#### 컨테이너화 및 오케스트레이션

- **Docker:** 재현 가능하고 캡슐화된 서빙 환경을 만들기 위해 Docker를 사용하는 것이 표준적인 접근 방식입니다. Docker 컨테이너는 모델, 종속성, 실행 환경을 하나로 묶어 개발 환경과 프로덕션 환경 간의 일관성을 보장합니다.2
- **Kubernetes:** 컨테이너화된 애플리케이션을 대규모로 관리하기 위한 사실상의 표준입니다. Kubernetes는 컨테이너의 배포, 확장, 라이프사이클 관리를 자동화하여 MLOps 엔지니어가 인프라의 세부적인 관리보다 모델 자체에 집중할 수 있도록 합니다.2

#### 자동 확장 (Auto-Scaling)

자동 확장은 실시간 메트릭을 기반으로 모델 서버 인스턴스의 수를 자동으로 조절하는 시스템을 구현하는 것입니다.3 확장의 트리거는 CPU/GPU 사용률, 요청 큐의 깊이, 응답 지연 시간 또는 특정 비즈니스 메트릭이 될 수 있습니다.3 이 기능을 통해 트래픽이 급증하는 동안에도 서비스 품질을 유지하고, 트래픽이 적은 시간에는 비용을 최적화할 수 있습니다.

### 하드웨어 가속 및 아키텍처 고려사항

이 섹션에서는 추론에 사용되는 주요 하드웨어 가속기를 비교 분석하며, 각 기술의 이상적인 사용 사례를 결정짓는 아키텍처적 차이점에 초점을 맞춥니다.

#### GPU (NVIDIA) 대 TPU (Google): 두 아키텍처 이야기

GPU와 TPU는 근본적인 설계 철학에서 차이를 보입니다.

- **GPU:** 수천 개의 유연한 CUDA 코어를 활용하여 범용 병렬 프로세서 역할을 합니다. 원래 그래픽 처리를 위해 설계되었지만, 광범위한 병렬 연산 작업에서 뛰어난 성능을 발휘합니다.
- **TPU:** 특정 용도용 집적 회로(ASIC)로서, 딥러닝 워크로드의 대부분을 차지하는 대규모 행렬 곱셈과 같은 텐서 연산을 위해 처음부터 설계되었습니다. 이들은 **Systolic Array** 아키텍처를 사용하여 데이터를 처리 요소 그리드를 통해 리드미컬하게 전달함으로써, 딥러닝 연산에서 탁월한 효율성을 보입니다.

#### 메모리와 상호 연결: 규모 확장의 숨은 공로자

성능은 단순히 연산 능력에만 의존하지 않습니다. 메모리와 통신의 역할 또한 매우 중요합니다.

- **고대역폭 메모리(HBM):** 최신 GPU와 TPU는 모두 HBM을 칩에 직접 통합하여 시스템 RAM에 비해 월등히 뛰어난 메모리 대역폭을 제공합니다. 이는 연산 유닛에 데이터를 공급하고, 대규모 모델 및 KV 캐시와 같은 중간 상태를 저장하는 데 필수적입니다. NVIDIA H100과 Google의 TPU v5/Ironwood와 같은 주요 칩의 HBM 용량 및 대역폭을 비교하면, 각 아키텍처가 대규모 데이터 처리를 위해 어떻게 최적화되었는지 알 수 있습니다.
- **칩 간 상호 연결(Inter-Chip Interconnects):** 여러 칩에 걸쳐 있는 매우 큰 모델을 서빙할 때, 칩 간의 통신 속도는 주요 병목 지점이 됩니다. NVIDIA의 **NVLink/NVSwitch**와 Google의 맞춤형 **Inter-Chip Interconnect (ICI)** 는 이러한 문제를 해결하기 위한 기술로, 각각의 대역폭과 대규모 '팟(pod)' 형태의 가속기 클러스터 구축을 위한 확장성 특성에서 차이를 보입니다.

#### 와트당 성능: 데이터센터의 핵심 지표

에너지 효율성은 대규모 데이터센터 운영에서 점점 더 중요한 경쟁 우위 요소가 되고 있습니다. TPU는 특화된 설계 덕분에 추론 작업에서 종종 우수한 와트당 성능(performance-per-watt)을 제공하며, 이는 대규모 데이터센터의 경제성에 큰 영향을 미칩니다.

<u>하드웨어의 특성화는 서로 다른 최적화 경로</u>를 만들어냅니다. GPU의 강점은 유연성(CUDA 코어)에 있으며, 이는 비전형적인 구성 요소를 가진 모델이나 맞춤형 C++ 커널을 포함하는 다양한 종류의 연산을 처리할 수 있게 해줍니다. 반면, TPU의 강점은 특정 작업(Systolic Array를 통한 행렬 곱셈)에 대한 극단적인 최적화에 있습니다. 이러한 성능을 달성하기 위해 TPU는 제약 조건을 부과합니다. 워크로드는 XLA(Accelerated Linear Algebra) 컴파일러로 컴파일되어야 하며, 비효율적인 패딩 없이 MXU(Matrix Multiplication Unit)를 완전히 활용하려면 텐서 형태가 8 또는 128의 배수가 되는 것이 이상적입니다.

이로 인해 명확한 분기점이 생깁니다. 만약 워크로드가 순수한 대규모 행렬 연산(많은 대형 트랜스포머 모델의 전형)이고 XLA 생태계 내에서 운영될 수 있다면, TPU는 우수한 성능과 효율성을 제공할 수 있습니다. 그러나 워크로드가 맞춤형 연산을 포함하거나, 빈번한 분기, 또는 다른 CPU 기반 코드와의 최대 유연성이 필요한 경우, GPU가 더 다재다능한 플랫폼을 제공합니다. 결론적으로, GPU와 TPU 사이의 선택은 어느 것이 '더 나은가'의 문제가 아니라, 특정 워크로드의 연산 그래프와 개발팀의 생태계 제약 조건에 어느 것이 '더 잘 맞는가'의 전략적인 아키텍처 결정 문제입니다.

## 마치며


> 본 포스트는 Google Gemini의 응답을 기반으로 저의 의견을 반영하여 다시 작성했습니다.